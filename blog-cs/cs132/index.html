<!DOCTYPE html>
<html>
<head>
	<title>CS132</title>
	<meta charset="utf-8">
	<link rel="stylesheet" type="text/css" href="../../style/style.css" media="all" id="theme-link">  
	<meta name="viewport" content="width=device-width" initial-scale=1.0> 
	<link rel="icon" type="image/png" href="../../style/images/DragonIcon.png">
	<script type="text/javascript" src="../../js/goback.js"></script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

	<div class="hidden">
		<header>
			<div class="parallax parsmaller">
				<div class="columncontainer cthreeside">
					<div class="column tinycolumn">
						<button class="nav dark-light">Darkmode</button>
						<!--<button onclick="goBack()" class="nav">Back</button>-->
					</div>
					<div class="column tinycolumn">
						<a href="../../about.html" class="nav">About</a>
					</div>
					<div class="column tinycolumn">
						<a href="../../blog.html" class="nav">Back</a>
					</div>
				</div>
				<div class="cbox"> 		
					<h1>CS132</h1>
					<p class="subheading">Computer Systems and Architecture</p>
				</div>
			</div>
		</header>

		<header>
			<div class="cbox">
				<h1>Contents</h1>
			</div>
		</header>

		<div class="cbox">
			<ol>
				<li><a href="#datarep">Data Representation</a></li>
				<li><a href="#logic">Digital Logic</a></li>
				<li><a href="#assembler">The Assembler</a></li>
				<li><a href="#memsys">Memory Systems</a></li>
				<li><a href="#iomech">IO Mechanisms</a></li>
				<li><a href="#architecture">Microprocessor Architecture</a></li>
			</ol>

			<i>Editor's note: Diagrams may be omitted if time does not permit. The University has fairly stringent IP regulations for university-made resources, so all diagrams are mine or sourced externally from publically available websites.</i>
		</div>

		<div class="colourband" id="datarep">
			<h2>Data Representation</h2>
		</div>

		<div class="cbox">

			<p>
				<i>Editor's note:</i> Since data rep is a topic covered fairly extensively in GCSE and A level CS, these notes will be brief.
			</p>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						Representations and Binary.
					</p>
				</div>
				<div>
					<p>
						Numbers can be represented in many different ways (decimal, octal, etc) but we most often use binary when dealing with computer systems.
					</p>

					<p>
						Computers work with transistors, and <b>TTL</b> (transistor-transistor logic) works over voltages. Transistors work over a range of about five volts, and we assign the range 0 - 0.8V as 0 and 2.4 - 5V as 1 (and a forbidden zone in the middle), which gives us binary values. 
					</p>

					<p>
						The reason we do this is to achieve something called <b>noise immunity</b>, where natural fluctuations in voltage won't affect the bits.
					</p>
				</div>
			</div>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						Mathematical Operators.
					</p>
				</div>
				<div>
					<p>
						Do recall that overflow exists when working in binary. 
					</p>

					<p>
						We can (fairly) easily make a circuit that adds two binary numbers. However what do we do for subtraction? We could either build a subtractor, or easier find a way to represent negative binary numbers. How about working with decimal numbers.
					</p>
				</div>

				<div>
					<p style="font-style: italic; text-align: right;">
						(Negatives) Signed Magnitude
					</p>
				</div>
				<div>
					<p>
						The largest bit of a binary number acts as the <i>sign</i>, a "flag" which is 1 if the number is negative and 0 if the number is positive;
						\[1101_{2SM} = -1 \times (4 + 0 + 1) = -5.\]
						This can represent numbers in the range \([-2^{n-1}, 2^{n-1}]\), for \(n\) bits.
					</p>
				</div>

				<div>
					<p class="ir">
						(Negatives) Two's Complement
					</p>
				</div>
				<div>
					<p>
						The more commonly used, two's complement is where the largest bit is a negative number;
						\[1101_{2TC} = -8 + 4 + 0 + 1 = -3.\]
						Two's complement represent numbers in the range \([-2^{n-1}, 2^{n-1}-1]\), and a major advantage of two's complement is that it has no unique zero. Signed magnitude numbering has two zeros, \(1000 \equiv 0000\) which can be problematic, whilst two's complement has only \(0000\).
					</p>
				</div>

				<div>
					<p class="ir">
						(Decimals) Fixed Point
					</p>
				</div>
				<div>
					<p>
						A fixed decimal point where to the right are negative powers of two. However this is limited by accuracy (depending on where the fixed point is), nor can it represent very large numbers
					</p>
				</div>

				<div>
					<p class="ir">
						(Decimals) Floating Point
					</p>
				</div>
				<div>
					<p>
						A floating point number is represented with \( (\textrm{sign}) \textrm{ mantissa} \times 2^{\textrm{exponent}} \). One bit is allocated to the sign, a few for the exponent, and the rest for the mantissa. More bits equal more numbers that can be represented.
					</p>

					<button class="collapsible nul">IEE754...</button>
					<div class="ccontent cnul">
						<p>
							The IEEE 754 standard gives 32 bits for a single float, 64 bits for a double, and 128 bits for a quad. For a single precision float, 1 bit is the sign, 8 bits for the exponent and 23 bits for the mantissa.
						</p>
					</div>
				</div>
			</div>
		</div>

		<div class="colourband" id="logic">
			<h2>Digital Logic</h2>
		</div>

		<div class="cbox">
			<h2>Introduction</h2>

			<ol>
				<li><a href="#log-1">Basic Logic Functions</a></li>
				<li><a href="#log-2">Karnaugh Maps</a></li>
				<li><a href="#log-3">Combinatorial Logic Circuits</a></li>
				<li><a href="#log-4">Sequential Logic Circuits</a></li>
			</ol>

			<h2 id="log-1">Basic Logic Functions</h2>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						Switches and bulbs.
					</p>
				</div>
				<div>
					<p>
						We can think about logic using switches and bulbs. Below, are three diagrams of circuits, with labelled switches.
					</p>

					<img src="logic/logics.svg" style="width: 100%;">

					<p>
						Notice how from left to right, these circuits make the NOT, AND, and OR circuits. 
					</p>

					<p>
						For \(n\) inputs, there are \(2^n\) combinations of inputs, and \(2^{(2^n)}\) possible functions and outputs.
					</p>
				</div>

				<div>
					<p class="ir">
						Note on Notation.
					</p>
				</div>
				<div>
					<p>
						In 132, true and false are denoted as \(1, 0\), and the operators AND, OR, and NOT are denoted by \(A \cdot B , A+B, \bar{A}\) respectively. 
					</p>
				</div>
				<div>
					<p class="ir">
						Logic Gates.
					</p>
				</div>
				<div>
					<p>
						Logic gates and truth tables. Included only for completeness' sake.
					</p>
					<button class="collapsible">Expand for gates...</button>
					<div class="ccontent">
						<p>
							Below are images of logic gates, along with their truth tables. 
						</p>

						<img src="https://instrumentationtools.com/wp-content/uploads/2017/07/instrumentationtools.com_digital-logic-gates-truthtables.png" style="max-width: 100%">
					</div>
					<p>
						We can combine logic gates to form more complicated circuits, for example exclusive or, \(A \oplus B\)
					</p>
					<button class="collapsible">Expand...</button>
					<div class="ccontent">
						<img src="https://www.electronicshub.org/wp-content/uploads/2015/07/exor-equivalent-circuit.jpg" style="max-width: 100%">
					</div>
					
					<p>
						Note that NOT, AND and OR are <b>fundamental</b> gates, since they are the building blocks of any function.
					</p>

					<p>
						NAND and NOR are <b>universal</b> gates, since they alone can be used to make any other logic gate. 
					</p>
					

					<p>
						We often want to simplify expressions as possible, because simplifying expressions leads to less logic gates, which is cheaper. (Also, simplifying to one universal gate can also be cheaper due to economy of scale of buying only one gate.)
					</p>

					<p>
						Two main methods of simplification are <b>boolean algebra</b> and <b>Karnaugh Maps</b>. Boolean algebra is covered in <a href="../cs130/index.html#proplogic" class="text">CS130</a>, though of course do note that 132 uses different syntax. 
					</p>
				</div>
			</div>

			<h2 id="log-2">Karnaugh Maps (K-Maps)</h2>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						K-maps.
					</p>
				</div>
				<div>
					<p>
						Karnaugh maps (also called k-maps) can show unambiguously a boolean expression in its simplest form. 
					</p>

					<p>
						Look at the following table. It is a k-map for 3 variables \(A, B, C\). The top row groups AB together, and the left column displays values of C. Within the table each of the squares represent a different combination of values of A, B, C to input into a function we want to simplify.
					</p>

					<img src="logic/kmap-example.png" style="max-width: 100%;">

					<p>
						Note the ordering of AB: 00 <b>01 11</b> 10. This is <i>deliberate</i>, and with this ordering it means that to "step" from any square to any orthogonally adjacent (sides touching) square, the result will differ by <b>only one variable.</b>
					</p>
				</div>

				<div>
					<p class="ir">
						Rules.
					</p>
				</div>
				<div>
					<p>
						Usually, when you get a function, only certain squares in the grid will give an overall result of 1. We do this by a process of <b>grouping 1s</b>.
					</p>

					<p>
						Basically, in a map, you want to group adjacent ones. The groups must be <b>rectangular</b> in shape, and not have any "turns" - an L shape for example is forbidden. Furtherfore, groups must be <b>powers of two</b> in size.
					</p>

					<p>
						Groups may <b>wrap around</b> edges - like pacman. 
					</p>

					<p>
						Groups are permitted to overlap.
					</p>

					<p>
						<b>Minimum no. of groups</b>, ideally bigger size groups, make more <b>optimal solution</b>. 
					</p>

					<p>
						Then to find the simplfied equation, find only the variables that remain constant in a group, and only include that.
					</p>

					<p>
						Have a look at the example below.
					</p>
				</div>

				<div>
					<p class="ir">
						<b>Example.</b>
					</p>
				</div>
				<div class="ncontent">
					<p>
						Simplify the function \(f = AB\bar{C}D + A\bar{B}\bar{C}D + \bar{A}\bar{B}CD + \bar{A}BCD\). 
					</p>

					<div>
						<p >
							Take the following karnaugh map - note that we have to split now AB / CD.
						</p>

						<img src="logic/kmap-gr1.png" style="max-width: 100%">

						<p>
							In the red group, A remains constant 1, B changes, C remains consant 0, and D remains constant 1, therefore we get \(A \cdot \bar{C} \cdot D\). Similarly for the blue group, A remains constant 0, B changes, and C, D remain constant 1, therefore we get \(\bar{A} \cdot C \cdot D\).
						</p>
						<p>
							Thus \(f = A \cdot \bar{C} \cdot D + \bar{A} \cdot C \cdot D\)
						</p>
					</div>
				</div>

				<div>
					<p class="ir">
						Equivalences.
					</p>
				</div>
				<div>
					<p>
						It is possible to have equivalent constructions which are all the optimal solution. For example, for the following map:
					</p>

					<img src="logic/kmap-gr2.png" style="max-width: 100%">

					<p>
						The optimal solution could either comprise of red, green, and blue, or red, purple, and blue. 
					</p>
				</div>

				<div>
					<p class="ir">
						<b>Example</b> of wrapping.
					</p>
				</div>
				<div class="ncontent">
					<p>
						Look at the karnaugh map below. The optimal grouping is shown.
					</p>

					<img src="logic/kmap-gr3.png" style="max-width: 100%">

					<p>
						Thus here \(f = \bar{B} + \bar{A} \cdot \bar{C}\)
					</p>
				</div>

				<div>
					<p class="ir">
						Impossibilites.
					</p>
				</div>
				<div>
					<p>
						Sometimes, however, with specific cases, minimising this way is impossible.
					</p>

					<img src="logic/kmap-gr4.png" style="max-width: 100%">

					<p>
						This is actually \((A \oplus B) \oplus (C \oplus D)\). It is thus only of use in cases, especially where exclusive or is involved. 
					</p>

					<p>
						Sometimes, even, it is easier to extract \(\bar{f}\), i.e. 0s from the map. 
					</p>
				</div>

				<div>
					<p class="ir">
						"Don't care" conditions.
					</p>
				</div>
				<div>
					<p>
						Denoted often with an \(\times\), this can be assumed to be either 1 or 0 depending on context. 
					</p>

					<img src="logic/kmap-gr5.png" style="max-width: 100%">

					<p>
						The case where \(\times\) is a 0, we have \(f = A + B + C \cdot D\).
					</p>

					<img src="logic/kmap-gr6.png" style="max-width: 100%">

					<p>
						The case where \(\times\) is a 1, we have \(f = A + B + D\).
					</p>
				</div>
			</div>

			<h2 id="log-3">Combinatorial Logic Circuits</h2>

			<p>
				<i>Editor's note:</i> Apologies for the PNG and not SVG images, but I'm not going to switch to svg or use latex because it takes long enough.
			</p>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						Half bit adder.
					</p>
				</div>
				<div>
					<p>
						There are several combinatorial logic ciruits one should know about. First of all, we want to look at adding bits, since addition is very important generally. To start adding bits, we start off with only a half bit adder, where we add \(A, B\) and get a \(\Sigma, \textrm{Carry}\). 
					</p>

					<figure>
						<img src="https://upload.wikimedia.org/wikipedia/commons/d/d9/Half_Adder.svg" style="max-width: 200px; width: 100%; margin-left: auto; margin-right: auto; display: block;">
						<figcaption><i>Half Adder (Wikimedia Commons)</i></figcaption>
					</figure>

					<p>
						Which has a truth table of:

						\begin{array} {|r|r|}\hline A & B & \Sigma & \textrm{Carry} \\ \hline 0 & 0 & 0 & 0 \\ \hline 0 & 1 & 1 & 0 \\ \hline 1 & 0 & 1 & 0 \\ \hline 1 & 1 & 0 & 1 \\ \hline  \end{array}
					</p>
				</div>

				<div>
					<p class="ir">
						Full bit adder.
					</p>
				</div>
				<div>
					<p>
						Now that's just a <i>half</i> adder, a full adder on the other hand requires taking a carry as an input. Thus, we take an \(A, B, C_{\textrm{in}}\) and get a \(\Sigma, C_{\textrm{out}}\).
					</p>

					<p>
						The logic diagram of a full adder is not strictly necessary, but Matt has said he would be pleased if someone produced it, so it's included below.
					</p>

					<figure>
						<img src="https://upload.wikimedia.org/wikipedia/commons/a/a9/Full-adder.svg" style="max-width: 300px; width: 100%; margin-left: auto; margin-right: auto; display: block;">
						<figcaption><i>Full Adder (Wikimedia Commons)</i></figcaption>
					</figure>
				</div>

				<div>
					<p class="ir">
						N-bit adder.
					</p>
				</div>
				<div>
					<p>
						We can then string together a series of full bit adders to form an \(n\)-bit adder.
					</p>

					<figure>
						<img src="https://upload.wikimedia.org/wikipedia/commons/5/5d/4-bit_ripple_carry_adder.svg" style="max-width: 400px; width: 100%; margin-left: auto; margin-right: auto; display: block;">
						<figcaption><i>N-bit adder (Wikimedia Commons)</i></figcaption>
					</figure>
				</div>

				<div>
					<p class="ir">
						Subtraction with adders.
					</p>
				</div>
				<div>
					<p>
						Since subtraction is nothing but addition of negative numbers, we can use two's complement principle to do this. We have a toggle bit \(M\) which hooks onto \(B\). 
					</p>

					<p>
						To convert a number to two's complement, we flip the bits and add 1, so what we can do is flip all the bits of B if M is 1, and then add on M to fit two's complement. An operation to flip the bits of B when M is 1 is <b>exclusive or</b> (check the truth table). We can now build an \(n\)-bit adder-subtractor.
					</p>

					<figure>
						<img src="https://www.electronicshub.org/wp-content/uploads/2015/06/Parallel-subtactor-and-adder.jpg" style="width: 100%; max-width: 440px; margin-left: auto; margin-right: auto; display: block;">
						<figcaption><i>N-bit adder-subtractor (<a href="https://www.electronicshub.org/binary-adder-and-subtractor/">Electronics Hub</a>)</i></figcaption>
					</figure>
				</div>

				<div>
					<p class="ir">
						
					</p>
				</div>
				<div>
					<p>
						There are many other important combinatorial logic circuits that one needs to know (but not necessarily draw the internals of).
					</p>
				</div>

				<div>
					<p class="ir">
						Active Low Decoder.
					</p>
				</div>
				<div>
					<p>
						Active low, often written \(\overline{\textrm{Enable}}\) (with an overline), is where 0 denotes the "true" state. Naturally, Active High also exists, but low seems more commonplace.
					</p>

					<img src="logic/actlow.png" style="max-width: 100%">

					<p>
						A decoder takes an "encoded" binary value and translates it into the appropriate discrete output.
					</p>
				</div>

				<div>
					<p class="ir">
						Encoder.
					</p>
				</div>
				<div>
					<p>
						On the oher hand, the other way round would be an encoder, which takes in a series of inputs and returns an "encoded" binary value. 
					</p>
				</div>

				<div>
					<p class="ir">
						Multiplexer.
					</p>
				</div>
				<div>
					<p>
						A multiplexer "chooses" from a series of \(2^n\) inputs based on \(n\) selection inputs. The following truth table shows a 4-1 (4 in 1 out) multiplexer.
					</p>

					<img src="logic/multiplex.png" style="max-width: 100%">

					<p>
						Note how the denary value \(n\) of the binary \(S_{0}S_{1}\) will choose which value \(X_n\) is "channeled through".
					</p>
				</div>

				<div>
					<p class="ir">
						De-multiplexer.
					</p>
				</div>
				<div>
					<p>
						Opposite to the multiplexer we have a de-multiplexer (a Demux) which does almost the opposite to what a multiplexer does. Have a look at the truth table. 
					</p>

					<p>
						Note that this Demux is active-<b>low</b>.
					</p>

					<img src="logic/demux.png" style="max-width: 100%">

					<p>
						The denary value \(n\) given by \(S_{0}S_{1}\) will choose which \(Y_n\) \(A\) is sent through.
					</p>
				</div>

				<div>
					<p class="ir">
						Applications.
					</p>
				</div>
				<div>
					<p>
						These circuits can be used for source control - i.e. controlling which source gets sent through - so you can have one line for multiple senders. Another application may be converting from serial to parallel, or vice versa. 
					</p>
				</div>
			</div>

			<h2 id="log-4">Sequential Logic Circuits</h2>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						
					</p>
				</div>
				<div>
					<p>
						A sequential logic circuit is a circuit whose outputs are <b>logical functions</b> of <b>inputs</b> and <b>current state</b>. It's often used to build memory. 
					</p>

					<p class="blue">
						Thus, <b>Combinatorial</b> circuits are "time independent" circuits which do not depend on any previous inputs to generate an output, whereas <b>sequential</b> circuits are those which depend on clock cycles, and depend on both current and past inputs ("current state") to generate output.
					</p>
				</div>

				<div>
					<p class="ir">
						Flip flops.
					</p>
				</div>
				<div>
					<p>
						The flip flop is one of the most important circuits. It is stable in two states. 
					</p>

					<img src="logic/flipflip.svg" style="width: 100%">

					<p>
						The truth table of the flip flop is given as follows:

						\begin{array} {|r|r|}\hline \bar{S} & \bar{R} & Q & P \\ \hline 0 & 0 & \times & \times \\ \hline 0 & 1 & 1 & 0 \\ \hline 1 & 0 & 0 & 1 \\ \hline 1 & 1 & N/A & N/A \\ \hline  \end{array}

						A cross in this table indicates a <i style="color: #D00">hazard</i> - basically don't have set and reset on at the same time, it's bad. N/A means no change in state. 
					</p>

					<p>
						Below is a time diagram of the flip flop. Remember that S and R are active low. 
					</p>

					<img src="logic/flipfloptimestep.png" style="width: 100%; max-width: 400px;">
				</div>

				<div>
					<p class="ir">
						D-type latch.
					</p>
				</div>
				<div>
					<p>
						Uses a flip flop, and makes a 1 bit memory circuit. There are inputs \(D, \textrm{Enable}\) and outputs \(Q, \bar{Q}\). \(D\) is usually referred to as "Data".
					</p>

					<img src="logic/dlatych.svg" style="max-width: 500px; width: 100%">

					<p>
						It has the truth table of the following:
						\begin{array} {|r|r|}\hline \textrm{Enable} & D & Q & \bar{Q} \\ \hline 0 & 0 & Q & \bar{Q} \\ \hline 0 & 1 & Q & \bar{Q} \\ \hline 1 & 0 & 0 & 1 \\ \hline 1 & 1 & 1 & 0 \\ \hline  \end{array}
						Note how when Enable is false, no matter what changes with data the latch retains its state, whilst when Enable is true the latch will take on the value of data.
					</p>
				</div>

				<div>
					<p class="ir">
						Edge triggering.
					</p>
				</div>
				<div>
					<p>
						<b>Edge triggering</b> means that a latch, or logic circuit is enabled when the state <b>changes</b>, and not depending on what the state is. For example, when something is active only on the transition of \(1 \rightarrow 0\) or \(0 \rightarrow 1\). 
					</p>

					<p>
						Something which is active at a steady value is called <b>level triggered</b>.
					</p>

					<img src="logic/edgetrigger.svg" style="max-width: 100%">
				</div>

				<div>
					<p class="ir">
						Clocked flip flops.
					</p>
				</div>
				<div>
					<p>
						Clocked flip flops are flips that flop only on the <i>rising edge</i> of a clock input. There are three types - most importantly D-type (<i>delay</i>), along with T-type (<i>toggle</i>) and JK-type.
					</p>

					<img src="logic/floptypes.png" style="max-width: 100%">
				</div>

				<div>
					<p class="ir">
						N-bit register
					</p>
				</div>
				<div>
					<p>
						We can connect multiple D-type latches together to store an \(N\)-bit binary word. Below is a diagram of a 4 bit parallel load register, you can extrapolate the rest.
					</p>

					<figure>
						<img src="logic/4b-barallel.gif" style="width: 100%; max-width: 440px; margin-left: auto; margin-right: auto; display: block;">
						<figcaption><i>4 bit parallel register (<a href="https://www.electronics-tutorials.ws/sequential/seq_5.html">Electronics Hub</a>)</i></figcaption>
					</figure>

					<p>
						In a <b>parallel</b> load register, the binary input \(A\) is loaded all simultaneously. Alternatively, we can have what's called a <b>shift</b> register, where each clock cycle will shift the bits along the register like a queue. The diagram displayed below shows a shift register that only goes one way. Of course, you can also have a two-way shift register. 
					</p>

					<figure>
						<img src="logic/4b-serial.gif" style="width: 100%; max-width: 440px; margin-left: auto; margin-right: auto; display: block;">
						<figcaption><i>4 bit serial in parallel out register (<a href="https://www.electronics-tutorials.ws/sequential/seq_5.html">Electronics Hub</a>)</i></figcaption>
					</figure>
				</div>

				<div>
					<p class="ir">
						N-bit counter
					</p>
				</div>
				<div>
					<p>
						We can also make counters by stringing up flip flops.
					</p>

					<figure>
						<img src="logic/count.png" style="width: 100%; max-width: 358px; margin-left: auto; margin-right: auto; display: block;">
						<figcaption><i>4 bit counter (<a href="https://electronics.stackexchange.com/questions/223986/asynchronous-down-counter-using-d-flip-flops">found off stack exchange</a>)</i></figcaption>
					</figure>
				</div>

				<div>
					<p class="ir">
						3-state logic.
					</p>
				</div>
				<div>
					<p>
						3-state logic is different from regular I/O logic circuits. It, as the name implies, introduces a third state, which is termed "<b>unconnected</b>". If the gate is enabled, the input is disconnected from the output. The gate is there to provide communication between subsystems, when we have a main bus, multiple systems connected to it, and we don't want collisions.
					</p>

					<div class="columncontainer ctwo" style="grid-template-columns: 1fr 2fr;">
						<div style="width: 180px">
							<img src="logic/tristate.svg" style="max-width: 100%">
							<p>
								<i>Right: devices connected to a central hub (<a href="https://www.sciencedirect.com/topics/computer-science/tristate-buffer">ScienceDirect</a>)</i>
							</p>
						</div>
						<div>
							<img src="logic/threestate.gif" style="max-width: 100%">
						</div>
					</div>

					<p>
						A circuit gets messy if there are lots of parallel lines, so for busses there is a consise representation where the bus is represented as a thick line, with a slash through it and a number describing its width.
					</p>
					
				</div>

				<div>
					<p class="ir">
						Physical details.
					</p>
				</div>
				<div>
					<p>
						Physical implementation of logic gates should always be specified, as logic gates <i>generally</i>, but not always, float high, active low. 
					</p>

					<p>
						<i>Propagation delay</i>, the time it takes for a logic gate to work, needs to be taken into account. Often, these are measured on nanosecond scales. For example, a NOT gate may have a delay of 1.2 ns whilst an AND has a delay of 1.7 ns (illustrative purposes only).
					</p>
				</div>

				<div>
					<p class="ir">
						Logic ICs
					</p>
				</div>
				<div>
					<p>
						Three acronyms:
					</p>

					<ul>
						<li><b>PAL</b> Programmable Array Logic</li>
						<li><b>PLA</b> Programmable Logic Array <i style="color: #FFF">People's Liberation Army</i></li>
						<li><b>FPGA</b> Field Programmable Gate Array</li>
					</ul>

					<p>
						Describing types of programmable logic circuits. A diagram for a PLA circuit is shown below.
					</p>

					<img src="logic/PLA.svg" style="max-width: 600px; width: 100%">
				</div>
			</div>

		</div>

		<div class="colourband" id="assembler">
			<h2>The Assembler</h2>
		</div>

		<div class="cbox">
			<h2>Introduction</h2>

			<ol>
				<li><a href="#ass-1">Microprocessors</a></li>
				<li><a href="#ass-2">Register Transfer Language</a></li>
				<li><a href="#ass-3">Assembly</a></li>
			</ol>

			<h2 id="ass-1">Microprocessors</h2>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						CPU.
					</p>
				</div>
				<div>
					<p>
						The CPU controls, and performs instructions. It is housed on a chip - the microprocessor.
					</p>

					<p>
						The CPU will continuously perform an instruction cycle - the <b>FDE Cycle</b>. Note: one FDE cycle will take <i>several</i> clock ticks. 
					</p>

					<p>
						It contains the following components:
					</p>

					<ul>
						<li>ALU - does calculations</li>
						<li>CU - decodes and handles logic</li>
						<li>PC - memory address tracking</li>
						<li>IR (Instruction Reg.), MAR (Mem. Address Reg.), and MDR/MBR (Mem. Data Reg.)</li>
					</ul>
				</div>

				<div>
					<p class="ir">
						FDE Cycle.
					</p>
				</div>
				<div>
					<div class="columncontainer" style="grid-column-gap: 20px">
						<div>
							<p style="text-decoration: underline;">Fetch</p>
							<ul>
								<li>Taking an address from the PC</li>
								<li>Retrieving instruction</li>
								<li>Storing in IR</li>
								<li>Incrmenting PC</li>
							</ul>
						</div>
						<div>
							<p style="text-decoration: underline;">Decode</p>
							<ul>
								<li>Decode operation</li>
								<li>Read address to establish opcode type</li>
							</ul>
						</div>
						<div>
							<p style="text-decoration: underline;">Execute</p>
							<ul>
								<li>Execute instruction</li>
								<li>This will depend on the instruction being executed</li>
							</ul>
						</div>

					</div>
				</div>

				<div>
					<p class="ir">
						Worked Example - <b>the programmer's model</b>.
					</p>
				</div>
				<div>
					<p>
						In 132, we take the 68008 (68K) architecture as our base architecture to work from. Do note that this is a specific architecture, and questions in the exam will not consider a specific architecture.
					</p>

					<p>
						We have what's called a <i>programmer's model</i> to represent this, which is a commonly used abstraction. 
					</p>

					<img src="ass/programmers-model.svg" style="max-width: 100%">

					<p>
						Internal registers are 32 bits wide, internal data buses however are 16 bits wide (<i>which means to move 32 bits of data takes 2 clock cycles</i>). The 68008 has an 8 bit external data bus, and a 20 bit address bus.
					</p>
				</div>

				<div>
					<p class="ir">
						On Data.
					</p>
				</div>
				<div>
					<p>
						The data registers \(D_0 - D_7\) are <i>on-chip</i>, meaning that they are very fast. (Technically, only 1 register is needed, but it is helpful to have more for intermediate steps).
					</p>

					<p>
						This is a <i>16 bit</i> architecture, where the registers store the following data types (and lengths):
					</p>

					<ul>
						<li>LONG - 32 bits</li>
						<li>WORD - 16 bits</li>
						<li>SHORT - 8 bits</li>
					</ul>
				</div>

				<div>
					<p class="ir">
						The <b>S</b>tatus <b>R</b>egister (The CCR).
					</p>
				</div>
				<div>
					<p>
						This register actially consists of 2 registers, and the bits stored here are <i>flags</i>. We don't usually touch the system flags, so they'll be omitted. The user flags will be explained below.
					</p>

					<img src="ass/sr.svg" style="width: 400px; max-width: 100% ">

					<ul>
						<li>C - Carry</li>
						<li>V - Overflow</li>
						<li>Z - Zero</li>
						<li>N - Negative</li>
						<li>X - Extend</li>
					</ul>

					<p>
						Flags are used for control sequences in assembly.
					</p>
				</div>

				<div>
					<p class="ir">
						On Addresses.
					</p>
				</div>
				<div>
					<p>
						Registers \(A_0 - A_6\) are <i>pointer registers</i> - they point to memory addresses.
					</p>

					<p>
						\(A_7\) is the <i>system stack pointer</i>, which is a special pointer which can hold subroutine return addresses. Additionally, the stack pointer points to the next free location in the system stack (LiFo). 
					</p>

					<p>
						Address operations do not alter the CCR. Only the ALU can incur changes in it. 
					</p>

					<P>
						The PC is a 32 bit register that points to the next instruction. 
					</P>
				</div>

				<div>
					<p class="ir">
						CPU Diagram.
					</p>
				</div>
				<div>
					<img src="ass/diagram.svg" style="max-width: 100%; display: block; margin-left: auto; margin-right: auto;">
				</div>


			</div>

			<h2 id="ass-2">Register Transfer Language</h2>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						Definition.
					</p>
				</div>
				<div>
					<p class="blue">
						<b>RTL</b>, or <b>R</b>egister <b>T</b>ransfer <b>L</b>anguage is a language used to describe a single tick operation of a microprocessor as it is executing instructions 
					</p>

					<p>
						Example: <code>[MAR] <- [PC]</code>
					</p>

					<p>
						Main Memory in RTL is MS (Main Store), so memory location 12345 would be <code>[MS(12345)]</code>
					</p>
				</div>

				<div>
					<p class="ir">
						FDE Instruction in RTL.
					</p>
				</div>
				<div>
					<p>
						Here is an example of RTL for an instruction. <i>(Not considering inst. pipelining, which is an optimisation method)</i>
					</p>

					<div class="columncontainer ctwo" style="grid-column-gap: 20px">
						<div>
							<p>Fetch</p>
							<ol>
								<li>PC to MAR, increment PC</li>
								<li>Load MBR from external mem. (R/¬W set to read)</li>
								<li>Opcode to IR from MBR</li>
								<li>CU to Decode from IR</li>
							</ol>
						</div>
						<div>
							<p>RTL</p>
							<ol>
								<li><code>[MAR] <- [PC]</code></li>
								<li><code>[PC] <- [PC] + 1</code></li>
								<li><code>[MBR] <- [MS(MAR)]</code></li>
								<li><code>[IR] <- [MBR]</code></li>
								<li><code>CU <- [IR(opcode)]</code></li>
							</ol>
						</div>
					</div>

					<p>
							Fetch is the same for every cycle ever. Execute varies depending on instruction. Suppose we want to add a constant to \(D_0\);
					</p>

					<p>RTL for adding a constant (Execute)</p>

					<ol>
						<li><code>[MAR] <- [PC]</code></li>
						<li><code>[PC] <- [PC] + 1</code></li>
						<li><code>[MBR] <- [MS([MAR])]</code></li>
						<li><code>ALU <- [MBR] + [D0]</code></li>
						<li><code>[D0] <- ALU</code></li>
					</ol>
				</div>
			</div>

			<h2 id="ass-3">Assembly</h2>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						
					</p>
				</div>
				<div>
					<p>
						Lowest level programming language before machine code. 
					</p>

					<p>
						Path goes 「 High level → Compiler → Assembly → Compiler → Machine Code → Microprocessor 」. C is the lowest of the high level languages.
					</p>

					<p>
						Assembly has a 1:1 conversion to binary machine code. Assembly is more readable. Standard format of <code>[label]: &lt;opcode&gt; &lt;operands&gt;&emsp;| comment</code>. For example:
					</p>

					<p>
						<code>START: move.b #5 D0 &emsp; | Load D0 with 5</code>
					</p>

					<p>
						Or, for a bigger block of code;
					</p>

					<button class="collapsible">Expand...</button>
					<div class="ccontent">
	<div class="codediv">	ORG 	$4B0    | starts at hex 4B0
		move.b 	#5, D0   	| load D0 with 5
		add.b 	#$A, D0 	| Add 10 to D0
		move.b  D0, ANS 	| Store result in ANS

ANS:	DS.B 	1 			| allocate 1 byte of memory 
					| and give name ANS
</div>
</div>
				</div>
			</div>


					


			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						
					</p>
				</div>
				<div>
					<p>
						There are three suffixes to move, <code>.b</code> byte, <code>.w</code> word, <code>.l</code> long.
					</p>
				</div>

				<div>
					<p class="ir">
						Moving Longs.
					</p>
				</div>
				<div>
					<p>
						Longs are twice as long as a bus can move. There are multiple methods to move longs. One good to know method is <b>big endian</b>, where the biggest bytes are moved first. 
					</p>
				</div>

				<div>
					<p class="ir">
						Addressing Modes.
					</p>
				</div>
				<div>
					<p>
						Addressing modes tell what type of data operands are. They can be <i>constants, data structures,</i> or <i>variables</i>
					</p>

					<p>
						The 68k has the addressing modes <code>DIR</code>ect or DATA, <code>IMM</code>ediate, <code>ABS</code>olute, <code>A</code>ddress <code>R</code>egister <code>I</code>mmediate, and <code>REL</code>ative. 
					</p>

					<p>
						Direct points to a register; immediate means a constant; absolute means an explicit memory address <i>(shouldn't be used)</i>; ARI means accessing memory addresses stored in address registers; and relative takes an address and a constant, and accesses memory at that address + a constant offset. 
					</p>
				</div>
			</div>
		</div>

		<div class="colourband" id="memsys">
			<h2>Memory Systems</h2>
		</div>

		<div class="cbox">
			<h2>Introduction</h2>

			<ol>
				<li><a href="#mem-1">Memory Heirarchy</a></li>
				<li><a href="#mem-2">Memory Cell Organisation</a></li>
				<li><a href="#mem-3">Common Memory Components</a></li>
			</ol>

			<h2 id="mem-1">Memory Heirarchy</h2>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						
					</p>
				</div>
				<div>
					<p>
						There are many factors affecting memory technology
					</p>

					<ul>
						<li>Frequency of access</li>
						<li>Access time</li>
						<li>Capacity</li>
						<li>Cost per bit</li>
					</ul>

					<p>
						Ideally we want to have low cost, high capacity, and high performance memory, but as the adage goes: "pick two" but sometimes even only one.
					</p>
				</div>

				<div>
					<p class="ir">
						Memory Organisation.
					</p>
				</div>
				<div>
					<p>
						Closest to the CPU we have low capacity, expensive, <i>very</i> fast memory, and furthest externally we have high capacity, low cost but slow memory. From the CPU,
					</p>

					<ul>
						<li>Registers</li>
						<li>Cache</li>
						<li>Main Store <i>(RAM)</i></li>
						<li>Magnetic Disk <i>(Sequential AM)</i></li>
						<li>Optical Disk / Magnetic Tape</li>
					</ul>
				</div>

				<div>
					<p class="ir">
						Reasons for Organisation.
					</p>
				</div>
				<div>
					<p>
						Mostly economics. Also, because of small loops, array optimisation, data structures, etc, memory access locations are rather predictable. 
					</p>

					<p>
						<b>Temporal locality:</b> if a particular location is accessed, it is likely to be referenced again in the near future.
					</p>

					<p>
						<b>Spatial locality:</b> if a location is referenced, it is likely that nearby locations will be referenced soon. 90% of locations are within +/- 2 KB of a referenced location. 
					</p>
				</div>

				<div>
					<p class="ir">
						Cache Memory.
					</p>
				</div>
				<div>
					<p>
						Because of the 90% principle, we should probably store those 2 KB in cache. 
					</p>

					<p>
						Cache is much much closer to the CPU than MS, and comes in 3 levels, (smallest, quickest) L1, L2, L3 (largest, slowest), and is on the CPU chip itself. They are all relatively small though to limit cost. 
					</p>

					<p>
						If required data is found in cache, it is referred to as a <b>cache hit</b>. This is a big speed improvement from accessing MS. For reference, L1 cache is ~0.5 ns, L2 cache is ~7 ns, and MS is ~100 ns. 
					</p>
				</div>

				<div>
					<p class="ir">
						Moore's Law.
					</p>
				</div>
				<div>
					<p>
						Summed: <i>"The number of transistors in a chip doubles every 18 months"</i>. Moore's law is now starting to be broken, as clock speeds have flattened, but now core counts are increasing. 
					</p>
				</div>

				<div>
					<p class="ir">
						Relevance to Cache?
					</p>
				</div>
				<div>
					<p>
						We have cache because whilst memory <i>capacity</i> has increased á'la Moore's law, however memory <i>speed</i> hasn't really. 
					</p>
				</div>

				<div>
					<p class="ir">
						Cache Concepts.
					</p>
				</div>
				<div>
					<p>
						Caching Read-Only data is fairly straightforward. Does not need to consider changing copies across memory hierarchy, relatively consistent. 
					</p>

					<p>
						For caching writes, though, there are two main strategies.
					</p>

					<p>
						<b>Write Through.</b> updates item in cache and write-through to update lower levels of the memory heirarchy.
					</p>

					<p>
						<b>Write Back.</b> only update in cache and copy back to MS only when retiring. 
					</p>
				</div>

				<div>
					<p class="ir">
						Cache Misses and Performance. 
					</p>
				</div>
				<div>
					<p>
						We measure the performance of a cache with <i>hit rate</i> (\(h\)) and <i>miss rate</i> (\(1-h\)), and hit rate is calculated as:

						\[h = \frac{\# \textrm{ times words are in cache}}{\textrm{Total } \# \textrm{ memory references}}\]

						There are many categories for misses to go in.
					</p>

					<ul>
						<li>
							<B>Compulsory.</B> which would occur regardless of cache size, such as the first access block for a new application.
						</li>

						<li>
							<b>Capacity.</b> when cache is not hard enough for all blocks needed. 
						</li>

						<li>
							<b>Conflict.</b> which occurs as a result of placement <i>strategy</i> of blocks which are not fully associative - blocks may be discarded and retrieved.
						</li>

						<li>
							<b>Coherency.</b> which occur due to cache flushes in <i>multicore</i> systems.
						</li>
					</ul>

					<p>
						We can also measure performance with <i>average memory access time</i>, \(a\) defined as

						\[a = h + mp\]

						Where \(p\) is a given penalty constant. 
					</p>
				</div>

				<div>
					<p class="ir">
						Multilevel Caches.
					</p>
				</div>
				<div>
					<p>
						Basically, CPU ⇄ L1 Cache ⇄ L2 Cache ⇄ L3 Cache ⇄ MS. The L1 cache is the most often used, and is the quickest. 
					</p>

					<p>
						Memory is often a bottleneck in speed - we want faster memory but faster memory is smaller, otherwise it would be egregiously expensive. We can't then use the fastest memory for everything, since large data sets may not be stored entirely. 
					</p>

					<p>
						A solution to this is prefetching data to mask loading times, and reuse data as much as possible.
					</p>
				</div>
			</div>

			<h2 id="mem-2">Memory Cell Organisation</h2>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						Main Store Memory.
					</p>
				</div>
				<div>
					<p>
						We call main store RAM, but there are two types of RAM: <b>S</b>RAM (Static) and <B>D</B>RAM (Dynamic).
					</p>

					<p>
						SRAM uses a single flip flop per bit, kinda like what we've seen before. DRAM however uses the presence or absence of charge in a capacitor. Since this charge leaks over time, a circuit is needed to refresh it periodically.
					</p>

					<p>
						DRAM is cheaper in SRAM.
					</p>
				</div>

				<div>
					<p class="ir">
						SRAM.
					</p>
				</div>
				<div>
					<p>
						A typical cell uses 4 <i>coupled</i> transistors for a stable logic gate. (There are 6 transistors in total). 
					</p>
				</div>

				<div>
					<p class="ir">
						DRAM.
					</p>
				</div>
				<div>
					<p>
						Has a single transistor and capacitor, which makes it more dense-able.
					</p>
				</div>

				<div>
					<p class="ir">
						Organisation.
					</p>
				</div>
				<div>
					<p>
						The memory cell is the basic element of memory. It takes a \(R / \bar{W}\) input, a SELECT input, and a DATA I/O. When RW is low, data is accepted in from the DATA line, whilst when RW is high, the bit stored is sent on the data line. 
					</p>

					<p>
						Memory cells are arranged in grids <i><a href="http://edu.cs.tut.fi/pd2006/lecture4/memarray.jpg">(Temp Figure)</a></i>, much like original core memory, with a decoder between the address bus and the memory setup. 
					</p>
				</div>

				<div>
					<p class="ir">
						Choices in Organisation.
					</p>
				</div>
				<div>
					<p>
						If we have a 16 by 8 grid, then we have 128 cells, with 4 address lines and 8 data lines. 
					</p>

					<p>
						A 1 kb device, could have a 128 by 8 grid arrangement, which would require 7 address pins, and in total 15 I/O pins including data, R/W, etc. 
					</p>

					<p>
						A poor design would be something like 1024 by 1, since then you need a lot of address pins, and it is inefficient. We generally want to minimise memory cell space.
					</p>
				</div>

				<div>
					<p class="ir">
						Minimising Space.
					</p>
				</div>
				<div>
					<p>
						Naturally, the most cell for room is a square. However we can't just have one massive chonky square, but we can extend the idea with individual cells to organising arrays of cells. <!--Index Rows, Index COlumns, see minimising space in notes.-->
					</p>
				</div>

				<div>
					<p class="ir">
						Noise.
					</p>
				</div>
				<div>
					<p>
						Noise is unwanted interference to our signal, and from a source to a destination there is always noise. This noise can come from all over, such as thermal noise, noise from electric components, etc. This is why in digital logic we have a forbidden zone, as mentioned in the first section. (Granted, if the noise gets too large this buffer also becomes useless.)
					</p>
				</div>

				<div>
					<p class="ir">
						Detecting single, isolated errors.
					</p>
				</div>
				<div>
					<p>
						Single, isolated errors are considered to occur at random. There are several methods to detect and/or correct these isolated errors. We could:
					</p>

					<ul>
						<li>Send a message three times and use majority rule. However this is very expensive and costly data wise.</li>
						<li>If the probability of an error is very low, then the probability of two errors is even lower. So we could use <i>parity bitting</i>.</li>
					</ul>
				</div>

				<div>
					<p class="ir">
						Parity bits.
					</p>
				</div>
				<div>
					<p>
						Note how ASCII is a 7 bit system, but is always displayed in blocks of 8 bits. This is because the 8th bit is a <b>parity</b> bit, which flips depending on how many 1s is in the binary string. 
					</p>

					<p>
						<b>Even</b> parity tries to make the overall string have an even number of 1s: \(\underline{0}1000001\). <b>Odd parity</b> does the opposite: \(\underline{1}1000001\).
					</p>

					<p>
						We can calulate parity bit in hardware via finite state machines. 
					</p>

					<figure>
						<figcaption><i>(diagram pending)</i></figcaption>
					</figure>

					<p>
						In hardware, it just so happens that we can XOR all the bits together with a "dummy" parity bit (0) to work out the result. 
					</p>
				</div>

				<div>
					<p class="ir">
						Error Checking with Parity.
					</p>
				</div>
				<div>
					<p>
						When the receiver receives data, they
					</p>

					<ul>
						<li>Compute a new parity bit from the message received (excluding original parity bit)</li>
						<li>Compare new bit against original parity bit, if they are different then ask for retransmission</li>
					</ul>

					<p>
						However, this doesn't work if there is more than one error. It is inadequate in dealing with <i>burst errors</i>. A solution to this is to compute a further checksum over numtiple bytes.
					</p>
				</div>

				<div>
					<p class="ir">
						Dealing with Burst Errors. 
					</p>
				</div>
				<div>
					<p>
						<div class="columncontainer ctwo" style="column-width: 20px; grid-template-columns: 2fr 1fr;">
							<div>
								<ul>
									<li>Compute bit <i>column</i> parity checksum values - this comes out as 100 1001 (K)</li>
									<li>Send "MessageK" instead of "Message"</li>
									<li>This will detect all burst errors under 14 bits</li>
									<li>However, it <b>cannot</b> detect an even number of errors in a single column</li>
									<li>This can be extended to character parity as well as column parity</li>
									<li>This has the ability to not only identify that there is an error, but also <i>what</i> and <i>where</i> the error is - so we can <b>correct</b> it.</li>
								</ul>
							</div>
							<div>
								<img src="mem/bursty.png" style="max-width: 100%; width: 257px;">
							</div>
						</div>
					</p>
				</div>
			</div>

			<h2 id="mem-3">Common Memory Components</h2>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						HDDs.
					</p>
				</div>
				<div>
					<p>
						HDDs are stacked magnetic disks, (double sided) which are read using a magnetic read/write head, which moves across the disk which spins. 
					</p>

					<p>
						Data is stored on radial tracks, made up of sectors, with inter-sector gaps between them. On old disks, there are the same number of sectors on each radial track - meaning that the outer sectors are less space efficient, whereas newer disks will have more sectors as you near the outside of the disk. 
					</p>

					<p>
						Performace issues can arise because of moving parts, which makes HDDs more likely to fail than SSDs. 
					</p>
				</div>

				<div>
					<p class="ir">
						Optical Disks.
					</p>
				</div>
				<div>
					<p>
						Optical disks have a spiral track, and has a laser read head. Optical disks work off multiple methods - one of which is where the disk has pits and bumps, and the way laser light is reflected will encode information. Other disks (read/write ones) use dyes.
					</p>

					<p>
						Data is often written more than once, which adds resilience to scratches and damage. 
					</p>
					<p>
						Optical disks have a very slow seek time - 10x slower than HDDs. 
					</p>
				</div>
			</div>
		</div>

		<div class="colourband" id="iomech">
			<h2>IO Mechanisms</h2>
		</div>

		<div class="cbox">
			<h2>Introduction</h2>

			<ol>
				<li><a href="#io-1">Memory-Mapped IO</a></li>
				<li><a href="#io-2">Polling</a></li>
				<li><a href="#io-3">Handshaking</a></li>
				<li><a href="#io-4">Interrupts</a></li>
			</ol>

			<h2 id="io-1">Memory-Mapped IO</h2>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						Definition.
					</p>
				</div>
				<div>
					<p>
						Same address system for both memory and IO devices. IO devices are assigned their own memory address.
					</p>
				</div>

				<div>
					<p class="ir">
						Advantages.
					</p>
				</div>
				<div>
					<ul>
						<li>Simpler tham many alternatives</li>
						<ul>
							<li>Especially compared to <i>port-mapped IO</i>, which requires special extra instructions.</li>
							<li>CPU Requires less logic</li>
						</ul>
						<li>Uses existing (general purpose and memory) instructions.</li>
					</ul>
				</div>

				<div>
					<p class="ir">
						Disadvantages.
					</p>
				</div>
				<div>
					<ul>
						<li>Requires giving up existing memory.</li>
						<ul>
							<li>This is not a concern with 64 bit addresses.</li>
							<li>Is slightly more of a concern with 32 or 16 bit, or embedded systems.</li>
						</ul>
					</ul>
				</div>
			</div>

			<h2 id="io-2">Polling</h2>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						
					</p>
				</div>
				<div>
					<p>
						<i>"Synchronising with IO devices"</i>
					</p>

					<p>
						Most IO devices are much slower than the CPU. Creates a problem with syncing between them. 
					</p>

					<p>
						Need methods to check for <i>Read - </i>is there data to be read, and <i>Write -</i> is device ready to accept data.
					</p>
				</div>

				<div>
					<p class="ir">
						Busy Write.
					</p>
				</div>
				<div>
					<div class="columncontainer ctwo" style="column-width: 20px; grid-template-columns: 2fr 1fr;">
						<div>
							<ul>
								<li>Constant checking</li>
								<li>Kind of inefficient</li>
								<li>Lots of redundant processing</li>
							</ul>

							<p>
								Requires only simple hardware (support only for "ready"), and simple software (simple loop and check). 
							</p>

							<p>
								However wastes CPU time, thus wasing power.
							</p>
						</div>
						<div>
							<img src="io/busywrite.svg" style="max-width: 100%">
						</div>
					</div>
					
				</div>

				<div>
					<p class="ir">
						Interleaved Write.
					</p>
				</div>
				<div>
					<div class="columncontainer ctwo" style="column-width: 20px; grid-template-columns: 2fr 1fr;">
						<div>
							<ul>
								<li>Almost always better method for general systems.</li>
								<li>Unless it is a single task system - or critical systems.</li>
							</ul>

							<p>
								Doesn't waste CPU time as much, but can lead to delayed response. 
							</p>

							<p>
								Fine for some situations but really bad if there is a <i>hard</i> real time comtext (next imput <i>really depends</i> on previous one).
							</p>
						</div>
						<div>
							<img src="io/interwrite.svg" style="max-width: 100%">
						</div>
					</div>
				</div>
			</div>

			<h2 id="io-3">Handshaking</h2>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						
					</p>
				</div>
				<div>
					<p>
						Ways of solving timing problems.
					</p>
				</div>

				<div>
					<p class="ir">
						Types
					</p>
				</div>
				<div class="columncontainer" style="grid-column-gap: 20px;">
					<div>
						<p style="text-align: center;">Unsynched</p>

						<p>
							<i>System just sends data to IO device.</i>
						</p>
					</div>
					<div>
						<p style="text-align: center;">Open-Ended</p>

						<p>
							<i>Systems sends data to IO device, then asserts its validity. IO device manages the rest.</i>
						</p>
					</div>
					<div>
						<p style="text-align: center;">Closed-loop <i>(proper one)</i></p>

						<p>
							<i>Like prior but IO device asserts readiness to receive.</i>
						</p>
					</div>
				</div>

				<div>
					<p class="ir">
						Timing Diagram.
					</p>
				</div>
				<div>
					<p>
						Below is an example timing diagram - the actual numbered timings are not important, just note the delay in timing.
					</p>

					<figure>
						<img src="io/handshake.png" style="max-width: 352px; width: 100%; margin-left: auto; margin-right: auto; display: block;">
						<figcaption><i>Handshaking Diagram (<a href="http://www.interfacebus.com/Glossary-of-Terms-Handshaking-Protocol.html">Electronic Engineering Dictionary</a>)</i></figcaption>
					</figure>
				</div>

				<div>
					<p class="ir">
						Hardware Implementations.
					</p>
				</div>
				<div>
					<p>
						Usually done with proprietary chips. Sometimes there is an interface chip, and the CPU interfaces with software, whilst the chip does the actual work. 
					</p>
				</div>
			</div>

			<h2 id="io-4">Interrupts</h2>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						Overview.
					</p>
				</div>
				<div>
					<ul>
						<li>Comes in two types, <code>IRQ</code> (interrupt request) and <code>NMI</code> (non-maskable interrupt.</li>
						<li>Interrupts are <b>asynchronous</b>.</li>
						<li>IRQ interrupts can be refused/ignored in code, based on the priority level it comes with. NMIs however, are <i>never</i> ignored.</li>
						<li>However, if ignored enough, an IRQ <i>can</i> become an NMI.</li>
					</ul>
				</div>

				<div>
					<p class="ir">
						Effect.
					</p>
				</div>
				<div>
					<p>
						When an interrupt is received in code, it immediately halts and performs the following steps in order:
					</p>

					<ol>
						<li>Save state of working registers</li>
						<li>Service the interrupt</li>
						<li>Restore registers</li>
					</ol>

					<p>
						Whereupon the program will continue where it left off. 
					</p>

					<p>
						The CPU uses a stack structure to store and restore register states. 
					</p>

					<p>
						(In more detail) Upon <b>receiving</b> an interrupt:
					</p>

					<ol>
						<li>CPU completes the current instruction</li>
						<li>Push current PC onto stack</li>
						<li>Push Status Register(s) onto stack</li>
						<li>Load to PC the address of the interrupt handler</li>
						<li>Handle the interrupt handler</li>
					</ol>

					<p>
						Upon <b>returning</b> from being interrupted:
					</p>

					<ol>
						<li>Pop PC from stack <i>(Not necessarily the same stack!)</i></li>
						<li>Pop SR(s)</li>
						<li>Load PC with original address</li>
					</ol>

					<p>
						(2, 3) in receiving and returning are termed <b>context switches</b>.
					</p>
				</div>

				<div>
					<p class="ir">
						Nested Interrupt.
					</p>
				</div>
				<div>
					<p>
						Interrupts can be nested within interrupts, but <i>only if</i> the nested interrupt is of a <i>higher</i> priority or an NMI. A lower priority interrupt can and will get masked away. 
					</p>
				</div>

				<div>
					<p class="ir">
						Interrupts for IO. 
					</p>
				</div>
				<div>
					<ul>
						<li>Switches can be connected to IRQs.</li>
						<li>Hard drives can interruppt when requested data is ready to send.</li>
						<li>A timer can generate an IRQ at a set time interval.</li>
						<li>The printer can send an IRQ when ready to receive next character to print.</li>
					</ul>
				</div>

				<div>
					<p class="ir">
						Advantages (of Interrupts).
					</p>
				</div>
				<div>
					<ul>
						<li>Fast response</li>
						<li>No wasted CPU time / power</li>
					</ul>
				</div>

				<div>
					<p class="ir">
						Disadvantages.
					</p>
				</div>
				<div>
					<ul>
						<li>All data transfers are controlled by the CPU</li>
						<li>Interrupts are more complex both hardware and software wise</li>
					</ul>

					<p>
						There is, unfortunately, no best solution.
					</p>
				</div>
			</div>

			<h2 id="io-5">Direct Memory Access</h2>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						Overview.
					</p>
				</div>
				<div>
					<p>
						Direct Memory Access is often abbreviated to <b>DMA</b>.
					</p>

					<ul>
						<li>Often, the CPU is the bottleneck of all IO. A DMA controller (DMAC) is used where a large amount of data needs to be transferred at high speed.</li>
						<li>It is specialised and optimised for this, whereas the CPU is general purpose.</li>
						<li>The control of the system bus is relinquished to the DMAC when required.</li>
						<li>DMA IO can be 10 times faster.</li>
					</ul>

				</div>

				<div>
					<p class="ir">
						How It Works.
					</p>
				</div>
				<div>
					<ul>
						<li>DMA transfer request from IO</li>
						<li>DMA passes to CPU</li>
						<li>CPU initialises DMAC:</li>
						<ul>
							<li>Whether In/Out?</li>
							<li>The start ADRS sent to DMAC ADRS register</li>
							<li>The number of words to the count register</li>
							<li>DMAC is enabled</li>
						</ul>
						<li>DMAC requests the use of system buses</li>
						<li>CPU responds with acknowledgement when ready</li>
					</ul>

					<p>
						There are two modes of operation.
					</p>

					<p>
						<b>Cycle Stealing:</b> The DMAC uses sstem buses when the CPU is not using them. I.e. "stealing CPU downtime."
					</p>

					<p>
						<b>Burst Mode:</b> For when system buses are required for an extended transfer, the DMAC locks the CPU out of the buses for a fixed time - or whatever the device decides if it has high enough priority.
					</p>
				</div>

				<div>
					<p class="ir">
						Organisation of DMAs.
					</p>
				</div>
				<div>
					<p>
						<b>Single bus detatched DMA</b> is where all modules share the <i>same</i> SYS bus, and implement it similarly. It's simple but inefficient. Each word transfer takes 2 cycles.
					</p>

					<p>
						<b>IO Bus</b> has a dedicated IO bus which connects the DMA to IOs only. More complicated. 
					</p>
				</div>
			</div>
		</div>

		<div class="colourband" id="architecture">
			<h2>Microprocessor Architecture</h2>
		</div>

		<div class="cbox">
			<h2>Introduction</h2>

			<ol>
				<li><a href="#arc-1">Microprocessor Organisation</a></li>
				<li><a href="#arc-2">Instructions and Control Symbols</a></li>
			</ol>

			<h2 class="arc-1">Microprocessor Organisation</h2>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						Organisation vs Architecture.
					</p>
				</div>
				<div>
					<p>
						The arcitecture concerns the sturcture and properties in an abstract form (from perspective of a software engineer), whereas organisation is a perspective from a hardware engineer.
					</p>

					<p>
						Note that a lot of this topic goes through the PATP architecture, which is not specifically examined. Notes will be brief. <i>PATP is a series of PDFs created by Matthew Leeke of Warwick University.</i>
					</p>
				</div>

				<div>
					<p class="ir">
						PATP 1.
					</p>
				</div>
				<div>
					<p>
						<a href="patp/1.pdf" class="text">PDF.</a> Shows overall structure, and brief instruction set (<a href="patp/is.pdf" class="text">More detailed instruction set PDF</a>). Z is a clear/0 flag.
					</p>
				</div>

				<div>
					<p class="ir">
						PATP 2.
					</p>
				</div>
				<div>
					<p>
						<a href="patp/2.pdf" class="text">PDF.</a> Assembly examples.
					</p>
				</div>

				<div>
					<p class="ir">
						Building Blocks.
					</p>
				</div>
				<div>
					<div class="columncontainer ctwo" style="grid-column-gap: 20px; grid-template-columns: 2fr 1fr">
						<div><p>
							<b>Registers</b>, for which we have D latch registers.
						</p></div>
						<div>
							<img src="patp/register.svg" style="max-width: 100%">
						</div>
					</div>
					<div class="columncontainer ctwo" style="grid-column-gap: 20px; grid-template-columns: 2fr 1fr">
						<div><p>
							<b>The ALU</b>, recall N-bit binary adders for internals.
						</p></div>
						<div>
							<img src="patp/ALU.svg" style="max-width: 100%">
						</div>
					</div>

					<p>
						<b>Buses and 3 state buffers</b> are required. 
					</p>

					<p>
						Finally, the <b>Control Unit</b>, which regulates the FDE cycle, and runs at/near the microprocessor clock speed. It needs to be aware of the status/CCR register <i>(Z)</i>, and also decodes opcodes. For simplicity, the CU can be treated as a black box.
					</p>
				</div>

				<div>
					<p class="ir">
						PATP 3.
					</p>
				</div>
				<div>
					<p>
						<a href="patp/3.pdf" class="text">PDF.</a> shows a system implementation. Note the ALU has its own register, clocks and enables not shown. 
					</p>

					<p>
						All inputs are unbuffered, but nothing will happen until clock go bloop.
					</p>
				</div>
			</div>

			<h2 id="arc-2">Instructions and Control Signals</h2>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						Intro.
					</p>
				</div>
				<div>
					<p>
						At this moment we have nothing to process instructions. The CU has to retrieve an opcode, and map it to a sequence of control signals such that the opcode is executed.
					</p>

					<p>
						<b>Microinstructions</b> are the control signals that make up <b>macro</b> (opcode) instructions.
					</p>
				</div>

				<div>
					<p class="ir">
						PATP 4、5.
					</p>
				</div>
				<div>
					<p>
						<a href="patp/4.pdf" class="text">PDF.</a> Shows a breakdown of micro and control steps for carrying out macro instructions. PATP 5 (<a href="patp/5.pdf" class="text">PDF.</a>) shows more examples.
					</p>
				</div>

				<div>
					<p class="ir">
						Control Steps.
					</p>
				</div>
				<div>
					<p>
						Shows the clock step the microinstruction is performed on. Several microinstructions are able to be performed on the same clock tick (if they don't overlap / interfere), under <i>reasonable</i> step timing setups. 
					</p>
				</div>
			</div>
		</div>
		

		<footer>
			<div class="cbox">
				<div class="columncontainer ctwo">
					<div>
						<p class="small">
							© 2020-2021 Yijun Hu, all rights reserved.
						</p>
					</div>
					<div>
						<p class="small rj">
							Designed by Yijun Hu
						</p>
					</div>
				</div>
			</div>
		</footer>

	</div>

	<script type="text/javascript" src="../../js/collapsible.js"></script>  <!--This stays at the end-->
	<script type="text/javascript" src="../../js/toggle-darklight.js"></script>
</body>
</html>