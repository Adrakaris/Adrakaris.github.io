<!DOCTYPE html>
<html>
<head>
	<title>CS132</title>
	<meta charset="utf-8">
	<link rel="stylesheet" type="text/css" href="../../style/style.css" media="all">  
	<meta name="viewport" content="width=device-width" initial-scale=1.0> 
	<link rel="icon" type="image/png" href="../../style/images/DragonIcon.png">
	<script type="text/javascript" src="../../js/goback.js"></script>
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

	<div class="hidden">
		<header>
			<div class="parallax parsmaller">
				<div class="columncontainer cthreeside">
					<div class="column tinycolumn">
						<a href="../../about.html" class="nav">About</a>
						<!--<button onclick="goBack()" class="nav">Back</button>-->
					</div>
					<div class="column tinycolumn">
						<a href="../../blog.html" class="nav">Back</a>
					</div>
					<div class="column tinycolumn">
						<a href="./index.html" class="nav"><!--Link--></a>
					</div>
				</div>
				<div class="cbox"> 		
					<h1>CS132</h1>
					<p class="subheading">Computer Systems and Architecture</p>
				</div>
			</div>
		</header>

		<header>
			<div class="cbox">
				<h1>Contents</h1>
			</div>
		</header>

		<div class="cbox">
			<ol>
				<li><a href="#datarep">Data Representation</a></li>
				<li><a href="#logic">Digital Logic</a></li>
			</ol>
		</div>

		<div class="colourband" id="datarep">
			<h2>Data Representation</h2>
		</div>

		<div class="cbox">

			<p>
				<i>Editor's note:</i> Since data rep is a topic covered fairly extensively in GCSE and A level CS, these notes will be brief.
			</p>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						Representations and Binary.
					</p>
				</div>
				<div>
					<p>
						Numbers can be represented in many different ways (decimal, octal, etc) but we most often use binary when dealing with computer systems.
					</p>

					<p>
						Computers work with transistors, and <b>TTL</b> (transistor-transistor logic) works over voltages. Transistors work over a range of about five volts, and we assign the range 0 - 0.8V as 0 and 2.4 - 5V as 1 (and a forbidden zone in the middle), which gives us binary values. 
					</p>

					<p>
						The reason we do this is to achieve something called <b>noise immunity</b>, where natural fluctuations in voltage won't affect the bits.
					</p>
				</div>
			</div>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						Mathematical Operators.
					</p>
				</div>
				<div>
					<p>
						Do recall that overflow exists when working in binary. 
					</p>

					<p>
						We can (fairly) easily make a circuit that adds two binary numbers. However what do we do for subtraction? We could either build a subtractor, or easier find a way to represent negative binary numbers. How about working with decimal numbers.
					</p>
				</div>

				<div>
					<p style="font-style: italic; text-align: right;">
						(Negatives) Signed Magnitude
					</p>
				</div>
				<div>
					<p>
						The largest bit of a binary number acts as the <i>sign</i>, a "flag" which is 1 if the number is negative and 0 if the number is positive;
						\[1101_{2SM} = -1 \times (4 + 0 + 1) = -5.\]
						This can represent numbers in the range \([-2^{n-1}, 2^{n-1}]\), for \(n\) bits.
					</p>
				</div>

				<div>
					<p class="ir">
						(Negatives) Two's Complement
					</p>
				</div>
				<div>
					<p>
						The more commonly used, two's complement is where the largest bit is a negative number;
						\[1101_{2TC} = -8 + 4 + 0 + 1 = -3.\]
						Two's complement represent numbers in the range \([-2^{n-1}, 2^{n-1}-1]\), and a major advantage of two's complement is that it has no unique zero. Signed magnitude numbering has two zeros, \(1000 \equiv 0000\) which can be problematic, whilst two's complement has only \(0000\).
					</p>
				</div>

				<div>
					<p class="ir">
						(Decimals) Fixed Point
					</p>
				</div>
				<div>
					<p>
						A fixed decimal point where to the right are negative powers of two. However this is limited by accuracy (depending on where the fixed point is), nor can it represent very large numbers
					</p>
				</div>

				<div>
					<p class="ir">
						(Decimals) Floating Point
					</p>
				</div>
				<div>
					<p>
						A floating point number is represented with \( (\textrm{sign}) \textrm{ mantissa} \times 2^{\textrm{exponent}} \). One bit is allocated to the sign, a few for the exponent, and the rest for the mantissa. More bits equal more numbers that can be represented.
					</p>

					<button class="collapsible nul">IEE754...</button>
					<div class="ccontent cnul">
						<p>
							The IEEE 754 standard gives 32 bits for a single float, 64 bits for a double, and 128 bits for a quad. For a single precision float, 1 bit is the sign, 8 bits for the exponent and 23 bits for the mantissa.
						</p>
					</div>
				</div>
			</div>
		</div>

		<div class="colourband" id="logic">
			<h2>Digital Logic</h2>
		</div>

		<div class="cbox">
			<h2>Introduction</h2>

			<ol>
				<li><a href="#log-1">Basic Logic Functions</a></li>
				<li><a href="#log-2">Karnaugh Maps</a></li>
				<li><a href="#log-3">Combinatorial Logic Circuits</a></li>
				<li><a href="#log-4">Sequential Logic Circuits</a></li>
			</ol>

			<h2 id="log-1">Basic Logic Functions</h2>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						Switches and bulbs.
					</p>
				</div>
				<div>
					<p>
						We can think about logic using switches and bulbs. Below, are three diagrams of circuits, with labelled switches.
					</p>

					<img src="logic/logics.svg" style="width: 100%;">

					<p>
						Notice how from left to right, these circuits make the NOT, AND, and OR circuits. 
					</p>

					<p>
						For \(n\) inputs, there are \(2^n\) combinations of inputs, and \(2^{(2^n)}\) possible functions and outputs.
					</p>
				</div>

				<div>
					<p class="ir">
						Note on Notation.
					</p>
				</div>
				<div>
					<p>
						In 132, true and false are denoted as \(1, 0\), and the operators AND, OR, and NOT are denoted by \(A \cdot B , A+B, \bar{A}\) respectively. 
					</p>
				</div>
				<div>
					<p class="ir">
						Logic Gates.
					</p>
				</div>
				<div>
					<p>
						Logic gates and truth tables. Included only for completeness' sake.
					</p>
					<button class="collapsible">Expand for gates...</button>
					<div class="ccontent">
						<p>
							Below are images of logic gates, along with their truth tables. 
						</p>

						<img src="https://instrumentationtools.com/wp-content/uploads/2017/07/instrumentationtools.com_digital-logic-gates-truthtables.png" style="max-width: 100%">
					</div>
					<p>
						We can combine logic gates to form more complicated circuits, for example exclusive or, \(A \oplus B\)
					</p>
					<button class="collapsible">Expand...</button>
					<div class="ccontent">
						<img src="https://www.electronicshub.org/wp-content/uploads/2015/07/exor-equivalent-circuit.jpg" style="max-width: 100%">
					</div>
					
					<p>
						Note that NOT, AND and OR are <b>fundamental</b> gates, since they are the building blocks of any function.
					</p>

					<p>
						NAND and NOR are <b>universal</b> gates, since they alone can be used to make any other logic gate. 
					</p>
					

					<p>
						We often want to simplify expressions as possible, because simplifying expressions leads to less logic gates, which is cheaper. (Also, simplifying to one universal gate can also be cheaper due to economy of scale of buying only one gate.)
					</p>

					<p>
						Two main methods of simplification are <b>boolean algebra</b> and <b>Karnaugh Maps</b>. Boolean algebra is covered in <a href="../cs130/index.html#proplogic" class="text">CS130</a>, though of course do note that 132 uses different syntax. 
					</p>
				</div>
			</div>

			<h2 id="log-2">Karnaugh Maps (K-Maps)</h2>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						K-maps.
					</p>
				</div>
				<div>
					<p>
						Karnaugh maps (also called k-maps) can show unambiguously a boolean expression in its simplest form. 
					</p>

					<p>
						Look at the following table. It is a k-map for 3 variables \(A, B, C\). The top row groups AB together, and the left column displays values of C. Within the table each of the squares represent a different combination of values of A, B, C to input into a function we want to simplify.
					</p>

					<img src="logic/kmap-example.png" style="max-width: 100%;">

					<p>
						Note the ordering of AB: 00 <b>01 11</b> 10. This is <i>deliberate</i>, and with this ordering it means that to "step" from any square to any orthogonally adjacent (sides touching) square, the result will differ by <b>only one variable.</b>
					</p>
				</div>

				<div>
					<p class="ir">
						Rules.
					</p>
				</div>
				<div>
					<p>
						Usually, when you get a function, only certain squares in the grid will give an overall result of 1. We do this by a process of <b>grouping 1s</b>.
					</p>

					<p>
						Basically, in a map, you want to group adjacent ones. The groups must be <b>rectangular</b> in shape, and not have any "turns" - an L shape for example is forbidden. Furtherfore, groups must be <b>powers of two</b> in size.
					</p>

					<p>
						Groups may <b>wrap around</b> edges - like pacman. 
					</p>

					<p>
						Groups are permitted to overlap.
					</p>

					<p>
						<b>Minimum no. of groups</b>, ideally bigger size groups, make more <b>optimal solution</b>. 
					</p>

					<p>
						Then to find the simplfied equation, find only the variables that remain constant in a group, and only include that.
					</p>

					<p>
						Have a look at the example below.
					</p>
				</div>

				<div>
					<p class="ir">
						<b>Example.</b>
					</p>
				</div>
				<div class="ncontent">
					<p>
						Simplify the function \(f = AB\bar{C}D + A\bar{B}\bar{C}D + \bar{A}\bar{B}CD + \bar{A}BCD\). 
					</p>

					<div>
						<p >
							Take the following karnaugh map - note that we have to split now AB / CD.
						</p>

						<img src="logic/kmap-gr1.png" style="max-width: 100%">

						<p>
							In the red group, A remains constant 1, B changes, C remains consant 0, and D remains constant 1, therefore we get \(A \cdot \bar{C} \cdot D\). Similarly for the blue group, A remains constant 0, B changes, and C, D remain constant 1, therefore we get \(\bar{A} \cdot C \cdot D\).
						</p>
						<p>
							Thus \(f = A \cdot \bar{C} \cdot D + \bar{A} \cdot C \cdot D\)
						</p>
					</div>
				</div>

				<div>
					<p class="ir">
						Equivalences.
					</p>
				</div>
				<div>
					<p>
						It is possible to have equivalent constructions which are all the optimal solution. For example, for the following map:
					</p>

					<img src="logic/kmap-gr2.png" style="max-width: 100%">

					<p>
						The optimal solution could either comprise of red, green, and blue, or red, purple, and blue. 
					</p>
				</div>

				<div>
					<p class="ir">
						<b>Example</b> of wrapping.
					</p>
				</div>
				<div class="ncontent">
					<p>
						Look at the karnaugh map below. The optimal grouping is shown.
					</p>

					<img src="logic/kmap-gr3.png" style="max-width: 100%">

					<p>
						Thus here \(f = \bar{B} + \bar{A} \cdot \bar{C}\)
					</p>
				</div>

				<div>
					<p class="ir">
						Impossibilites.
					</p>
				</div>
				<div>
					<p>
						Sometimes, however, with specific cases, minimising this way is impossible.
					</p>

					<img src="logic/kmap-gr4.png" style="max-width: 100%">

					<p>
						This is actually \((A \oplus B) \oplus (C \oplus D)\). It is thus only of use in cases, especially where exclusive or is involved. 
					</p>

					<p>
						Sometimes, even, it is easier to extract \(\bar{f}\), i.e. 0s from the map. 
					</p>
				</div>

				<div>
					<p class="ir">
						"Don't care" conditions.
					</p>
				</div>
				<div>
					<p>
						Denoted often with an \(\times\), this can be assumed to be either 1 or 0 depending on context. 
					</p>

					<img src="logic/kmap-gr5.png" style="max-width: 100%">

					<p>
						The case where \(\times\) is a 0, we have \(f = A + B + C \cdot D\).
					</p>

					<img src="logic/kmap-gr6.png" style="max-width: 100%">

					<p>
						The case where \(\times\) is a 1, we have \(f = A + B + D\).
					</p>
				</div>
			</div>

			<h2 id="log-3">Combinatorial Logic Circuits</h2>

			<p>
				<i>Editor's note:</i> Apologies for the PNG and not SVG images, but I'm not going to switch to svg or use latex because it takes long enough.
			</p>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						Half bit adder.
					</p>
				</div>
				<div>
					<p>
						There are several combinatorial logic ciruits one should know about. First of all, we want to look at adding bits, since addition is very important generally. To start adding bits, we start off with only a half bit adder, where we add \(A, B\) and get a \(\Sigma, \textrm{Carry}\). 
					</p>

					<figure>
						<img src="https://upload.wikimedia.org/wikipedia/commons/d/d9/Half_Adder.svg" style="max-width: 200px; width: 100%; margin-left: auto; margin-right: auto; display: block;">
						<figcaption><i>Half Adder (Wikimedia Commons)</i></figcaption>
					</figure>

					<p>
						Which has a truth table of:

						\begin{array} {|r|r|}\hline A & B & \Sigma & \textrm{Carry} \\ \hline 0 & 0 & 0 & 0 \\ \hline 0 & 1 & 1 & 0 \\ \hline 1 & 0 & 1 & 0 \\ \hline 1 & 1 & 0 & 1 \\ \hline  \end{array}
					</p>
				</div>

				<div>
					<p class="ir">
						Full bit adder.
					</p>
				</div>
				<div>
					<p>
						Now that's just a <i>half</i> adder, a full adder on the other hand requires taking a carry as an input. Thus, we take an \(A, B, C_{\textrm{in}}\) and get a \(\Sigma, C_{\textrm{out}}\).
					</p>

					<p>
						The logic diagram of a full adder is not strictly necessary, but Matt has said he would be pleased if someone produced it, so it's included below.
					</p>

					<figure>
						<img src="https://upload.wikimedia.org/wikipedia/commons/a/a9/Full-adder.svg" style="max-width: 300px; width: 100%; margin-left: auto; margin-right: auto; display: block;">
						<figcaption><i>Full Adder (Wikimedia Commons)</i></figcaption>
					</figure>
				</div>

				<div>
					<p class="ir">
						N-bit adder.
					</p>
				</div>
				<div>
					<p>
						We can then string together a series of full bit adders to form an \(n\)-bit adder.
					</p>

					<figure>
						<img src="https://upload.wikimedia.org/wikipedia/commons/5/5d/4-bit_ripple_carry_adder.svg" style="max-width: 400px; width: 100%; margin-left: auto; margin-right: auto; display: block;">
						<figcaption><i>N-bit adder (Wikimedia Commons)</i></figcaption>
					</figure>
				</div>

				<div>
					<p class="ir">
						Subtraction with adders.
					</p>
				</div>
				<div>
					<p>
						Since subtraction is nothing but addition of negative numbers, we can use two's complement principle to do this. We have a toggle bit \(M\) which hooks onto \(B\). 
					</p>

					<p>
						To convert a number to two's complement, we flip the bits and add 1, so what we can do is flip all the bits of B if M is 1, and then add on M to fit two's complement. An operation to flip the bits of B when M is 1 is <b>exclusive or</b> (check the truth table). We can now build an \(n\)-bit adder-subtractor.
					</p>

					<figure>
						<img src="https://www.electronicshub.org/wp-content/uploads/2015/06/Parallel-subtactor-and-adder.jpg" style="width: 100%; max-width: 440px; margin-left: auto; margin-right: auto; display: block;">
						<figcaption><i>N-bit adder-subtractor (<a href="https://www.electronicshub.org/binary-adder-and-subtractor/">Electronics Hub</a>)</i></figcaption>
					</figure>
				</div>

				<div>
					<p class="ir">
						
					</p>
				</div>
				<div>
					<p>
						There are many other important combinatorial logic circuits that one needs to know (but not necessarily draw the internals of).
					</p>
				</div>

				<div>
					<p class="ir">
						Active Low Decoder.
					</p>
				</div>
				<div>
					<p>
						Active low, often written \(\overline{\textrm{Enable}}\) (with an overline), is where 0 denotes the "true" state. Naturally, Active High also exists, but low seems more commonplace.
					</p>

					<img src="logic/actlow.png" style="max-width: 100%">

					<p>
						A decoder takes an "encoded" binary value and translates it into the appropriate discrete output.
					</p>
				</div>

				<div>
					<p class="ir">
						Encoder.
					</p>
				</div>
				<div>
					<p>
						On the oher hand, the other way round would be an encoder, which takes in a series of inputs and returns an "encoded" binary value. 
					</p>
				</div>

				<div>
					<p class="ir">
						Multiplexer.
					</p>
				</div>
				<div>
					<p>
						A multiplexer "chooses" from a series of \(2^n\) inputs based on \(n\) selection inputs. The following truth table shows a 4-1 (4 in 1 out) multiplexer.
					</p>

					<img src="logic/multiplex.png" style="max-width: 100%">

					<p>
						Note how the denary value \(n\) of the binary \(S_{0}S_{1}\) will choose which value \(X_n\) is "channeled through".
					</p>
				</div>

				<div>
					<p class="ir">
						De-multiplexer.
					</p>
				</div>
				<div>
					<p>
						Opposite to the multiplexer we have a de-multiplexer (a Demux) which does almost the opposite to what a multiplexer does. Have a look at the truth table. 
					</p>

					<p>
						Note that this Demux is active-<b>low</b>.
					</p>

					<img src="logic/demux.png" style="max-width: 100%">

					<p>
						The denary value \(n\) given by \(S_{0}S_{1}\) will choose which \(Y_n\) \(A\) is sent through.
					</p>
				</div>

				<div>
					<p class="ir">
						Applications.
					</p>
				</div>
				<div>
					<p>
						These circuits can be used for source control - i.e. controlling which source gets sent through - so you can have one line for multiple senders. Another application may be converting from serial to parallel, or vice versa. 
					</p>
				</div>
			</div>

			<h2 id="log-4">Sequential Logic Circuits</h2>

			<div class="cornell">
				<div>
					<p style="font-style: italic; text-align: right;">
						
					</p>
				</div>
				<div>
					<p>
						A sequential logic circuit is a circuit whose outputs are <b>logical functions</b> of <b>inputs</b> and <b>current state</b>. It's often used to build memory. 
					</p>
				</div>

				<div>
					<p class="ir">
						Flip flops.
					</p>
				</div>
				<div>
					<p>
						The flip flop is one of the most important circuits. It is stable in two states. 
					</p>

					<img src="logic/flipflip.svg" style="width: 100%">

					<p>
						The truth table of the flip flop is given as follows:

						\begin{array} {|r|r|}\hline \bar{S} & \bar{R} & Q & P \\ \hline 0 & 0 & \times & \times \\ \hline 0 & 1 & 1 & 0 \\ \hline 1 & 0 & 0 & 1 \\ \hline 1 & 1 & N/A & N/A \\ \hline  \end{array}

						A cross in this table indicates a <i style="color: #D00">hazard</i> - basically don't have set and reset on at the same time, it's bad. N/A means no change in state. 
					</p>

					<p>
						Below is a time diagram of the flip flop. Remember that S and R are active low. 
					</p>

					<img src="logic/flipfloptimestep.png" style="width: 100%; max-width: 400px;">
				</div>

				<div>
					<p class="ir">
						D-type latch.
					</p>
				</div>
				<div>
					<p>
						Uses a flip flop, and makes a 1 bit memory circuit. There are inputs \(D, \textrm{Enable}\) and outputs \(Q, \bar{Q}\). \(D\) is usually referred to as "Data".
					</p>

					<img src="logic/dlatych.svg" style="max-width: 500px; width: 100%">

					<p>
						It has the truth table of the following:
						\begin{array} {|r|r|}\hline \textrm{Enable} & D & Q & \bar{Q} \\ \hline 0 & 0 & Q & \bar{Q} \\ \hline 0 & 1 & Q & \bar{Q} \\ \hline 1 & 0 & 0 & 1 \\ \hline 1 & 1 & 1 & 0 \\ \hline  \end{array}
						Note how when Enable is false, no matter what changes with data the latch retains its state, whilst when Enable is true the latch will take on the value of data.
					</p>
				</div>

				<div>
					<p class="ir">
						Edge triggering.
					</p>
				</div>
				<div>
					<p>
						<b>Edge triggering</b> means that a latch, or logic circuit is enabled when the state <b>changes</b>, and not depending on what the state is. For example, when something is active only on the transition of \(1 \rightarrow 0\) or \(0 \rightarrow 1\). 
					</p>

					<p>
						Something which is active at a steady value is called <b>level triggered</b>.
					</p>

					<img src="logic/edgetrigger.svg" style="max-width: 100%">
				</div>

				<div>
					<p class="ir">
						Clocked flip flops.
					</p>
				</div>
				<div>
					<p>
						Clocked flip flops are flips that flop only on the <i>rising edge</i> of a clock input. There are three types - most importantly D-type (<i>delay</i>), along with T-type (<i>toggle</i>) and JK-type.
					</p>

					<img src="logic/floptypes.png" style="max-width: 100%">
				</div>

				<div>
					<p class="ir">
						N-bit register
					</p>
				</div>
				<div>
					<p>
						We can connect multiple D-type latches together to store an \(N\)-bit binary word. Below is a diagram of a 4 bit parallel load register, you can extrapolate the rest.
					</p>

					<figure>
						<img src="logic/4b-barallel.gif" style="width: 100%; max-width: 440px; margin-left: auto; margin-right: auto; display: block;">
						<figcaption><i>4 bit parallel register (<a href="https://www.electronics-tutorials.ws/sequential/seq_5.html">Electronics Hub</a>)</i></figcaption>
					</figure>

					<p>
						In a <b>parallel</b> load register, the binary input \(A\) is loaded all simultaneously. Alternatively, we can have what's called a <b>shift</b> register, where each clock cycle will shift the bits along the register like a queue. The diagram displayed below shows a shift register that only goes one way. Of course, you can also have a two-way shift register. 
					</p>

					<figure>
						<img src="logic/4b-serial.gif" style="width: 100%; max-width: 440px; margin-left: auto; margin-right: auto; display: block;">
						<figcaption><i>4 bit serial in parallel out register (<a href="https://www.electronics-tutorials.ws/sequential/seq_5.html">Electronics Hub</a>)</i></figcaption>
					</figure>
				</div>

				<div>
					<p class="ir">
						3-state logic.
					</p>
				</div>
				<div>
					<p>
						3-state logic is different from regular I/O logic circuits. It, as the name implies, introduces a third state, which is termed "<b>unconnected</b>". 
					</p>

					<img src="logic/tristate.svg" style="width: 180px; max-width: 100%">
				</div>
			</div>

		</div>
		

		<footer>
			<div class="cbox">
				<div class="columncontainer ctwo">
					<div>
						<p class="small">
							Â© 2020-2021 Yijun Hu, all rights reserved.
						</p>
					</div>
					<div>
						<p class="small rj">
							Designed by Yijun Hu
						</p>
					</div>
				</div>
			</div>
		</footer>

	</div>

	<script type="text/javascript" src="../../js/collapsible.js"></script>  <!--This stays at the end-->
</body>
</html>