<!DOCTYPE html>
<html>
<head>
	<title>CS259</title>
	<meta charset="utf-8">
	<link rel="stylesheet" type="text/css" href="../../style/style.css" media="all">  <!--TODO: CHANGE HREF-->
	<link rel="stylesheet" type="text/css" href="../../style/prism.css" media="all">
	<meta name="viewport" content="width=device-width" initial-scale=1.0>  <!--TODO: CHANGE LINKS ON BOTTOM OF SHEET FOR COLLAPSIBLE-->
	<link rel="icon" type="image/png" href="../../style/images/DragonIcon.png">
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

	<div class="hidden">
		<header>
			<div class="parallax parsmaller">
				<div  style="display: grid; grid-template-columns: 1fr 1fr 1fr 8fr 1fr; grid-column-gap: 10px; padding: 5px; ">
					<div class="column tinycolumn">
						<a href="../../" class="nav">Home</a>
					</div>
					<div class="column tinycolumn">
						<a href="../../blog.html" class="nav">Blog</a>
					</div>
					<div class="column tinycolumn">
						
						<a href="../../about.html" class="nav">About</a>
					</div>
					<div></div>
					<div class="column">
						<button class="nav dark-light">Dark Mode</button>
					</div>
				</div>
				<div class="cbox"> 		
					<h1>CS259</h1>
					<p class="subheading">Formal Languages</p>
				</div>
			</div>
		</header>

		<header>
			<div class="cbox">
				<h1>Introduction</h1>
			</div>
		</header>

		<!-- <div class="buttonwrapper beside" >
			<a href="./index-zh.html">简体中文</a>
		</div> -->
		<!-- REMEMBER TO DO! -->

		<div class="cbox">

			<h3>Contents</h3>
			<ol>
				<li><a href="#dfa">Deterministic Finite Automata</a></li>
				<li><a href="#nfa">Non-deterministic Finite Automata</a></li>
				<li><a href="#regex">RegEx</a></li>
				<li><a href="#nonreg">Non-Regular Languages</a></li>
				<li><a href="#grammars">Grammars</a></li>
				<li><a href="#cfl">Context Free Languages</a></li>
			</ol>
			<h3>Languages</h3>
			<p class="blue">
				An <b>alphabet</b> is a <b>non-empty</b> set of symbols, usually denoted \(\Sigma = \{a,b,c,\dots\}\). \(\renewcommand{\epsilon}{\varepsilon}\)
			</p>
			<p class="blue">
				A <b>language</b> is then a (potentially infinte) set of <b>finite strings</b> (words) over an alphabet. The set of <b>all</b> words is denoted \(\Sigma*\).
			</p>
			<p>
				In CS, we can model every decision problem as a question "is a given string in a given language L?", thus, one can see the usefulness of formal languages.
			</p>
		</div>

		
		<div class="colourband">
			<h2 id="dfa">Deterministic Finite Automata</h2>
		</div>

		<div class="cbox">
			<h3>Contents</h3>

			<ol>
				<li><a href="#dfa-1">DFA</a></li>
				<li><a href="#dfa-2">Regular Languages</a></li>
			</ol>

			<h3 id="dfa-1">DFA</h3>

			<div class="blue">
				<p>
					A <b>deterministic finite automata</b> (DFA, also referred to as a finite state machine) is comprised of:
				</p>
				<ul>
					<li>\(Q\) the <i>finite</i> set of states</li>
					<li>\(\Sigma\) the alphabet set</li>
					<li>\(q_0 \in Q\) the start/initial state</li>
					<li>\(F \subseteq Q\) final/accept states</li>
					<li>\(\delta : Q \times \Sigma \longrightarrow Q\) the <b>transition function</b> between states.</li>
				</ul>
				<p>
					And is denoted by the 5-tuple \(M=(Q, \Sigma, q_0, F, \delta)\).
				</p>
				
			</div>
			<p>
				The DFA can either be represented in a state diagram, or in a transition table:
			</p>
			<figure>
				<img src="./dfa.png" alt="" style="max-width: 600px;">
				<figcaption>A DFA. Every "transition" the DFA reads one symbol from the input string. States which are double circled (or annotated with stars) are finish states, and states with a blank arrow pointing in are start states. There must be one arrow for every possible incoming letter.</figcaption>
			</figure>

			<div class="blue">
				<p>
					\(\varepsilon\) represents the <b>empty string</b>. Any DFA with an input of \(\varepsilon\) will halt immediately on the start state. \(\varepsilon \in \Sigma* \).
				</p>
				<p>
					\(L = \{\} = \varnothing\) is the <b>empty language</b> - note that \(L = \{\varepsilon\}\) is <i>not</i> empty.
				</p>
			</div>
			<p>
				A <b>monoid</b> is a tuple of a set, an associative binary equation, and an identity:
				<ul>
					<li>\((\mathbb{N}_0, +, 0)\) where + is integer addition, and \(\mathbb{N_0} \) are nonnegative integers.</li>
					<li>\((\Sigma*, \circ, \varepsilon)\) where \(\circ\) is string concat, is a monoid. </li>
				</ul>
			</p>
			<p>
				<i><b>Note well</b> that the concat symbol \(\circ\) can also be written \(\cdot\) or omitted entirely.</i>
			</p>

			<p class="side">
				Formally, the way a DFA computes can be defined with the help of the <b>extended transition function</b>:
				\[\hat{\delta} : Q \times \Sigma* \longrightarrow Q\]
				Which can be recursively defined (in a haskell <i>like</i> form) over a string \(w = w' \circ a\) as
				\begin{align}
					\hat{\delta}(q, \varepsilon) &= q\\
					\hat{\delta}(q, w' \circ a) &= \delta(\hat{\delta}(q, w'), a).
				\end{align}
			</p>

			<p class="side">
				The <b>accepted language</b> of a DFA \(M = (Q, \Sigma, q_0, F, \delta)\) is \(L(M)\), such that
				\[L(M) = \{ s \in \Sigma* : \hat{\delta} (q_0, s) \in F \}.\]
			</p>

			<div class="side">
				<p>The <b>run</b> of M on a word \(s\) is the path of states M goes through for \(s\):</p>
				
				<ul>
					<li>The run of M on \(\varepsilon\) is trivially \(q_0\)</li>
					<li>
						The run of M on a string \(s_0..s_n \neq \varepsilon\) is \(r_0..r_n\) such that
						\[r_0 = q_0,\; \forall i \in [1..n] \; r_i = \delta(r_{i-1}, s_i)\]
					</li>
				</ul>
			</div>

			<p class="side">
				The run is an <b>accepting run</b> is a run that ends in an accepting state, thus \(s\) is accepted if its run is accepting - we can also define \(L(M)\) using accepting runs.
			</p>

			<h3 id="dfa-2">Regular Languages</h3>

			<p class="blue">
				A language L is <b>regular</b> if it is accepted by some DFA. 
			</p>
			<p>
				Trivially, the empty language \(L=\varnothing\) is regular (any DFA with no accept states), and \(\Sigma* \) is regular (define \(\delta(q_0, \_) = q_0\)).
			</p>
			<p>
				Naturally not all languages are regular, one particular one to note is that the language of (binary) <b>palindromes</b> is <b>not</b> regular.	
			</p>
			<p>
				Since languages are sets of strings, we can naturally perform set operations: \(\overline{L}, L \cap M, L \cup M\). There are also a few string-specific operators, such as
				<ul>
					<li><code>reverse L</code>: reverse all strings in L</li>
					<li><code>truncate L n</code>: trim all strings in L to at most \(n\) long </li>
					<li><code>concat L1 L2</code>: like cross product, but concactenating strings together instead of tuple pairing</li>
				</ul>
				But the main question is: are the results of these operations also regular languages?
			</p>

			<p class="side">
				For <b>completement</b>: where \(\overline{L} = L \setminus \Sigma* \), this is <b>closed</b>, as one can just invert the accept and reject states of the DFA.
			</p>
			<p class="side">
				For <b>intersection</b>: given \(L_1, L_2\), \(L_1 \cap L_2\) is regular, this is <b>closed</b>. Given \(M_1 = (Q_1, \Sigma, q_1, F_1, \delta_1)\) and \(M_2 = (Q_2, \Sigma, q_2, F_2, \delta_2)\), we can construct an <b>intersection automaton</b> like the following:
			</p>

			<button class="collapsible active">Intersection Automation... </button>
			<div class="ccontent" style="display: block;">
				<p>
					We define \(M_3 = (Q, \Sigma, q_0, F, \delta)\) as the intersection automaton of \(M_1, M_2\), and define it like follows:
				</p>
				<ul>
					<li>\(Q = Q_1 \times Q_2\)</li>
					<li>\(q_0 = (q_1, q_2)\) (note how states are labelled with pairs)</li>
					<li>\(F = F_1 \times F_2\)</li>
					<li>\(\forall a \in \Sigma, \forall x \in Q_1, \forall y \in Q_2:\)
						\[\delta((x,y), a) = (\delta_1(x,a), \delta_2(x,a)).\]
					</li>
				</ul>
			</div>
			<p>
				Note that \(L_1\) regular, \(L_2\) regular \(\implies L_1 \cap L_2\) regular is a <b>one-way implication</b>. If we take \(L_1\) to be the set of palindromes, \(L_2\) being all zeroes 0*, their union is clearly regular, but the separate languages are not.
			</p>

			<p class="side">
				For <b>union</b>, this is also <b>closed</b>. We can similarly construct a union automaton.
			</p>

			<button class="collapsible active">Union Automaton... </button>
			<div class="ccontent" style="display: block;">
				<p>
					Given two machines \(M_1 = (Q_1, \Sigma, q_1, F_1, \delta)\) and \(M_2 = (Q_2, \Sigma, q_2, F_2, \delta)\) -- note the deltas are the same, construct a machine \(M_3 = (Q, \Sigma, q, F, \delta)\) as
					<ul>
						<li>\(Q = Q_1 \times Q_2\)</li>
						<li>\(q = (q_1, q_2)\)</li>
						<li>\(F = (F_1 \times Q_2) \cup (F_2 \times Q_1\)</li>
					</ul>
					To make the two \(\delta\)s the same, you can include the transitions in one as redundant transitions in the other.
				</p>
			</div>

			<p class="side">
				<b>Set difference</b> is <b>closed</b>, since \(L_1 \setminus L_2 = L_1 \cap \overline{L_2} \).
			</p>

			<p class="side">
				<b>Set reverse</b> \(L^{rev}\) is... well it's closed, but it's not so simple with only DFAs. Intuitively, we want to reverse all the arrows, and make all the finish states start states, and vice versa, but of course, more often than not, this'll break a DFA rules, which means we need to introduce another abstraction:
			</p>
		</div>

		<div class="colourband">
			<h2 id="nfa">Non-deterministic Finite Automata</h2>
		</div>

		<div class="cbox">

			<h3>Contents</h3>

			<ol>
				<li><a href="#nfa-1">NFAs</a></li>
				<li><a href="#nfa-2">Transition Functions, \(\varepsilon\)-closure, Runs</a></li>
			</ol>

			<h3 id="nfa-1">NFAs</h3>
			<p>
				A <b>non-deterministic finite automata</b>, an NFA, is like a DFA, but you no longer have so much of the restrictions. 
			</p>

			<div class="blue">
				<p>
					An <b>NFA</b> can be defined as a five tuple of
				</p>
				<ul>
					<li>\(Q\) a finite set of states</li>
					<li>\(\Sigma\) a finite alphabet</li>
					<li>\(q_0\) an initial state</li>
					<li>\(F \subseteq Q\) accept states</li>
					<li>\(\delta\) the transition function, <b>defined as</b>
						\[\delta : Q \times (\Sigma \cup \{\varepsilon\}) \longrightarrow 2^Q\]
					</li>
				</ul>
				<p>
					Yep - that's right, an NFA can have empty string transitions (epsilon transitions), and a single letter can lead to multiple (a set of) states. 
				</p>
			</div>

			<figure>
				<img src="./nfa.png" alt="" style="max-width: 500px;">
				<p>An NFA. Note the multiple possible transitions, missing transitions, and epsilon transitions.</p>
			</figure>

			<p>
				Going back to our \(L^{rev}\), we <i>still</i> can't have multiple start states, <i>however</i>, we can merely add a new start state, and add \(\varepsilon\)-transitions to all the would've-been start states.
			</p>

			<p>
				A DFA has a clear, linear progression, but how does an NFA run? An NFA runs like a multiple world theory, where every time the NFA encounters multiple possible transitions, the NFA "branches" into multiple worlds which each going to one possible transition.
			</p>
			<p>
				If an NFA world reaches a state with no possible transitions, it crashes, and is considered a <b>reject</b> by default. 
			</p>
			<p>
				As long as <b>at least one</b> world reaches a finish state, the NFA run is considered an <b>accept</b>.
			</p>

			<p>
				A computer simulating an NFA would basically be doing a brute force DFS/BFS search.
			</p>

			<figure>
				<img src="./nfa-worlds.png" alt="	" style="max-width: 420px;">
				<figcaption>
					An NFA branching, and one branch reaching a finish.
				</figcaption>
			</figure>

			<p>
				We can think of DFAs as being strict subsets of NFAs, where there can only be one world and other special conditions.
			</p>

			<h3 id="nfa-2">Transition Functions, \(\varepsilon\)-closure, Runs</h3>

			<p>
				Let's try to formally define NFAs. 
			</p>
			<div class="side">
				<p>
					We want to use \(\delta : Q \times \Sigma_\varepsilon \longrightarrow 2^Q\) to define \(\hat{\delta} \). (Note \(\Sigma_\varepsilon = \Sigma \cup \{\varepsilon\} \) for convenience). 
					\[\hat{\delta} : Q \times \Sigma* \longrightarrow 2^Q.\]
				</p>
				<p>
					Say that \(\forall q \in Q\, s \in \Sigma*,\; \hat{\delta}(q, s) =\) all states in Q such that there <b>exists a run</b> from \(q\) upon reading string \(s\). i.e. all reachable states.  
				</p>
				
			</div>

			<div class="side">
				<p>
					The <b>run</b> of an NFA M on a word \(s = s_1 .. s_n\) is the sequence of states \(r_0 .. r_n\), such that
					<ul>
						<li>\(r_0 = s_0\)</li>
						<li>\(\forall i \in [1..n], \; r_i \in \delta(r_{i-1}, s_i)\)</li>
					</ul>
					An <b>accepting run</b> is then a run which ends in an accept state.
				</p>
			</div>

			<p>
				To define the extended transition function however, we need to first of all look at <b>epsilon-closure</b>: ECLOSE().
			</p>

			<div class="side">
				<p>
					<b>Epsilon Closure</b> is a function \(\textrm{ECLOSE}: Q \longrightarrow 2^Q\) which denotes all states that can be reached from a starting state \(q\) only by \(\varepsilon\)-transitions. 
				</p>
				<p>
					Formally, \(\forall X \subseteq Q\):
					\begin{align}
						\textrm{ECLOSE}(\varnothing) &= \varnothing\\
						\textrm{ECLOSE}(X) &= \bigcup_{x \in X} \textrm{ECLOSE}(\{x\})
					\end{align}
				</p>
			</div>

			<div class="side">
				<p>
					The <b>Extended Transition Function</b> \(\hat{\delta}\) defined \(\forall q \in Q,\; \forall s \in \Sigma* \setminus \{\varepsilon\}: s = wa\) where \(w \in \Sigma* \;\land \;\; a \in \Sigma \). In plain english: for all states \(q\), and for all non-empty strings \(s\) which are decomposed into \(w\), the prefix, and \(a\), the last letter:

					\begin{align}
					\hat{\delta} (q, \varepsilon) &= \textrm{ECLOSE}(q)\\
					\hat{\delta} (q, wa) &= \textrm{ECLOSE}(\bigcup_{q' \in \hat{\delta}(q,w)} \delta(q',a))
					\end{align}
				</p>
			</div>

			<p>
				Thus, the language accepted by an NFA can be defined in two ways, either as the set of all strings whose extended transition functions contain some finish state,
				\[L(M) = \{s \in \Sigma* : \hat{\delta} (q_0, s) \cup F \neq \varnothing\}\]
				or the set of all strings which have an accepting run.
			</p>

			<h3 id="nfa-3">Reduction to DFA</h3>

			<p>
				Are NFAs more powerful than DFAs? And by that, we mean can NFAs accept languages which DFAs can't? 
			</p>
			<p>
				Well the answer to that is <b>no</b>. NFAs can reduce to DFAs. Similar to how one DFA can simulate two DFAs like in intersection automata, we can do something similar for simulating an NFA. 
			</p>
			<p>
				An NFA's state information can be captured by a <b>set</b> of states, so we can just have a DFA with states corresponding to \(2^Q\) in the NFA, and transitions between them. 
			</p>
			

			<div class="side">
				<p>
					<b><i>Subset Construction.</i></b> Let \(N = (Q, \Sigma, q_0, F, \delta)\) be the NFA we want to convert. Let the resulting DFA be denoted \(M = (Q_d, \Sigma, q_d, F_d, \delta_d)\).
				</p>
				<ul>
					<li>
						M has a state for every subset of N: \(Q_d = 2^Q\). This includes the empty subset \(\varnothing\), which simulates N "crashing".
					</li>
					<li>
						The start of NFA is \(q_0\), but since we have to consider \(\varepsilon\)-transitions, \(q_d = \textrm{ECLOSE}(q_0)\).
					</li>
					<li>
						Finish states are all subsets of N that contain N's finish states, \(F_d = \{X \subseteq Q : X \cap F \neq \varnothing\} \).
					</li>
					<li>
						Given a starting set \(X\) and a letter \(a\), we reach the set of all possible states reached in N by \(\delta(X,a)\) followed by ECLOSE:
						\begin{align}
							\delta_d (X,a) &= \bigcup_{x \in X} \textrm{ECLOSE}(\delta(X,a)) \\
							&= \{z : \textrm{ for some } x \in X, z \in \textrm{ ECLOSE}(\delta(X, a))\}
						\end{align}
					</li>
				</ul>
			</div>

			<p>
				Of course, drawing all of these states is <b>not feasible</b> for any significant number of NFA state0s, especially as there would probably be a lot of <b>redundant states</b>, and thus the machine should be built up incrementally. Start from \(\textrm{ECLOSE}(q_0)\) and work from there.
			</p>

			<p>
				In general, this means that a language is regular <br>
				&emsp;<b>iff</b> it is accepted by a DFA <br>
				&emsp;<b>iff</b> it is accepted by an NFA.
			</p>
		</div>
		
		<div class="colourband">
			<h2 id="regex">RegEx</h2>
		</div>

		<div class="cbox">
			<h3>Contents</h3>

			<ol>
				<li><a href="#reg-1">Regex</a></li>
				<li><a href="#reg-2">Regex to NFA</a></li>
				<li><a href="#reg-3">Generalised NFA</a></li>
			</ol>

			<h3 id="reg-1">Regex</h3>

			<div class="blue">
				<p>
					A <b>Regular Expression</b> (RegEx) is a compat way to describe a (regular) language. It can be defined with the following 6 rules:
				</p>
				<ul>
					<li>R = \(a\) for some \(a \in \Sigma\)</li>
					<li>R = \(\varepsilon\)</li>
					<li>R = \(\varnothing\)</li>
					<li>R = \(R_1 + R_2\) (<b>or</b>: \(R_1 \cup R_2\))</li>
					<li>R = \(R_1 \cdot R_2\) (<b>concat</b>: more often \(R_1 R_2\))</li>
					<li>R = \(R_1*\) (0 or more, called the <b>kleene star</b>)</li>
				</ul>
			</div>

			<p class="small">
				Sure, "regex" on most systems have way more symbols to make life easier, but this is sufficient to generate all regular languages.
			</p>

			<p>
				In terms of operator precedence, it goes \(*, \cdot, +\).
			</p>

			<p>
				Some examples then, over \(\Sigma = \{a,b\}\):
			</p>
			<ul>
				<li><code>(a+b)*</code>: effectively \(\Sigma* \).</li>
				<li><code>(a+b)*(a+bb)</code>, any word which ends in "a" or "bb".</li>
				<li><code>(aa)*(bb)*b</code>, any word made up of even "a"s followed by even "b"s, ending in a "b".</li>
				<li><code>(aa+b)*</code>, all consecutive "a"s must be of an even number.</li>
			</ul>
			<p>
				Often, if a regex can be understood in plain english, one can turn that regex into a DFA or NFA directly via creative thinking, but there is a modular algorithmic way of doing so, since 
			</p>
			

			<h3 id="reg-2">Regex to NFA</h3>

			<p class="side">
				<b><i>Theorem.</i></b> A language is accepted by an NFA/DFA \(\iff\) it is generated by a regex.
			</p>

			<p>
				<b><i>Proof.</i></b> We have two algorithms, one to turn a regex to an NFA, and vice-versa.
			</p>

			<h4>Regex to NFA</h4>

			<p>
				This can be done modularly based on the recursive definition of a regex string. Our base cases (below) can be modelled by three different "modules":
			</p>
			<figure>
				<img src="./regex-dfa-base.png" alt="" title="R=a: ->()-a>(accept). R=ε: ->(accept). R=nothing: ->()" style="max-width: 500px;">
			</figure>
			<p>
				Then we have our recursive / inductive cases: \(R_1 + R_2\), \(R_1 \cdot R_2\), and \(R*\). A rectangle, in this case, represents a whole machine. 
			</p>
			<figure>
				<img src="./regex-dfa-recursive.png" alt="" style="max-width: 420px;" title="OR: e-transition to both machines from a common state. CONCAT: Connect all accept states of first to start of second (and make the accept states of first not accept). STAR: Make a new initial accept state, connect all accept states of machine to this state.">
			</figure>

			<p>
				As an aside have a think about the language \(\varnothing* \). What does that make? Well, concating \(\varnothing\) with anything is just ... \(\varnothing\), but the definition of kleene star is 0 or more times: i.e. \(\{\varepsilon\} \cup \varnothing \cup \varnothing^2 \cup \dots\), thus \(\varnothing* = \{\varepsilon\}.\)
			</p>

			<h4>NFA to Regex</h4>

			<p>
				This is better explained going along with an example:
			</p>
			<figure><img src="./dfa-regex/st1.png" alt="" style="max-width: 420px;"></figure>
			<p>
				Our goal is to slowly eliminate all the nodes one at a time, reflecting their effect by changing arcs into smaller <i>regex expressions</i>. First though, we need to add a start \(q_s\) and unique final \(q_f\) state and transition to them with epsilon:
			</p>
			<figure><img src="./dfa-regex/st2.png" alt="" style="max-width: 420px;">
				<figcaption>The start state is a source and the finish state is a sink</figcaption>
			</figure>
			<p>
				Start by eliminating \(q_3\). Possible paths are \(\langle q_2,q_3,q_2 \rangle :10*\) and \(\langle q_2, q_3, q_f\rangle : 1\varepsilon = 1\). Thus, we can have a self loop on \(q_2\) to be \(10*\) and modify \(q_2 \longrightarrow q_f\) to be \(1 + \varepsilon\)* to represent the two possible choices. Then, \(q_3\) becomes redundant and can be removed.
			</p>
			<figure>
				<img src="./dfa-regex/st3.png" alt="" style="max-width: 210px;">
			</figure>
			<p>
				* Technically, the transition \(q_2 \longrightarrow q_f : \varepsilon\) remains unaffected, but since we also have a new transition \(q_2 \longrightarrow q_f : 1\), we <i>simplify</i> the two parallel transitions into one: \(1 + \varepsilon\). This is very important to note.
			</p>
			<p>
				Eliminate \(q_2\) using a similar process. 
			</p>
			<figure>
				<img src="./dfa-regex/st4.png" alt="" style="max-width: 420px;">
			</figure>
			<p>
				Eliminate \(q_1\)
			</p>
			<figure><img src="./dfa-regex/st5.png" alt="" style="max-width: 420px;"></figure>
			<p>
				Finally, eliminate \(q_0\)
			</p>
			<figure><img src="./dfa-regex/st6.png" alt="" style="max-width: 420px;"></figure>
			<p>
				Then, we simply read off the last remaining transition for our regex. 
			</p>
			<p>
				Now sure, it's not the cleanest, shortest, or most efficient, but it <i>is</i> a regex, and that's all that matters.
				$$\tag*{$\Box$}$$
			</p>

			<h3 id="reg-3">Generalised NFA</h3>

			<div class="blue">
				<p>
					A <b>Generalised NFA (GNFA)</b> is a tuple \((Q, \Sigma, \delta, q_{start}, q_{accept})\) where 
					\[\delta : (Q \setminus \{q_{accept}\}) \times (Q \setminus \{q_{start})\} \longrightarrow \mathfrak{R}.\]
					Which the fraktur blackletter \(\mathfrak{R}\) means the set of <b>all regular expressions</b>.
				</p>
				<p>
					For simplicity \(q_0 = q_{start}\) and \(q_f = q_{accept} \). Note the <b>unique</b> start and finish states.
				</p>
				<p>
					\(q_0\) must be a <b>source</b> with outgoing transitions to <b>all</b> other states. <br>
					\(q_f\) must be a <b>sink</b> with incoming transitions from <b>all</b> other states. 
				</p>
				<p>
					These transitions can be \(\varnothing\), i.e. nothing.
				</p>
			</div>

			<p class="side">
				The <b>run</b> of a GNFA M on a word \(s\) is a sequence of states \(r_0 .. r_n\) such that \(r_0 = q_0\), and 
				\[\exists s_1 .. s_n \in \Sigma* : s = s_1 .. s_n \textrm{ and } \forall i \in [1..n] \; s_i \in L(\delta(r_{i-1}, r_i)).\]
				Plain english: \(s\) can be broken down into <b>substrings</b> such that there is a transition that matches each substring.
			</p>

			<p class="side">
				<b><i>Theorem.</i></b> Every NFA can be converted to an equivalent GNFA. This is techically what we have done in the <i>NFA to Regex</i> section, but with the \(\varnothing\) lines omitted for simplicity, which they often can be.
			</p>
			<p>
				With this fact we can now define our <b>elimination process</b> using some very complicated maths language. 
			</p>
			<div class="side">
				<img src="./gnfa-elim.png" alt="" align="right" style="max-width: 315px;">
				<p>
					<b>Assuming</b> we have <b>already converted</b> our NFA to a GNFA, and we want to eliminate a state \(q_1\), then for all pairs \(q_a, q_b \in (Q \setminus \{q_f, q_1\}) \times (Q \setminus \{q_0, q_1\}\) (pairs which do not include start and finish states):

					\begin{align}
						\delta' (q_a, q_b) &= \delta(q_a, q_b) \\
						&+ \delta(q_a, q_1) \cdot [\delta(q_1, q_1)*] \cdot \delta(q_1, q_b).
					\end{align}

					i.e. The existing a to b, or a to 1, any number of 1s, then 1 to b.
				</p>
			</div>
		</div>

		<div class="colourband">
			<h2 id="nonreg">Non-Regular Languages</h2>
		</div>

		<div class="cbox">
			<h3>Introduction</h3>

			<ol>
				<li><a href="#non-1">Myhill-Nerode</a></li>
				<li><a href="#non-2">Pumping Lemma</a></li>
			</ol>

			<p>
				Let \(L = \{0^n1^n : n \in \mathbb{N}\}\): i.e. equal number of zeroes and ones. Is this regular?
			</p>
			<p>
				Intuitively, it isn't, since one would need to keep track of both the number of zeroes and ones, and thus would need inifite memory, impossible on a <i>finite</i> state machine. But how do we formally prove this? 
			</p>

			<p>
				We can use <b>closure properties</b>, especially because its quick:
			</p>

			<button class="collapsible">Example \(L = \{w \in \{0, 1\}* : n_0 = n_1\} \)</button>
			<div class="ccontent">
				<p>
					<b><i>Proof.</i></b> i.e binary strings with equal zeroes and ones. Suppose L is regular. We know \(0*1*\) is regular, thus by closure properties \(0*1* \cap L\) should be regular ... right?
				</p>
				<p>
					Nope: \(0*1* \cap L = 0^n 1^n\) which is known to be irregular. $$\tag*{$\Box$}$$
				</p>
			</div>

			<p>
				But if we can't, there's two main ways.
			</p>

			<h3 id="non-1">Proving Nonregularity: Myhill-Nerode</h3>

			<p>
				If \(\hat{\delta}(q_0, \textrm{cat}) = \hat{\delta}(q_0, \textrm{rabbit}) = \hat{\delta}(q_0, \textrm{rat})\), then we can say these three strings are <b>equivalent</b>.
			</p>
			<p>
				These can be thought of as <b>equivalent relations</b> (remember cs130?), and following on from this, we can partition \(\Sigma* \) into <b>equivalence classes</b> based on what states they end up in. 
			</p>


			

			<p class="blue">
				<b><i>Definition.</i></b> The <b>index</b> of a language is its <b>number of equivalence classes</b>. This can be written \(\equiv_L\).
			</p>

			<div class="blue">
				<p>
					Strings \(x,y\) are <b>distinguishable</b> in language L, if there exists a <b>certifier</b> string \(z \in \Sigma* \), such that \(xz \in L\) and \(yz \not \in L\).
				</p>
				<p>
					Conversely, if two strings \(x,y\) are <b>indistinguishable</b>, we write \(x \equiv_L y\) where L is the language we're talking about. 
				</p>
				
			</div>
			<p>
				<b>Note: \(x, y\) both do <i>not</i> have to be in L. As long as \(xz \in L\) and \(yz \not \in L\) then this is sufficient.</b>
			</p>

			<p>
				Since DFAs have finite states, a regular language must have <b>finite equivalence classes</b>.
			</p>
			<p>
				Thus if a language has infinite equivalence classes, it can't be regular:
			</p>
			
			<p class="blue">
				<b><i>Theorem.</i> (Myhill-Nerode)</b> L is a regular language <b>if and only if</b> \(\equiv_L\) is finite.
			</p>

			<div class="side">
				<p>
					Proof structure for Myhill-Nerode:
				</p>
				<ol>
					<li>Come up with an infinite set of strings.</li>
					<li><b>Either</b>: Come up with a cerificate for a string \(i\) that distinguishes \(i\) from every other string simultaneously</li>
					<li><b>Or</b>: Come up with separate certificates that distinguish every \(i,j\) pair separately</li>
				</ol>
				<p>i.e, prove <b>pairwise distinguishability</b>.</p>
			</div>

			<button class="collapsible">Example \(L=\{0^n1^n : n \in \mathbb{N}\} \)</button>
			<div class="ccontent">
				<p>
					<b><i>Example.</i></b> Take the set of strings \(0* = \{\epsilon, 0, 00, 000, \dots\} \). We claim that these are all pairwise distinguishable.
				</p>
				<p>
					<b><i>Proof.</i></b> For string \(0^k\), take string \(1^k\) as certifier. That is: 0 has certificate 1, 00 has 11, 000 has 111, etc. 
				</p>
				<p>
					Note that for 0 with certificate 1, \(01 \in L\) but \(001 \not \in L, 002 \not \in L, \dots\) Same goes for all the others.
				</p>
				<p>
					Thus every string is pairwise distinguisable from every other. $$\tag*{$\Box$}$$
				</p>
				
			</div>

			<button class="collapsible">Example \(L = \{w : w \in \{a,b\}*, n_a(w) < n_b(w)\}\)</button>
			<div class="ccontent">
				<p>
					<b><i>Example.</i></b> This language is basically words with less "a"s than "b"s. 
				</p>
				<p>
					<b><i>Proof.</i></b> Take the set of strings \(a*\). For string \(a^r\), string \(b^{r+1} \) distinguishes \(a^r\) from every string \(a^s : s > r\). Thus, we can always find a distinguisher.
					$$\tag*{$\Box$}$$
				</p>
			</div>

			<button class="collapsible">Example \(L = \{1^n : n \textrm{ is prime}\} \)</button>
			<div class="ccontent">
				<p>
					<b><i>Proof.</i></b> Take the set of strings \(1*\). We need to individually pairwise distinguish them this time.
				</p>
				<p>
					Take any two strings \(1^i, 1^j\) (assuming \(i &lt; j\) for convenience). Pick any prime \(p : p &lt; i \land p &gt; 2\) <br>
					&emsp;\(\implies p + 0(j-i)\) is prime, obviously.
				</p>
				<p>
					Since \(p > 2,\; j-i > 0,\; p + p(j-i)\) is <i>not</i> prime.
				</p>
				<p>
					Thus let's look at the series \(s_n = p + n(j-1)\). i.e.
					\begin{align}
						&p + 0(j-i) \\
						&p + 0(j-i) \\
						&\vdots \\
						&p + (p-1)(j-i) \\
						&p + p(j-i) \\
					\end{align}
					there must be a <b>switch</b> from being prime to not being prime, between \(s_0\) and \(s_p\). Let \(k \in [1..p] \) be the <b>first</b> such switch at \(s_k = p + k(j-i)\).
				</p>
				<p>
					Thus, \(p + (k-1)(j-i)\) is prime whilst \(p + k(j-1)\) is not. Therefore, we make the certificate
					\[z = 1^{p + (k-1)(j-i) -i}.\]
					Note that
					\[1^i \cdot z = 1^{p + (k-1)(j-i)} \textrm{ which is prime,}\]
					Whereas
					\[i^j \cdot z = 1^{p + (k-1)(j-i) + (j-1)} = 1^{p + k(j-i)} \textrm{ which is not.}\]
					That was involved. $$\tag*{$\Box$}$$
				</p>
			</div>

			
			<h3 id="non-2">Proving Nonregularity: Pumping Lemma</h3>

			<h4>Infiniteness or Finiteness</h4>

			<p>
				Looking at given a DFA, can we determine whether or not it accepts a language of an infinite length? 
			</p>
			<p>
				Well, it must have a cycle that is (a) reachable from the start and (b) can reach the accept state: <b>cycle => inf words</b>
			</p>
			<p>
				But if we have infinite words, it must be necessary to have a cycle, since the machine itself is finite: <b>inf words => cycle</b>.
			</p>
			<p>
				Thus there is an if and only if. We can use this princple to find another way of proving <i>ir</i>regularity.
			</p>

			<h4>Pumping Lemma</h4>

			<div class="blue">
				<p>
					<b><i>Lemma.</i></b> <b>if</b> L is a regular language,
				</p>
				<p>
					<b>then</b> there exists an integer \(m \in \mathbb{Z}^+\), the <b>pumping number</b>, such that for <b>any</b> string \(w \in L : |w| > m\) (w longer than m), \(w\) can be decomposed into \(xyz\), where
					\begin{array} 
					& |xy| \leq m & |y| \geq 1 & \forall i \in \mathbb{N}_0,\, xy^i z \in L.
					\end{array}
					Usually referred to as "xy is <b>short</b>, y is nonempty". \(y\) is the string being "pumped": able to be repeated infinitely (i.e. cycle in the DFA).
				</p>
			</div>
			<p></p>
			<button class="collapsible">Proof... </button>
			<div class="ccontent">
				<p>
					<b><i>Proof.</i></b> Let \(M = (Q, \Sigma, q_0, F, \delta)\) be a DFA for a language L. Let \(m = |Q|\).
				</p>
				<ul>
					<li>
						Consider a <b>sufficiently long</b> word \(w \in L : |w| \geq m\) and the run of \(w\) on M: \[(r_0 r_1 \cdots r_{|w|}) : r_0 = q_0, r_{|w|} \in F, \forall j \in {0..|w|}\; r_j \in Q\]
						i.e. A run of \(|w|\) states.
					</li>
					<li>
						By the <b>pidgeonhole principle</b> (If you have \(n\) boxes and more than \(n\) items, at least one box will have two items in), there must be a loop in the list of states. That is, 
						\[\exists j_1, j_2 : j_1 < j_2 \land r_{j_1} = r_{j_2}\]
						Let's say this is the smallest possible \(j\)s; the earliest possible loop. This may be a self loop. 
						<br>
						<span class="grey">This is why we have to \(|w| \geq m\). There are only \(m-1\) "boxes" (\(q_0\) doesn't count the first time round, since we enter without reading) so we can pideonhole.</span>
					</li>
					<li>
						Since we say \(j_1\) is the <b>smallest possible</b>, either \(j_1 = 0\) or the partial run \((r_0 \cdots r_{j_1})\) has no repeating states, \(\therefore j_1 \leq |Q| = m\). <br>
						Also \((r_{j_1} \cdots r_{j_2})\) is a loop in the graph.
					</li>
					<li>
						Let \(x\) be the substring that runs over \((r_0 \cdots r_{j_1})\). <br>
						Let \(y\) be the substring that loops \((r_{j_1} \cdots r_{j_2})\).
						<br>
						Let \(z\) be the rest of \(w\). 
					</li>
					<li>
						Thus \(|y| &gt; 0 \land |xy| \leq m\).
					</li>
					<li>
						This loop of \(y\) can be repeated infinitely, or skipped entirely, thus it should be trivial that 
						\[\forall i \geq 0,\; x y^i z \in L. \tag*{$\Box$}\]
						
					</li>
				</ul>
			</div>

			<p>
				<span style="color: red;"><b>NOTE WELL</b></span> that this is <b>not an if and only if</b>. , and , but <b>not</b> pumpable strings \(\implies\) L regular.
				<ul>
					<li>L regular \(\implies\) pumpable strings</li>
					<li>Contrapositively unpumpable strings \(\implies\) L irregular</li>
					<li><b>but</b> pumpable strings \(\mathrel{\rlap{\hskip .75em/}}\implies\) L regular. You <b>cannot</b> use the pumping lemma to prove something <i>is</i> regular.</li>
				</ul>
			</p>
			<p>
				<b>Use the contrapositive</b> (unpumpable strings \(\implies\) L irregular) to prove irregular languages.
			</p>

			<div class="side">
				<p>
					Proof structure for using pumping lemma: <span class="bigred">This is mandatory and must be clearly shown</span>
				</p>
				<ol>
					<li>Suppose L is regular (for contrapositive). Then, there must be a pumping number \(m\) for L.</li>
					<li>Choose some string \(w \in L : |w| \geq m\).</li>
					<li>Let \(w = xyz\) be some arbitrary decomposition such that \(|xy| \leq m,\; |y| \geq 1\)</li>
					<li>Pick any integer \(i\) which breaks the pumping lemma: \(xy^iz \not \in L\)</li>
				</ol>
			</div>
			<p></p>

			<button class="collapsible">Example \(L = \{1^n : n \textrm{ is prime.}\} \)</button>
			<div class="ccontent">
				<ol>
					<li>
						<b><i>Proof.</i></b> Suppose L is reguar. Let \(m\) be the pumping length of L.
					</li>
					<li>
						Let our string \(w = 1^q : q \geq m\) and \(q\) is prime. 
					</li>
					<li>
						Split \(w\) arbitrarily into \(1^\alpha 1^\beta 1^\gamma : \alpha + \beta + \gamma = q.\)
					</li>
					<li>
						Let \(i = \alpha + \gamma\). Then \(xy^iz = 1^\alpha 1^{\alpha+\gamma} 1^\gamma = 1^{2\alpha + 2\gamma} = 1^{2(\alpha + \gamma)}\) which is <b>not</b> prime.
					</li>
				</ol>
				<p>
					Thus L is not regular by contrapositive of the pumping lemma. $$\tag*{$\Box$}$$
				</p>
			</div>
		</div>

		<div class="colourband">
			<h2 id="grammars">Grammars</h2>
		</div>

		<div class="cbox">
			<h3>Contents</h3>

			<ul>
				<li><a href="#gra-1">Grammars</a></li>
				<li><a href="#gra-2">Derivation</a></li>
				<li><a href="#gra-3">Chomsky's Heirarchy</a></li>
				<li><a href="#gra-4">DFA to Linear Grammars</a></li>
			</ul>
			<h3 id="gra-1">Grammars</h3>

			<p>
				A grammar is a series of rules to form words: <code>&lt;sentence&gt; -&gt; &lt;noun_phrase&gt; &lt;verb phrase&gt; &lt;noun phrase&gt;</code>
			</p>
			<p>
				Recall <i>Backus-Naur form</i> from A level Comp Sci. 
			</p>
			<div class="blue">
				<p>
					A grammar is a tuple \((V, \Sigma, R, S)\) where
					<ul>
						<li>\(V\) is a finite set of <b>variables</b> or non-terminals</li>
						<li>\(\Sigma\) is a finite alphabet (of <b>terminals</b>)</li>
						<li>\(R\) is a finite set of "production rules": the things that go \(\alpha \longrightarrow \beta\) where if you have an \(\alpha\) you can apply the rule and replace it with \(\beta\)</li>
						<li>
							\(S \in V\) is the <b>start variable</b>
						</li>
					</ul>
				</p>
			</div>

			<p>
				If \(\alpha \implies \beta\) then \(\alpha\) <b>yields</b> \(\beta\) (it might be a single not a double arrow but what do I care -- it's just an arrow.)
			</p>
			<p>
				If you can have a path of successive yields from the start variable, to a desired string \(w\), this is a <b>derivation</b> of \(w\) from G (the grammar). We write \(S \overset{*}{\implies} w\).
			</p>
			
			<button class="collapsible ">Example 1...</button>
			<div class="ccontent" >

				<p>
					<b><i>Example.</i></b> Let \(G = (\{S\}, \{0,1\}, R, S):\)
					\begin{align}
						R := S &\longrightarrow 0S1 \\
						S &\longrightarrow \epsilon
					\end{align}
				</p>
				<p>
					We can have \(S \implies 0S1 \implies 00S11 \implies 000S111 \implies 000111\)
				</p>
				<p>
					This path is a <b>derivation</b> of 000111 from G. S <b>yields</b> 0S1 which yields 00S11, etc. 
				</p>
				<p>
					We can see that these grammars are more powerful than Regular languages already, since this is \(\{0^n1^n\} \).
				</p>
			</div>

			<p class="blue">
				The <b>language</b> of a grammar \(L(G) = \{w \in \Sigma* : s \overset{*}{\implies} w \}\) -- that is, all strings derivable via G.
			</p>

			<button class="collapsible">Example 2...</button>
			<div class="ccontent">
				<p>
					<b><i>Example.</i></b> Take \(G = (\{S\}, \Sigma, R, S) :\)
					\[R := S \longrightarrow S\]
					\(L(G) = \varnothing\), since this grammar can never yield anything (because it never terminates)
				</p>
			</div>

			<h3 id="gra-2">Derivation</h3>

			<p>
				Take \(G = (\{S\}, \{0,1\}, R, S :\)
				\begin{align}
					R:= S &\longrightarrow 0S1S &\pod{r_1} \\
					S &\longrightarrow 1S0S &\pod{r_2} \\ 
					S &\longrightarrow \epsilon &\pod{r_0}
				\end{align}
			</p>
			<p>
				A <b>leftmost derivation</b> means always expanding the leftmost variable. 
				\[S \implies 0S1S \implies 01S0S1S \implies 0010S1S0S1S \implies \cdots \implies 010101.\]
				A rightmost derivation should thus be obvious.
			</p>
			<p>
				A <b>parse tree</b> shows the order of derivation in, unsurprisingly, a tree.
			</p>
			<figure>
				<img src="./cfgparsetree.png" alt="" style="max-width: 480px;">
			</figure>
			<p class="blue">
				A grammar is <b>ambiguous</b> if it can be generated via multiple parse trees (of a single directional derivation).
			</p>

			<p>
				Ambiguity is generally not desired, however it is a part of the <b>grammar</b>, and not the language itself.
			</p>
			<p>
				Most grammars can be rewritten to be non-ambiguous, but there are some <i>"inherently ambiguous"</i> grammars. 
			</p>

			<h3 id="gra-3">Chomsky's Heirarchy of Grammars</h3>

			<p>
				Yes, <i>That</i> Chomsky, the guy who also wrote stuff like <i>Manufacturing Consent</i>. 
			</p>
			<p>
				Chomsky puts grammars in a heirarchy, with each larger rank containing all the languages of the previous rank. 
			</p>
			<p>
				Given \(G = (V, \Sigma, R, S)\) and \(A, B \in V, x \in \Sigma*, \alpha, \beta, \gamma, w \in (V \cup \Sigma*)\), if
			</p>
			<ul>
				<li>
					<b><i>Type 3.</i></b>  
					\[
					\begin{array}{} A \longrightarrow xB \\ A \longrightarrow x \end{array} \;\;\textrm{  xor  }\;\;
					\begin{array}{} A \longrightarrow Bx \\ A \longrightarrow x \end{array}
					\]
					Are the only rule forms permitted, it is a <b>Regular language</b>, with the two forms being called <b>left</b> and <b>right</b> linear grammars respectively. 
				</li>
				<li>
					<b><i>Type 2.</i></b>
					\[A \longrightarrow w\]
					where \(w\) is any comibnation of variables and terminals, the language is a <b>context free language</b>
				</li>
				<li>
					<b><i>Type 1.</i></b>
					\[\alpha A \gamma \longrightarrow \alpha \beta \gamma\]
					i.e. we care what's around \(A\), then it is a <b>context sensitive language</b>.
				</li>
				<li>
					<b><i>Type 0.</i></b>
					\[\alpha \longrightarrow \beta\]
					i.e. go nuts, then it is a <b>recursively enumerable language</b>.
				</li>
			</ul>
			<p>
				In summary, 
				\[\textrm{Regular } \subset \textrm{ Cont. free } \subset \textrm{ Cont. Sens. } \subset \textrm{ Rec. Enumerable} \]
			</p>

			<h3 id="gra-4">DFA to L/R Linear Grammars</h3>

			<p>
				Whilst for a linear grammar \(x\) can be any string, in a <b>strictly</b> linear grammar, \(x\) has to be a single letter. This doesn't make the grammar any less powerful, just simpler to work with.
			</p>

			<h4>Right Linear</h4>

			<p>
				The general rule is
				\[
				\forall q, q' \in Q, a \in \Sigma,\textrm{ if } \delta(q,a) = q', \textrm{add rule } q \longrightarrow aq'
				\]
				\[
				\forall q \in F, \textrm{ add rule } q \longrightarrow \epsilon\]
			</p>
			
			<button class="collapsible">Example 3... </button>
			<div class="ccontent">
				<p>
					<b><i>Example.</i></b> Take the DFA shown with \(M = (Q = \{X,Y,S\}, \Sigma = \{a,b\}, S, F=\{S\}, \delta)\): 
					<figure>
						<img src="./dfa-to-linear-dfa.png" alt="" style="max-width: 300px;">
					</figure>
					This will make a grammar \(G = (V = \{S,X,Y\}, \Sigma, R, S)\) where the variables are just the states, however we now need to figure out what the production rules lead to. 
				</p>
				<p>
					The idea is to find all strings which will take us from the given one to an accept state. But we can start with just rewriting the state transition function:
					\begin{align}
						S &\longrightarrow \epsilon | bS | aX \\
						X &\longrightarrow bS | aY \\
						Y &\longrightarrow aY | bY 
					\end{align}
					We can then strip away dead states (Y) to get 
					\begin{align}
						R := S &\longrightarrow \epsilon | bS | aX \\
						X &\longrightarrow bS.
					\end{align}
					Which is a left linear grammar.
				</p>
			</div>
			
			<p>
				Again, cleaning up dead states is helpful, but <b>not necessary in the exam</b>.
			</p>

			<h4>Left Linear</h4>

			<p>
				Left linear grammars are slightly more difficult, since we're effectively <i>working backwards</i> from end to beginning. Thus, our accept state is our starting variable. 
			</p>
			<p>
				If there are multiple accept states, we can just \(\epsilon\)-transition all the accept states into one single state (since NFA \(\leq\) DFA, to use reducibility syntax)
			</p>
			<p>
				The start state \(q_0\) must of course also yield \(\epsilon\).
			</p>

			<button class="collapsible">Example 4...</button>
			<div class="ccontent">
				<p>
					<b><i>Example.</i></b> Take the following DFA 
					<figure>
						<img src="./dfa-to-left-lienar.png" alt="" style="max-width: 300px;">
					</figure>
					Our grammar will be \(G = (\{A,B,C,D,E\}, \{0,1\}, R, E)\) and 
					\begin{align}
						R := E &\longrightarrow B1 | A0 \\
						D &\longrightarrow E0 | E1 | C1 | D0 | D1 \\
						C &\longrightarrow B0 \\
						B &\longrightarrow A1 | C0 \\
						A &\longrightarrow \epsilon | C0
					\end{align}
					And since D is a dead state, we can clean it up to get
					\begin{align}
						R := E &\longrightarrow B1 | A0 \\
						C &\longrightarrow B0 \\
						B &\longrightarrow A1 \\
						A &\longrightarrow \epsilon | C0
					\end{align}
				</p>
			</div>
		</div>

		<div class="colourband">
			<h2 id="cfl">Context Free Languages</h2>
		</div>

		<div class="cbox">
			<h3>Introduction</h3>

			<ol>
				<li><a href="#cfl-1">Pushdown Automata</a></li>
				<li><a href="#cfl-2">CFGs to PDAs</a></li>
				<li><a href="#cfl-3">PDAs to CFGs</a></li>
				<li><a href="#cfl-4">Chomsky Normal Form</a></li>
				<li><a href="#cfl-5">String Testing</a></li>
				<li><a href="#cfl-6">Pumping Lemma</a></li>
			</ol>


			<p>
				A context free language (CFL) is simply one that is written using a <b>context free grammar</b>.
			</p>
			<p>
				Some examples of CFLs are
				\begin{align}
					L &= \{0^n1^n : n \geq 0\} \\
					L &= \{[(+)]*:\textrm{ brackets are balanced}\} \\
					L &= \{w\#w^R\} \pod{w^R\textrm{ meaning w is reversed}}
				\end{align}
				And we want a way to be able to parse them.
			</p>

			<h3 id="cfl-1">Pushdown Automata</h3>
			<p>
				We already have DFA and NFA for regular languages, why not augment them with something? A lot of context free languages can be parsed if you have a LiFo data structure, so why not add a <b>stack</b>?
			</p>
			<p>
				This makes a <b>push-down automaton</b>.
			</p>

			<div class="blue">
				<p>
					A <b>Pushdown Automaton (PDA)</b> is a machine \(M = (Q, \Sigma, \Gamma, \delta, q_0, F)\) where 
					<ul>
						<li>\(Q, \Sigma, q_0, F\) should all be things we've seen</li>
						<li>
							\(\Gamma\) is the <b>stack alphabet:</b> what symbols can be pushed to the stack. Usually includes all of \(\Sigma\) and a special \(\$\) symbol, which we'll use to represent <b>empty stack</b>.
						</li>
						<li>
							\(\delta : Q \times \Sigma_\epsilon \times \Gamma_\epsilon \longrightarrow 2^{Q \times \Gamma_\epsilon}\)
						</li>
					</ul>
					By default PDAs are <b>non-deterministic</b> -- we don't include dead states like NFAs.
				</p>
			</div>
			<p>
				PDA transitions are annotated \(a,c \longrightarrow b\), meaning <b>read</b> \(a\), <b>pop</b> \(c\), <b>push</b> \(b\):
				<figure><img src="./pda-notation.png" alt="" style="max-width: 160px;"></figure>
			</p>
			<ul>
				<li>
					Any of \(a,b,c\) can be \(\epsilon\) (i.e. don't pop, don't push, etc.)
				</li>
				<li>
					\(\epsilon,\epsilon \longrightarrow \$\) is what denotes the starting transition: "push $ and move".
				</li>
				<li>
					\(\epsilon, \$ \longrightarrow \epsilon\) is what denotes the end transition: "pop $ and move".
				</li>
			</ul>
			<p>
				The reason why we use $ is that, like C and arrays, a PDA doesn't know the length of its stack, so it's helpful to have an indicator (like <code>\0</code>)
			</p>

			<button class="collapsible">Example 1...</button>
			<div class="ccontent">
				<p>
					<b><i>Example.</i></b> The PDA for \(L = \{0^n1^n : n \geq 0 \} \) is 
					<figure><img src="./pda-1.png" alt="" style="max-width: 480px;"></figure>
				</p>
			</div>
			<button class="collapsible">Example 2...</button>
			<div class="ccontent">
				<p>
					<b><i>Example.</i></b> The PDA for \(L = \{w\#w^R\} \pod{w^R\textrm{ meaning w is reversed}}\) is 
					<figure><img src="./pda-2.png" alt="" style="max-width: 480px;"></figure>

				</p>
				<p class="grey">
					The language  \(L = \{w\#w\}\) is actually much more difficult, and is not solvable with a stack.
				</p>
			</div>
			<button class="collapsible">Example 3...</button>
			<div class="ccontent">
				<p>
					<b><i>Example.</i></b> The PDA for \(L = \{ww^R\}\) is slightly harder, since there's no indication of when they reverse. 
					<figure><img src="./pda-3.png" alt="" style="max-width: 630px;"></figure>
					Essentially at any time they could reverse, and we just non-deterministically move to the other state.s
				</p>
			</div>
			<p>
				Sometimes, we want to push a whole bunch of things for one input. The transition function can be <b>extended</b> to push a <b>string</b> instead: 
				\[a, c \longrightarrow b_1b_2\cdots b_r\]
				Which is equivalent to \(a,c \longrightarrow b_1\) followed by \(\epsilon,\epsilon \longrightarrow b_2\), ..., \(\epsilon, \epsilon \longrightarrow b_r\).
			</p>

			<div class="side">
				<p>
					A PDA \(M = (Q, \Sigma, \Gamma, q_0, F, \delta\) <b>accepts</b> a string \(w \in \Sigma*\) if 
					\begin{align}
						\exists w_1w_2 \cdots w_r &\in \Sigma_\epsilon \\ 
						\exists x_1x_2 \cdots x_r &\in Q \\
						\exists s_0s_1 \cdots s_r &\in \Gamma
					\end{align}
					such that \(x_0 = q_0, x_r \in F\); \(s_0 = \epsilon\), and 
					\[\forall i \in [0..r-1]\;\delta(x_i, w_{i+1}, a) \ni (x_{i+1}, b) \]
					where \(s_i = a \cdot t\) and \(s_{i+1} = b \cdot t\) for some \(a,b \in \Gamma_\epsilon\) and \(t \in \Gamma*\)
				</p>
				<p>
					Which is a complex way of saying, well, pretty much what you'd think "accept" means.
				</p>
				<p>
					But the thing to note somewhat is that the pairs of states and stack letters \((x_i, s_i)\) in sequence form the <b>run</b>.
				</p>
			</div>
			<blockquote>Pushdown Automata accept precisely the set of all context-free languages.</blockquote>

			<h3 id="cfl-2">CFGs to PDAs</h3>

			<p>
				We have a non-deterministic algorithm to compute the leftmost derivation of a string, should it exist.
			</p>
			<ul class="side">
				<li>Set <code>currentString</code> to \(s\)</li>
				<li>
					Do:
					<ul>
						<li>
							<b>if</b> the leftmost element of <code>currentString</code> is a variable A, <b>then</b> select any grammar rule for A, replace A by the other side of this rule, and record.
						</li>
						<li>
							<b>if</b> the leftmost is a terminal \(a\), <b>then</b> read next input, and check if is the same as \(a\). If so, remove \(a\). Else, <i>reject</i> the branch.
						</li>
						<li>
							<b>if</b> string is now empty, <b>then</b> <i>accept</i>, output recorded rules.
						</li>
					</ul>
				</li>
			</ul>
			<p>
				Thus, we have an algorithm to make a string from a grammar. 
			</p>
			<p>
				We can then convert this to a PDA compatible algorithm, namely:
			</p>

			<ul class="side">
				<li>
					Push \(s \cdot \$ \) onto the stack (last in first). 
				</li>
				<li>
					Do:
					<ul>
						<li>
							<b>If</b> top is a variable A, <b>then</b> select node for A, pop A and push right hand side. 
						</li>
						<li>
							<b>If</b> top is a terminal \(a\), <b>then</b> read the next symbol. If it's the same, pop \(a\).
						</li>
						<li>
							<b>If</b> top is \(\$\), <b>then</b> pop $ and accept.
						</li>
					</ul>
				</li>
			</ul>
			<p>
				We can thus make a machine with three states: a start \(q_s\), a loop \(q_2\), and an accept \(q_f\).
			</p>
			<figure class="blue"><img src="./cfg-to-pda-generic.png" alt="" style="max-width: 540px;"></figure>

			<p>
				i.e. just write all the rules on the middle \(q_2\).
			</p>

			<button class="collapsible">Example 4... </button>
			<div class="ccontent">
				<p>
					<b><i>Example.</i></b> Take \(L = \{0^n 1^n : n \geq 0\}\) which gives 
					\begin{align}
					R := S &\longrightarrow 0S1 \\
					S &\longrightarrow \epsilon
					\end{align}
					This makes a PDA which looks like 
				</p>
				<figure>
					<img src="./cfg-to-pda-ex4.png" alt="" style="max-width: 630px;">
				</figure>
			</div>

			<p>
				This is effectively brute forcing, but we can convert the grammar into a specific form which makes this deterministic (which will be covered later.)
			</p>

			<h3 id="cfl-3">PDAs to CFGs</h3>
			
			<p>
				To convert a PDA to a CFG, we want to first transform it into a <b>normalised</b> form:
			</p>

			<div class="blue">
				<p>
					A <b>normalised PDA</b> is:
				</p>
				<ul>
					<li>Has a single accept state \(q_f\). <span class="grey">Epsilon transition to a single \(q_f\) </span></li>
					<li>Never accept if the stack is non-empty <span class="grey">Have a state after original accepts which just empties the stack</span></li>
					<li>Each transition either pushes or pops, <b>not both, not none</b> <span class="grey">Separate out a push and pop transition into two, separate out an empty transition into one that pushes and one that pops the same item</span></li>
				</ul>
			</div>

			<p>
				Thus \(\forall p, q \in Q\), we have a variable \(A_{pq}\) (p can equal q)
			</p>
			<p>
				And \(A_pq\) generates all strings that can transition from \(p\) to \(q\), <i>with an empty stack at start and end</i>.
			</p>
			<p>
				Thus the language accepted is generated by \(A_{q_s q_f} \).
			</p>

			<ol class="side">
				<li>
					\(\forall p \in Q\), make a rule \(A_{pp} \longrightarrow G\). 
				</li>
				<li>
					\(\forall p,q,r \in Q\), make rule \(A_{pq} \longrightarrow A_{pr} A{_rq} \)
				</li>
				<li>
					\(\forall p,q,r,s \in Q,\; u \in \Gamma,\; \alpha, \beta \in \Sigma_\epsilon\) <span class="grey">(every 4 states, a stack letter \(u\), and letters \(\alpha, \beta\)))</span>, if the transition \(\delta(p,\alpha,\epsilon)\) can go to the state \(r\) and pushes \(u\) (contains \((r,u)\)), make a rule \(A_{pq} \longrightarrow \alpha A_{rs} \beta\).
					<figure>
						<img src="./pda-to-cfg-general.png" alt="" style="max-width: 630px;">
					</figure>
				</li>
			</ol>

			<h3 id="cfl-4">Chomsky Normal Form</h3>

			<p>
				Chomsky normal form is a normalised form of a CFG, which is helpful for certain algorithms. 
			</p>

			<div class="blue">
				<p>
					A CFG grammar \(G = (V,\Sigma,R,S)\) is in <b>Chomsky Normal Form (CNF)</b> if <b>every</b> production rule looks like one of the following
				</p>
				<ul>
					<li>\(S \longrightarrow \epsilon\)</li>
					<li>\(A \longrightarrow x\) where \(x\) is a terminal</li>
					<li>\(A \longrightarrow BC\) where \((B, C \in V) \land (B, C \neq S)\)</li>
				</ul>
			</div>
			<p class="side">
				<b><i>Theorem</i> (Sipser).</b> <b>Any</b> CFG can be converted to CNF. 
			</p>

			<h4>Conversion into CNF</h4>

			<p>
				"See violation, change violation":
			</p>
			<ul class="side">
				<li>
					Create a new start \(S_0 \longrightarrow S\) (if needed for start restriction)
					<button class="collapsible nul">Expand... </button>
					<div class="ccontent cnul">
						\[
					\begin{array}{rl}
						&S &\longrightarrow ASB \\
						&A &\longrightarrow aAS | a | \epsilon \\
						&B &\longrightarrow SbS | A | bb
					\end{array}
					\implies 
					\begin{array}{rl}
						&S_0 &\longrightarrow S \\
						&S &\longrightarrow ASB \\
						&A &\longrightarrow aAS | a | \epsilon \\
						&B &\longrightarrow SbS | A | bb
					\end{array}
					\]
					<!-- <hr> -->
					</div>
					
				</li>
				<li>
					Eliminate all \(A \longrightarrow \epsilon : A \neq S_0\), by essentially creating an new rule for every other variable, removing \(A\) (and replacing into \(\epsilon\) if needed):
					<button class="collapsible nul">Expand... </button>
					<div class="ccontent cnul">
						\[
					\begin{array}{rl}
						&S_0 &\longrightarrow S \\
						&S &\longrightarrow ASB \\
						&A &\longrightarrow aAS | a | \epsilon \\
						&B &\longrightarrow SbS | A | bb
					\end{array}
					\implies 
					\begin{array}{rl}
						&S_0 &\longrightarrow S \\
						&S &\longrightarrow ASB | SB \\
						&A &\longrightarrow aAS | a | aS \\
						&B &\longrightarrow SbS | A | bb | \epsilon
					\end{array}
					\implies 
					\begin{array}{rl}
						&S_0 &\longrightarrow S \\
						&S &\longrightarrow ASB | SB | AS | S \\
						&A &\longrightarrow aAS | a | aS \\
						&B &\longrightarrow SbS | A | bb 
					\end{array}
					\]
					</div>
					
					And repeat until all epsilons, including newly introduced ones, are gone (except on \(S_0\)). <b>Do not reintroduce \(\epsilon\) on variables that already had it eliminated.</b>
				</li>
				<li>
					Eliminate unit variables \(A \longrightarrow B\). Replace with \(A \longrightarrow w\) for every \(B \longrightarrow w\) production. Delete self references. 
					<button class="collapsible nul">Expand... </button>
					<div class="ccontent cnul">
						\[
						\begin{array}{rl}
						&S_0 &\longrightarrow S \\
						&S &\longrightarrow ASB | SB | AS | S \\
						&A &\longrightarrow aAS | a | aS \\
						&B &\longrightarrow SbS | A | bb 
					\end{array}
						\implies 
						\begin{array}{rl}
							&S_0 &\longrightarrow S \\
							&S &\longrightarrow ASB | SB | AS \\
							&A &\longrightarrow aAS | a | aS \\
							&B &\longrightarrow SbS | bb | aAS | a | aS
						\end{array}
						\implies 
						\begin{array}{rl}
						&S_0 &\longrightarrow ASB | SB | AS \\
						&S &\longrightarrow ASB | SB | AS \\
						&A &\longrightarrow aAS | a | aS \\
						&B &\longrightarrow SbS | bb | aAS | a | aS
					\end{array}
						\]
					</div>
				</li>
				<li>
					Add variables and rules to remove occurences \(A \longrightarrow u\) where \(u\) is either a string longer than 1, or a mixture of terminals and non-terminals.

					<button class="collapsible nul">Expand... </button>
					<div class="ccontent cnul">
						\[
						\begin{array}{rl}
							&S_0 &\longrightarrow ASB | SB | AS \\
							&S &\longrightarrow ASB | SB | AS \\
							&A &\longrightarrow aAS | a | aS \\
							&B &\longrightarrow SbS | bb | aAS | a | aS
						\end{array}
						\implies
						\begin{array}{rl}
							&S_0 &\longrightarrow AU_1 | SB | AS \\
							&S &\longrightarrow AU_1 | SB | AS \\
							&A &\longrightarrow aU_2 | a | aS \\
							&B &\longrightarrow SU_3 | bb | aU_2 | a | aS \\
							&U_1 &\longrightarrow SB \\
							&U_2 &\longrightarrow AS \\
							&U_3 &\longrightarrow bS \\
						\end{array}
						\implies
						\begin{array}{rl}
							&S_0 &\longrightarrow AU_1 | SB | AS \\
							&S &\longrightarrow AU_1 | SB | AS \\
							&A &\longrightarrow V_1 U_2 | a | V_1 S \\
							&B &\longrightarrow SU_3 | V_2 V_2 | V_1 U_2 | a | V_1 S \\
							&U_1 &\longrightarrow SB \\
							&U_2 &\longrightarrow AS \\
							&U_3 &\longrightarrow V_2 S \\
							&V_1 &\longrightarrow a \\
							&V_2 &\longrightarrow b
						\end{array}
						\]
						(The rule \(A \longrightarrow a\) is allowed.)
					</div>
				</li>
			</ul>

			<p >
				In CNF every string of length \(n\) can be derived in <b>exactly</b> \(2n-1\) steps,
			</p>
			<p>
				Since from 1 start variable, we get to \(n\) variables in \(n-1\) steps, and each variable maps to one terminal, adding \(n\) steps, \(\therefore 2n-1\) steps exactly.
			</p>

			<p>
				To test if a CFG generates anything at all, we can: 
			</p>
			<ol>
				<li>
					Mark all variables which produce a terminal on the RHS. 
				</li>
				<li>
					Mark all variables which produce a combination of terminals and already marked variables on the RHS 
				</li>
				<li>
					If S is not marked, then \(L(G) = \varnothing\).
				</li>
			</ol>

			<h3 id="cfl-5">String Testing</h3>

			<p>
				The <b>Cocke Younger Kasami (CYK) Algorithm</b> is used to test if a string is generated by a CFG (in CNF). 
			</p>
			<p>
				It is based off dynamic programming: for a string \(y = y_1y_2 \cdots y_n\), column \(j\) are the substrings that start at \(y_j\), and row \(i\) of column \(j\) means a substring starting with \(y_j\) and \(i\) letters long.
			</p>
			<p>
				Inside the array are stored <b>variables</b> which can generate that substring.
			</p>
			<p>
				The <b>top left</b> cell (\(6, y_0\), i.e. the entire string) <b>must contain</b> \(S\) for the derivation to be a success.
			</p>
			<p>
				The way the dynamic programming works is that for a square \(i, j\), it'll search <b>up</b> the columns, and <b>down</b> the diagonal, seeing if there's a production rule that makes this substring with any pair. 
			</p>
			<figure>
				<img src="./cyk-looking.png" alt="" style="max-width: 440px;">
			</figure>
			<p>
				For reference, here's an animation of a CYK run from wikipedia. 
			</p>
			<figure>
				<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/f5/CYK_algorithm_animation_showing_every_step_of_a_sentence_parsing.gif/440px-CYK_algorithm_animation_showing_every_step_of_a_sentence_parsing.gif" alt="" title="(Wikimedia Commons)" style="max-width: 440px;">
			</figure>
			<p>
				We can even stop the algorithm early if an entire row yields \(\varnothing\), since if a substring cannot be generated, how can the whole string?
			</p>
			<p>
				Given a string of length \(l\):
			</p>

			<div class="codediv">for \(i = 2 \cdots l-1\):
	for \(j = 1 \cdots l -(i-1)\):
		for \(p = 1 \cdots i-1\):
			\(M[i][j] \longleftarrow M[i][j] \cup LHS(M[p,j] \times M[i-p][j-p])\)</div>

			<p>
				Where \(LHS(P \times Q)\) are all variables \(J \in V :\) there exists a rule \(J \longrightarrow XY : X \in P, Y \in Q\).
			</p>
			<p>	
				With an efficiency of \(O(n^3 r)\) where \(n\) is the length of the string, and \(r\) is the number of grammar rules. 
			</p>


			<h3 id="cfl-6">Pumping Lemma</h3>

			<p>
				The idea is to look at parse trees. If a derived string is too long, a non terminal R must <b>repeat</b> on the <b>same branch</b> of a parse tree. 
			</p>

			<p>
				Thus we can define a \(w = uvxyz\), where \(x\) is created by the second R and \(v\) and \(y\) are the pre- and suffixes of \(x\) created by the first R:
			</p>
			<figure>
				<img src="./cfg-pumplemma-tree.png" alt="" style="max-width: 480px;">
			</figure>
			<p>
				Similar to the DFA loop, we can remove the second R, or reduplicate and add more Rs, giving us 
			</p>
			<div class="blue">
				<p>
					<b><i>Pumping Lemma.</i></b> Let L be a CFL. There exists a positive integer \(m : \forall w \in L \pod{|w| \geq m},\; \exists\) a <b>decomposition</b> \(uvxyz:\)
				</p>
				<ul>
					<li>
						\(|vxy| \leq m\) (\(vxy\) is short)
					</li>
					<li>\(|vy| \geq 1\)</li>
					<li>\(\forall i \in \mathbb{N}_0,\; uv^ixy^iz \in L.\)</li>
				</ul>
			</div>
			<p>
				But what is the pumping number? 
			</p>
			<ul>
				<li>
					Let \(b\) be the longest RHS generation (the longest single rule on a RHS). \(b\) is generally a "small" number (mathematically speaking), like 10.
				</li>
				<li>
					No leaf will have more than \(b\) children; the max degree is \(b\)
				</li>
				<li>
					For a tree of height \(h\), the number of leaves is at most \(b^h\)
				</li>
				<li>
					If a string is very long, and \(b\) is small, then the height must increase along with string length; longer string -> heigher height. 
				</li>
				<li>
					If \(h &gt; |V|\) (no. variables) then there must be a repeat of a variable. Thus, we want a parse tree height \(\geq |V| + 1\).
				</li>
			</ul>
			<p class="blue">
				Thus the pumping number \(m = b^{|V| + 1}\).
			</p>
			<p class="grey">
				This is by no means the smallest possible number -- it's an upper bound, which is sufficient.
			</p>

			<button class="collapsible">Proof... </button>
			<div class="ccontent">
				<p>
					<b><i>Proof.</i></b> Given L as a CFL, where \(\exists m &gt; 0 : \forall w \in L : |w| \geq m\), there is a decomposition \(w = uwxyz\) which satisfies the pumping lemma conditions. 
				</p>
				<ul>
					<li>
						Let \(G = (V,\Sigma, S, R)\) be the CFG generating L. 
					</li>
					<li>
						Let \(b = \max_{\textrm{rule }X \longrightarrow Y} |Y|\) (longest RHS rule)
					</li>
					<li>
						Let \(m = b^{|V| + 1} \)
					</li>
					<li>
						By <b>pidgeonhole principle</b>, \(\exists A \in V,\; \exists\) nodes \(\alpha, \beta \in\) internal nodes of the tree T, such that 
						<ul>
							<li>
								\(val(\alpha) = val(\beta) = A\)
							</li>
							<li>
								\(\alpha\) is the ancestor of \(\beta\)
							</li>
						</ul>
					</li>
					<li>
						<b>Claim</b> that the subtree of T rooted at \(\alpha\) has \(\leq b^{|V|+1} \) leaves. <b>Ensure</b> by picking \(\alpha\) such that its height \(\leq |V| + 1\).
					</li>
					<li>
						Let string \(x\) be yield of subtree rooted at \(\beta\).
					</li>
					<li>
						Let us have strings \(v,y : vxy\)  is yielded by subtree rooted at \(\alpha\).
					</li>
					<li>
						Let strings \(u,z : uvxyz\) is the yield of the root T. 
					</li>
					<li>
						\(\forall i \geq 0,\; uv^i xy^i z \in L\), since we can <b>pump up</b> by repeating \(\beta\), turning it into \(\beta \cdots \alpha\), and can <b>pump down</b> by removing \(\alpha\), and \(\alpha\) just having \(\beta\).
						<figure>
							<img src="./cfg-pumpup-pumpdown.png" alt="" style="max-width: 630px;">
						</figure>
					</li>
					
				</ul>
				<p>
					Thus the pumping lemma. \[\tag*{$\Box$}\]
				</p>
				
			</div>
		</div>

		<footer>
			<div class="cbox">
                <div class="columncontainer ctwo" id="fc2">
                </div>
                <script type="text/javascript" src="../../js/footerGen.js"></script>
            </div>
		</footer>

	</div>

	<script type="text/javascript" src="../../js/collapsible.js"></script>  <!--This stays at the end-->
	<script type="text/javascript" src="../../js/toggle-darklight.js"></script>
	<script type="text/javascript" src="../../js/prism.js"></script>
</body>
</html>