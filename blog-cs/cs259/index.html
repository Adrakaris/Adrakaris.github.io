<!DOCTYPE html>
<html>
<head>
	<title>CS259</title>
	<meta charset="utf-8">
	<link rel="stylesheet" type="text/css" href="../../style/style.css" media="all">  <!--TODO: CHANGE HREF-->
	<link rel="stylesheet" type="text/css" href="../../style/prism.css" media="all">
	<meta name="viewport" content="width=device-width" initial-scale=1.0>  <!--TODO: CHANGE LINKS ON BOTTOM OF SHEET FOR COLLAPSIBLE-->
	<link rel="icon" type="image/png" href="../../style/images/DragonIcon.png">
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

	<div class="hidden">
		<header>
			<div class="parallax parsmaller">
				<div  style="display: grid; grid-template-columns: 1fr 1fr 1fr 8fr 1fr; grid-column-gap: 10px; padding: 5px; ">
					<div class="column tinycolumn">
						<a href="../../" class="nav">Home</a>
					</div>
					<div class="column tinycolumn">
						<a href="../../blog.html" class="nav">Blog</a>
					</div>
					<div class="column tinycolumn">
						
						<a href="../../about.html" class="nav">About</a>
					</div>
					<div></div>
					<div class="column">
						<button class="nav dark-light">Dark Mode</button>
					</div>
				</div>
				<div class="cbox"> 		
					<h1>CS259</h1>
					<p class="subheading">Formal Languages</p>
				</div>
			</div>
		</header>

		<header>
			<div class="cbox">
				<h1>Introduction</h1>
			</div>
		</header>


		<div class="cbox">

			<h3>Contents</h3>
			<ol>
				<li><a href="#dfa">Deterministic Finite Automata</a></li>
				<li><a href="#nfa">Non-deterministic Finite Automata</a></li>
				<li><a href="#regex">RegEx</a></li>
				<li><a href="#nonreg">Non-Regular Languages</a></li>
				<li><a href="#grammars">Grammars</a></li>
				<li><a href="#cfl">Context Free Languages</a></li>
				<li><a href="#turing">Turing Machines</a></li>
			</ol>
			<h3>Languages</h3>
			<p class="blue">
				An <b>alphabet</b> is a <b>non-empty</b> set of symbols, usually denoted \(\Sigma = \{a,b,c,\dots\}\). \(\renewcommand{\epsilon}{\varepsilon}\)
			</p>
			<p class="blue">
				A <b>language</b> is then a (potentially infinte) set of <b>finite strings</b> (words) over an alphabet. The set of <b>all</b> words is denoted \(\Sigma*\).
			</p>
			<p>
				In CS, we can model every decision problem as a question "is a given string in a given language L?", thus, one can see the usefulness of formal languages.
			</p>
		</div>

		
		<div class="colourband">
			<h2 id="dfa">Deterministic Finite Automata</h2>
		</div>

		<div class="cbox">
			<h3>Contents</h3>

			<ol>
				<li><a href="#dfa-1">DFA</a></li>
				<li><a href="#dfa-2">Regular Languages</a></li>
			</ol>

			<h3 id="dfa-1">DFA</h3>

			<div class="blue">
				<p>
					A <b>deterministic finite automata</b> (DFA, also referred to as a finite state machine) is comprised of:
				</p>
				<ul>
					<li>\(Q\) the <i>finite</i> set of states</li>
					<li>\(\Sigma\) the alphabet set</li>
					<li>\(q_0 \in Q\) the start/initial state</li>
					<li>\(F \subseteq Q\) final/accept states</li>
					<li>\(\delta : Q \times \Sigma \longrightarrow Q\) the <b>transition function</b> between states.</li>
				</ul>
				<p>
					And is denoted by the 5-tuple \(M=(Q, \Sigma, q_0, F, \delta)\).
				</p>
				
			</div>
			<p>
				The DFA can either be represented in a state diagram, or in a transition table:
			</p>
			<figure>
				<img src="./dfa.png" alt="" style="max-width: 600px;">
				<figcaption>A DFA. Every "transition" the DFA reads one symbol from the input string. States which are double circled (or annotated with stars) are finish states, and states with a blank arrow pointing in are start states. There must be one arrow for every possible incoming letter.</figcaption>
			</figure>

			<div class="blue">
				<p>
					\(\varepsilon\) represents the <b>empty string</b>. Any DFA with an input of \(\varepsilon\) will halt immediately on the start state. \(\varepsilon \in \Sigma* \).
				</p>
				<p>
					\(L = \{\} = \varnothing\) is the <b>empty language</b> - note that \(L = \{\varepsilon\}\) is <i>not</i> empty.
				</p>
			</div>
			<p>
				A <b>monoid</b> is a tuple of a set, an associative binary equation, and an identity:
				<ul>
					<li>\((\mathbb{N}_0, +, 0)\) where + is integer addition, and \(\mathbb{N_0} \) are nonnegative integers.</li>
					<li>\((\Sigma*, \circ, \varepsilon)\) where \(\circ\) is string concat, is a monoid. </li>
				</ul>
			</p>
			<p>
				<i><b>Note well</b> that the concat symbol \(\circ\) can also be written \(\cdot\) or omitted entirely.</i>
			</p>

			<p class="side">
				Formally, the way a DFA computes can be defined with the help of the <b>extended transition function</b>:
				\[\hat{\delta} : Q \times \Sigma* \longrightarrow Q\]
				Which can be recursively defined (in a haskell <i>like</i> form) over a string \(w = w' \circ a\) as
				\begin{align}
					\hat{\delta}(q, \varepsilon) &= q\\
					\hat{\delta}(q, w' \circ a) &= \delta(\hat{\delta}(q, w'), a).
				\end{align}
			</p>

			<p class="side">
				The <b>accepted language</b> of a DFA \(M = (Q, \Sigma, q_0, F, \delta)\) is \(L(M)\), such that
				\[L(M) = \{ s \in \Sigma* : \hat{\delta} (q_0, s) \in F \}.\]
			</p>

			<div class="side">
				<p>The <b>run</b> of M on a word \(s\) is the path of states M goes through for \(s\):</p>
				
				<ul>
					<li>The run of M on \(\varepsilon\) is trivially \(q_0\)</li>
					<li>
						The run of M on a string \(s_0..s_n \neq \varepsilon\) is \(r_0..r_n\) such that
						\[r_0 = q_0,\; \forall i \in [1..n] \; r_i = \delta(r_{i-1}, s_i)\]
					</li>
				</ul>
			</div>

			<p class="side">
				The run is an <b>accepting run</b> is a run that ends in an accepting state, thus \(s\) is accepted if its run is accepting - we can also define \(L(M)\) using accepting runs.
			</p>

			<h3 id="dfa-2">Regular Languages</h3>

			<p class="blue">
				A language L is <b>regular</b> if it is accepted by some DFA. 
			</p>
			<p>
				Trivially, the empty language \(L=\varnothing\) is regular (any DFA with no accept states), and \(\Sigma* \) is regular (define \(\delta(q_0, \_) = q_0\)).
			</p>
			<p>
				Naturally not all languages are regular, one particular one to note is that the language of (binary) <b>palindromes</b> is <b>not</b> regular.	
			</p>
			<p>
				Since languages are sets of strings, we can naturally perform set operations: \(\overline{L}, L \cap M, L \cup M\). There are also a few string-specific operators, such as
				<ul>
					<li><code>reverse L</code>: reverse all strings in L</li>
					<li><code>truncate L n</code>: trim all strings in L to at most \(n\) long </li>
					<li><code>concat L1 L2</code>: like cross product, but concactenating strings together instead of tuple pairing</li>
				</ul>
				But the main question is: are the results of these operations also regular languages?
			</p>

			<p class="side">
				For <b>completement</b>: where \(\overline{L} = L \setminus \Sigma* \), this is <b>closed</b>, as one can just invert the accept and reject states of the DFA.
			</p>
			<p class="side">
				For <b>intersection</b>: given \(L_1, L_2\), \(L_1 \cap L_2\) is regular, this is <b>closed</b>. Given \(M_1 = (Q_1, \Sigma, q_1, F_1, \delta_1)\) and \(M_2 = (Q_2, \Sigma, q_2, F_2, \delta_2)\), we can construct an <b>intersection automaton</b> like the following:
			</p>

			<button class="collapsible active">Intersection Automation... </button>
			<div class="ccontent" style="display: block;">
				<p>
					We define \(M_3 = (Q, \Sigma, q_0, F, \delta)\) as the intersection automaton of \(M_1, M_2\), and define it like follows:
				</p>
				<ul>
					<li>\(Q = Q_1 \times Q_2\)</li>
					<li>\(q_0 = (q_1, q_2)\) (note how states are labelled with pairs)</li>
					<li>\(F = F_1 \times F_2\)</li>
					<li>\(\forall a \in \Sigma, \forall x \in Q_1, \forall y \in Q_2:\)
						\[\delta((x,y), a) = (\delta_1(x,a), \delta_2(x,a)).\]
					</li>
				</ul>
			</div>
			<p>
				Note that \(L_1\) regular, \(L_2\) regular \(\implies L_1 \cap L_2\) regular is a <b>one-way implication</b>. If we take \(L_1\) to be the set of palindromes, \(L_2\) being all zeroes 0*, their union is clearly regular, but the separate languages are not.
			</p>

			<p class="side">
				For <b>union</b>, this is also <b>closed</b>. We can similarly construct a union automaton.
			</p>

			<button class="collapsible active">Union Automaton... </button>
			<div class="ccontent" style="display: block;">
				<p>
					Given two machines \(M_1 = (Q_1, \Sigma, q_1, F_1, \delta)\) and \(M_2 = (Q_2, \Sigma, q_2, F_2, \delta)\) -- note the deltas are the same, construct a machine \(M_3 = (Q, \Sigma, q, F, \delta)\) as
					<ul>
						<li>\(Q = Q_1 \times Q_2\)</li>
						<li>\(q = (q_1, q_2)\)</li>
						<li>\(F = (F_1 \times Q_2) \cup (F_2 \times Q_1\)</li>
					</ul>
					To make the two \(\delta\)s the same, you can include the transitions in one as redundant transitions in the other.
				</p>
			</div>

			<p class="side">
				<b>Set difference</b> is <b>closed</b>, since \(L_1 \setminus L_2 = L_1 \cap \overline{L_2} \).
			</p>

			<p class="side">
				<b>Set reverse</b> \(L^{rev}\) is... well it's closed, but it's not so simple with only DFAs. Intuitively, we want to reverse all the arrows, and make all the finish states start states, and vice versa, but of course, more often than not, this'll break a DFA rules, which means we need to introduce another abstraction:
			</p>
		</div>

		<div class="colourband">
			<h2 id="nfa">Non-deterministic Finite Automata</h2>
		</div>

		<div class="cbox">

			<h3>Contents</h3>

			<ol>
				<li><a href="#nfa-1">NFAs</a></li>
				<li><a href="#nfa-2">Transition Functions, \(\varepsilon\)-closure, Runs</a></li>
			</ol>

			<h3 id="nfa-1">NFAs</h3>
			<p>
				A <b>non-deterministic finite automata</b>, an NFA, is like a DFA, but you no longer have so much of the restrictions. 
			</p>

			<div class="blue">
				<p>
					An <b>NFA</b> can be defined as a five tuple of
				</p>
				<ul>
					<li>\(Q\) a finite set of states</li>
					<li>\(\Sigma\) a finite alphabet</li>
					<li>\(q_0\) an initial state</li>
					<li>\(F \subseteq Q\) accept states</li>
					<li>\(\delta\) the transition function, <b>defined as</b>
						\[\delta : Q \times (\Sigma \cup \{\varepsilon\}) \longrightarrow 2^Q\]
					</li>
				</ul>
				<p>
					Yep - that's right, an NFA can have empty string transitions (epsilon transitions), and a single letter can lead to multiple (a set of) states. 
				</p>
			</div>

			<figure>
				<img src="./nfa.png" alt="" style="max-width: 500px;">
				<p>An NFA. Note the multiple possible transitions, missing transitions, and epsilon transitions.</p>
			</figure>

			<p>
				Going back to our \(L^{rev}\), we <i>still</i> can't have multiple start states, <i>however</i>, we can merely add a new start state, and add \(\varepsilon\)-transitions to all the would've-been start states.
			</p>

			<p>
				A DFA has a clear, linear progression, but how does an NFA run? An NFA runs like a multiple world theory, where every time the NFA encounters multiple possible transitions, the NFA "branches" into multiple worlds which each going to one possible transition.
			</p>
			<p>
				If an NFA world reaches a state with no possible transitions, it crashes, and is considered a <b>reject</b> by default. 
			</p>
			<p>
				As long as <b>at least one</b> world reaches a finish state, the NFA run is considered an <b>accept</b>.
			</p>

			<p>
				A computer simulating an NFA would basically be doing a brute force DFS/BFS search.
			</p>

			<figure>
				<img src="./nfa-worlds.png" alt="	" style="max-width: 420px;">
				<figcaption>
					An NFA branching, and one branch reaching a finish.
				</figcaption>
			</figure>

			<p>
				We can think of DFAs as being strict subsets of NFAs, where there can only be one world and other special conditions.
			</p>

			<h3 id="nfa-2">Transition Functions, \(\varepsilon\)-closure, Runs</h3>

			<p>
				Let's try to formally define NFAs. 
			</p>
			<div class="side">
				<p>
					We want to use \(\delta : Q \times \Sigma_\varepsilon \longrightarrow 2^Q\) to define \(\hat{\delta} \). (Note \(\Sigma_\varepsilon = \Sigma \cup \{\varepsilon\} \) for convenience). 
					\[\hat{\delta} : Q \times \Sigma* \longrightarrow 2^Q.\]
				</p>
				<p>
					Say that \(\forall q \in Q\, s \in \Sigma*,\; \hat{\delta}(q, s) =\) all states in Q such that there <b>exists a run</b> from \(q\) upon reading string \(s\). i.e. all reachable states.  
				</p>
				
			</div>

			<div class="side">
				<p>
					The <b>run</b> of an NFA M on a word \(s = s_1 .. s_n\) is the sequence of states \(r_0 .. r_n\), such that
					<ul>
						<li>\(r_0 = s_0\)</li>
						<li>\(\forall i \in [1..n], \; r_i \in \delta(r_{i-1}, s_i)\)</li>
					</ul>
					An <b>accepting run</b> is then a run which ends in an accept state.
				</p>
			</div>

			<p>
				To define the extended transition function however, we need to first of all look at <b>epsilon-closure</b>: ECLOSE().
			</p>

			<div class="side">
				<p>
					<b>Epsilon Closure</b> is a function \(\textrm{ECLOSE}: Q \longrightarrow 2^Q\) which denotes all states that can be reached from a starting state \(q\) only by \(\varepsilon\)-transitions. 
				</p>
				<p>
					Formally, \(\forall X \subseteq Q\):
					\begin{align}
						\textrm{ECLOSE}(\varnothing) &= \varnothing\\
						\textrm{ECLOSE}(X) &= \bigcup_{x \in X} \textrm{ECLOSE}(\{x\})
					\end{align}
				</p>
			</div>

			<div class="side">
				<p>
					The <b>Extended Transition Function</b> \(\hat{\delta}\) defined \(\forall q \in Q,\; \forall s \in \Sigma* \setminus \{\varepsilon\}: s = wa\) where \(w \in \Sigma* \;\land \;\; a \in \Sigma \). In plain english: for all states \(q\), and for all non-empty strings \(s\) which are decomposed into \(w\), the prefix, and \(a\), the last letter:

					\begin{align}
					\hat{\delta} (q, \varepsilon) &= \textrm{ECLOSE}(q)\\
					\hat{\delta} (q, wa) &= \textrm{ECLOSE}(\bigcup_{q' \in \hat{\delta}(q,w)} \delta(q',a))
					\end{align}
				</p>
			</div>

			<p>
				Thus, the language accepted by an NFA can be defined in two ways, either as the set of all strings whose extended transition functions contain some finish state,
				\[L(M) = \{s \in \Sigma* : \hat{\delta} (q_0, s) \cup F \neq \varnothing\}\]
				or the set of all strings which have an accepting run.
			</p>

			<h3 id="nfa-3">Reduction to DFA</h3>

			<p>
				Are NFAs more powerful than DFAs? And by that, we mean can NFAs accept languages which DFAs can't? 
			</p>
			<p>
				Well the answer to that is <b>no</b>. NFAs can reduce to DFAs. Similar to how one DFA can simulate two DFAs like in intersection automata, we can do something similar for simulating an NFA. 
			</p>
			<p>
				An NFA's state information can be captured by a <b>set</b> of states, so we can just have a DFA with states corresponding to \(2^Q\) in the NFA, and transitions between them. 
			</p>
			

			<div class="side">
				<p>
					<b><i>Subset Construction.</i></b> Let \(N = (Q, \Sigma, q_0, F, \delta)\) be the NFA we want to convert. Let the resulting DFA be denoted \(M = (Q_d, \Sigma, q_d, F_d, \delta_d)\).
				</p>
				<ul>
					<li>
						M has a state for every subset of N: \(Q_d = 2^Q\). This includes the empty subset \(\varnothing\), which simulates N "crashing".
					</li>
					<li>
						The start of NFA is \(q_0\), but since we have to consider \(\varepsilon\)-transitions, \(q_d = \textrm{ECLOSE}(q_0)\).
					</li>
					<li>
						Finish states are all subsets of N that contain N's finish states, \(F_d = \{X \subseteq Q : X \cap F \neq \varnothing\} \).
					</li>
					<li>
						Given a starting set \(X\) and a letter \(a\), we reach the set of all possible states reached in N by \(\delta(X,a)\) followed by ECLOSE:
						\begin{align}
							\delta_d (X,a) &= \bigcup_{x \in X} \textrm{ECLOSE}(\delta(X,a)) \\
							&= \{z : \textrm{ for some } x \in X, z \in \textrm{ ECLOSE}(\delta(X, a))\}
						\end{align}
					</li>
				</ul>
			</div>

			<p>
				Of course, drawing all of these states is <b>not feasible</b> for any significant number of NFA state0s, especially as there would probably be a lot of <b>redundant states</b>, and thus the machine should be built up incrementally. Start from \(\textrm{ECLOSE}(q_0)\) and work from there.
			</p>

			<p>
				In general, this means that a language is regular <br>
				&emsp;<b>iff</b> it is accepted by a DFA <br>
				&emsp;<b>iff</b> it is accepted by an NFA.
			</p>
		</div>
		
		<div class="colourband">
			<h2 id="regex">RegEx</h2>
		</div>

		<div class="cbox">
			<h3>Contents</h3>

			<ol>
				<li><a href="#reg-1">Regex</a></li>
				<li><a href="#reg-2">Regex to NFA</a></li>
				<li><a href="#reg-3">Generalised NFA</a></li>
			</ol>

			<h3 id="reg-1">Regex</h3>

			<div class="blue">
				<p>
					A <b>Regular Expression</b> (RegEx) is a compat way to describe a (regular) language. It can be defined with the following 6 rules:
				</p>
				<ul>
					<li>R = \(a\) for some \(a \in \Sigma\)</li>
					<li>R = \(\varepsilon\)</li>
					<li>R = \(\varnothing\)</li>
					<li>R = \(R_1 + R_2\) (<b>or</b>: \(R_1 \cup R_2\))</li>
					<li>R = \(R_1 \cdot R_2\) (<b>concat</b>: more often \(R_1 R_2\))</li>
					<li>R = \(R_1*\) (0 or more, called the <b>kleene star</b>)</li>
				</ul>
			</div>

			<p class="small">
				Sure, "regex" on most systems have way more symbols to make life easier, but this is sufficient to generate all regular languages.
			</p>

			<p>
				In terms of operator precedence, it goes \(*, \cdot, +\).
			</p>

			<p>
				Some examples then, over \(\Sigma = \{a,b\}\):
			</p>
			<ul>
				<li><code>(a+b)*</code>: effectively \(\Sigma* \).</li>
				<li><code>(a+b)*(a+bb)</code>, any word which ends in "a" or "bb".</li>
				<li><code>(aa)*(bb)*b</code>, any word made up of even "a"s followed by even "b"s, ending in a "b".</li>
				<li><code>(aa+b)*</code>, all consecutive "a"s must be of an even number.</li>
			</ul>
			<p>
				Often, if a regex can be understood in plain english, one can turn that regex into a DFA or NFA directly via creative thinking, but there is a modular algorithmic way of doing so, since 
			</p>
			

			<h3 id="reg-2">Regex to NFA</h3>

			<p class="side">
				<b><i>Theorem.</i></b> A language is accepted by an NFA/DFA \(\iff\) it is generated by a regex.
			</p>

			<p>
				<b><i>Proof.</i></b> We have two algorithms, one to turn a regex to an NFA, and vice-versa.
			</p>

			<h4>Regex to NFA</h4>

			<p>
				This can be done modularly based on the recursive definition of a regex string. Our base cases (below) can be modelled by three different "modules":
			</p>
			<figure>
				<img src="./regex-dfa-base.png" alt="" title="R=a: ->()-a>(accept). R=ε: ->(accept). R=nothing: ->()" style="max-width: 500px;">
			</figure>
			<p>
				Then we have our recursive / inductive cases: \(R_1 + R_2\), \(R_1 \cdot R_2\), and \(R*\). A rectangle, in this case, represents a whole machine. 
			</p>
			<figure>
				<img src="./regex-dfa-recursive.png" alt="" style="max-width: 420px;" title="OR: e-transition to both machines from a common state. CONCAT: Connect all accept states of first to start of second (and make the accept states of first not accept). STAR: Make a new initial accept state, connect all accept states of machine to this state.">
			</figure>

			<p>
				As an aside have a think about the language \(\varnothing* \). What does that make? Well, concating \(\varnothing\) with anything is just ... \(\varnothing\), but the definition of kleene star is 0 or more times: i.e. \(\{\varepsilon\} \cup \varnothing \cup \varnothing^2 \cup \dots\), thus \(\varnothing* = \{\varepsilon\}.\)
			</p>

			<h4>NFA to Regex</h4>

			<p>
				This is better explained going along with an example:
			</p>
			<figure><img src="./dfa-regex/st1.png" alt="" style="max-width: 420px;"></figure>
			<p>
				Our goal is to slowly eliminate all the nodes one at a time, reflecting their effect by changing arcs into smaller <i>regex expressions</i>. First though, we need to add a start \(q_s\) and unique final \(q_f\) state and transition to them with epsilon:
			</p>
			<figure><img src="./dfa-regex/st2.png" alt="" style="max-width: 420px;">
				<figcaption>The start state is a source and the finish state is a sink</figcaption>
			</figure>
			<p>
				Start by eliminating \(q_3\). Possible paths are \(\langle q_2,q_3,q_2 \rangle :10*\) and \(\langle q_2, q_3, q_f\rangle : 1\varepsilon = 1\). Thus, we can have a self loop on \(q_2\) to be \(10*\) and modify \(q_2 \longrightarrow q_f\) to be \(1 + \varepsilon\)* to represent the two possible choices. Then, \(q_3\) becomes redundant and can be removed.
			</p>
			<figure>
				<img src="./dfa-regex/st3.png" alt="" style="max-width: 210px;">
			</figure>
			<p>
				* Technically, the transition \(q_2 \longrightarrow q_f : \varepsilon\) remains unaffected, but since we also have a new transition \(q_2 \longrightarrow q_f : 1\), we <i>simplify</i> the two parallel transitions into one: \(1 + \varepsilon\). This is very important to note.
			</p>
			<p>
				Eliminate \(q_2\) using a similar process. 
			</p>
			<figure>
				<img src="./dfa-regex/st4.png" alt="" style="max-width: 420px;">
			</figure>
			<p>
				Eliminate \(q_1\)
			</p>
			<figure><img src="./dfa-regex/st5.png" alt="" style="max-width: 420px;"></figure>
			<p>
				Finally, eliminate \(q_0\)
			</p>
			<figure><img src="./dfa-regex/st6.png" alt="" style="max-width: 420px;"></figure>
			<p>
				Then, we simply read off the last remaining transition for our regex. 
			</p>
			<p>
				Now sure, it's not the cleanest, shortest, or most efficient, but it <i>is</i> a regex, and that's all that matters.
				$$\tag*{$\Box$}$$
			</p>

			<h3 id="reg-3">Generalised NFA</h3>

			<div class="blue">
				<p>
					A <b>Generalised NFA (GNFA)</b> is a tuple \((Q, \Sigma, \delta, q_{start}, q_{accept})\) where 
					\[\delta : (Q \setminus \{q_{accept}\}) \times (Q \setminus \{q_{start})\} \longrightarrow \mathfrak{R}.\]
					Which the fraktur blackletter \(\mathfrak{R}\) means the set of <b>all regular expressions</b>.
				</p>
				<p>
					For simplicity \(q_0 = q_{start}\) and \(q_f = q_{accept} \). Note the <b>unique</b> start and finish states.
				</p>
				<p>
					\(q_0\) must be a <b>source</b> with outgoing transitions to <b>all</b> other states. <br>
					\(q_f\) must be a <b>sink</b> with incoming transitions from <b>all</b> other states. 
				</p>
				<p>
					These transitions can be \(\varnothing\), i.e. nothing.
				</p>
			</div>

			<p class="side">
				The <b>run</b> of a GNFA M on a word \(s\) is a sequence of states \(r_0 .. r_n\) such that \(r_0 = q_0\), and 
				\[\exists s_1 .. s_n \in \Sigma* : s = s_1 .. s_n \textrm{ and } \forall i \in [1..n] \; s_i \in L(\delta(r_{i-1}, r_i)).\]
				Plain english: \(s\) can be broken down into <b>substrings</b> such that there is a transition that matches each substring.
			</p>

			<p class="side">
				<b><i>Theorem.</i></b> Every NFA can be converted to an equivalent GNFA. This is techically what we have done in the <i>NFA to Regex</i> section, but with the \(\varnothing\) lines omitted for simplicity, which they often can be.
			</p>
			<p>
				With this fact we can now define our <b>elimination process</b> using some very complicated maths language. 
			</p>
			<div class="side">
				<img src="./gnfa-elim.png" alt="" align="right" style="max-width: 315px;">
				<p>
					<b>Assuming</b> we have <b>already converted</b> our NFA to a GNFA, and we want to eliminate a state \(q_1\), then for all pairs \(q_a, q_b \in (Q \setminus \{q_f, q_1\}) \times (Q \setminus \{q_0, q_1\}\) (pairs which do not include start and finish states):

					\begin{align}
						\delta' (q_a, q_b) &= \delta(q_a, q_b) \\
						&+ \delta(q_a, q_1) \cdot [\delta(q_1, q_1)*] \cdot \delta(q_1, q_b).
					\end{align}

					i.e. The existing a to b, or a to 1, any number of 1s, then 1 to b.
				</p>
			</div>
		</div>

		<div class="colourband">
			<h2 id="nonreg">Non-Regular Languages</h2>
		</div>

		<div class="cbox">
			<h3>Introduction</h3>

			<ol>
				<li><a href="#non-1">Myhill-Nerode</a></li>
				<li><a href="#non-2">Pumping Lemma</a></li>
			</ol>

			<p>
				Let \(L = \{0^n1^n : n \in \mathbb{N}\}\): i.e. equal number of zeroes and ones. Is this regular?
			</p>
			<p>
				Intuitively, it isn't, since one would need to keep track of both the number of zeroes and ones, and thus would need inifite memory, impossible on a <i>finite</i> state machine. But how do we formally prove this? 
			</p>

			<p>
				We can use <b>closure properties</b>, especially because its quick:
			</p>

			<button class="collapsible">Example \(L = \{w \in \{0, 1\}* : n_0 = n_1\} \)</button>
			<div class="ccontent">
				<p>
					<b><i>Proof.</i></b> i.e binary strings with equal zeroes and ones. Suppose L is regular. We know \(0*1*\) is regular, thus by closure properties \(0*1* \cap L\) should be regular ... right?
				</p>
				<p>
					Nope: \(0*1* \cap L = 0^n 1^n\) which is known to be irregular. $$\tag*{$\Box$}$$
				</p>
			</div>

			<p>
				But if we can't, there's two main ways.
			</p>

			<h3 id="non-1">Proving Nonregularity: Myhill-Nerode</h3>

			<p>
				If \(\hat{\delta}(q_0, \textrm{cat}) = \hat{\delta}(q_0, \textrm{rabbit}) = \hat{\delta}(q_0, \textrm{rat})\), then we can say these three strings are <b>equivalent</b>.
			</p>
			<p>
				These can be thought of as <b>equivalent relations</b> (remember cs130?), and following on from this, we can partition \(\Sigma* \) into <b>equivalence classes</b> based on what states they end up in. 
			</p>


			

			<p class="blue">
				<b><i>Definition.</i></b> The <b>index</b> of a language is its <b>number of equivalence classes</b>. This can be written \(\equiv_L\).
			</p>

			<div class="blue">
				<p>
					Strings \(x,y\) are <b>distinguishable</b> in language L, if there exists a <b>certifier</b> string \(z \in \Sigma* \), such that \(xz \in L\) and \(yz \not \in L\).
				</p>
				<p>
					Conversely, if two strings \(x,y\) are <b>indistinguishable</b>, we write \(x \equiv_L y\) where L is the language we're talking about. 
				</p>
				
			</div>
			<p>
				<b>Note: \(x, y\) both do <i>not</i> have to be in L. As long as \(xz \in L\) and \(yz \not \in L\) then this is sufficient.</b>
			</p>

			<p>
				Since DFAs have finite states, a regular language must have <b>finite equivalence classes</b>.
			</p>
			<p>
				Thus if a language has infinite equivalence classes, it can't be regular:
			</p>
			
			<p class="blue">
				<b><i>Theorem.</i> (Myhill-Nerode)</b> L is a regular language <b>if and only if</b> \(\equiv_L\) is finite.
			</p>

			<div class="side">
				<p>
					Proof structure for Myhill-Nerode:
				</p>
				<ol>
					<li>Come up with an infinite set of strings.</li>
					<li><b>Either</b>: Come up with a cerificate for a string \(i\) that distinguishes \(i\) from every other string simultaneously</li>
					<li><b>Or</b>: Come up with separate certificates that distinguish every \(i,j\) pair separately</li>
				</ol>
				<p>i.e, prove <b>pairwise distinguishability</b>.</p>
			</div>

			<button class="collapsible">Example \(L=\{0^n1^n : n \in \mathbb{N}\} \)</button>
			<div class="ccontent">
				<p>
					<b><i>Example.</i></b> Take the set of strings \(0* = \{\epsilon, 0, 00, 000, \dots\} \). We claim that these are all pairwise distinguishable.
				</p>
				<p>
					<b><i>Proof.</i></b> For string \(0^k\), take string \(1^k\) as certifier. That is: 0 has certificate 1, 00 has 11, 000 has 111, etc. 
				</p>
				<p>
					Note that for 0 with certificate 1, \(01 \in L\) but \(001 \not \in L, 002 \not \in L, \dots\) Same goes for all the others.
				</p>
				<p>
					Thus every string is pairwise distinguisable from every other. $$\tag*{$\Box$}$$
				</p>
				
			</div>

			<button class="collapsible">Example \(L = \{w : w \in \{a,b\}*, n_a(w) < n_b(w)\}\)</button>
			<div class="ccontent">
				<p>
					<b><i>Example.</i></b> This language is basically words with less "a"s than "b"s. 
				</p>
				<p>
					<b><i>Proof.</i></b> Take the set of strings \(a*\). For string \(a^r\), string \(b^{r+1} \) distinguishes \(a^r\) from every string \(a^s : s > r\). Thus, we can always find a distinguisher.
					$$\tag*{$\Box$}$$
				</p>
			</div>

			<button class="collapsible">Example \(L = \{1^n : n \textrm{ is prime}\} \)</button>
			<div class="ccontent">
				<p>
					<b><i>Proof.</i></b> Take the set of strings \(1*\). We need to individually pairwise distinguish them this time.
				</p>
				<p>
					Take any two strings \(1^i, 1^j\) (assuming \(i &lt; j\) for convenience). Pick any prime \(p : p &lt; i \land p &gt; 2\) <br>
					&emsp;\(\implies p + 0(j-i)\) is prime, obviously.
				</p>
				<p>
					Since \(p > 2,\; j-i > 0,\; p + p(j-i)\) is <i>not</i> prime.
				</p>
				<p>
					Thus let's look at the series \(s_n = p + n(j-1)\). i.e.
					\begin{align}
						&p + 0(j-i) \\
						&p + 0(j-i) \\
						&\vdots \\
						&p + (p-1)(j-i) \\
						&p + p(j-i) \\
					\end{align}
					there must be a <b>switch</b> from being prime to not being prime, between \(s_0\) and \(s_p\). Let \(k \in [1..p] \) be the <b>first</b> such switch at \(s_k = p + k(j-i)\).
				</p>
				<p>
					Thus, \(p + (k-1)(j-i)\) is prime whilst \(p + k(j-1)\) is not. Therefore, we make the certificate
					\[z = 1^{p + (k-1)(j-i) -i}.\]
					Note that
					\[1^i \cdot z = 1^{p + (k-1)(j-i)} \textrm{ which is prime,}\]
					Whereas
					\[i^j \cdot z = 1^{p + (k-1)(j-i) + (j-1)} = 1^{p + k(j-i)} \textrm{ which is not.}\]
					That was involved. $$\tag*{$\Box$}$$
				</p>
			</div>

			
			<h3 id="non-2">Proving Nonregularity: Pumping Lemma</h3>

			<h4>Infiniteness or Finiteness</h4>

			<p>
				Looking at given a DFA, can we determine whether or not it accepts a language of an infinite length? 
			</p>
			<p>
				Well, it must have a cycle that is (a) reachable from the start and (b) can reach the accept state: <b>cycle => inf words</b>
			</p>
			<p>
				But if we have infinite words, it must be necessary to have a cycle, since the machine itself is finite: <b>inf words => cycle</b>.
			</p>
			<p>
				Thus there is an if and only if. We can use this princple to find another way of proving <i>ir</i>regularity.
			</p>

			<h4>Pumping Lemma</h4>

			<div class="blue">
				<p>
					<b><i>Lemma.</i></b> <b>if</b> L is a regular language,
				</p>
				<p>
					<b>then</b> there exists an integer \(m \in \mathbb{Z}^+\), the <b>pumping number</b>, such that for <b>any</b> string \(w \in L : |w| > m\) (w longer than m), \(w\) can be decomposed into \(xyz\), where
					\begin{array} 
					& |xy| \leq m & |y| \geq 1 & \forall i \in \mathbb{N}_0,\, xy^i z \in L.
					\end{array}
					Usually referred to as "xy is <b>short</b>, y is nonempty". \(y\) is the string being "pumped": able to be repeated infinitely (i.e. cycle in the DFA).
				</p>
			</div>
			<p></p>
			<button class="collapsible">Proof... </button>
			<div class="ccontent">
				<p>
					<b><i>Proof.</i></b> Let \(M = (Q, \Sigma, q_0, F, \delta)\) be a DFA for a language L. Let \(m = |Q|\).
				</p>
				<ul>
					<li>
						Consider a <b>sufficiently long</b> word \(w \in L : |w| \geq m\) and the run of \(w\) on M: \[(r_0 r_1 \cdots r_{|w|}) : r_0 = q_0, r_{|w|} \in F, \forall j \in {0..|w|}\; r_j \in Q\]
						i.e. A run of \(|w|\) states.
					</li>
					<li>
						By the <b>pidgeonhole principle</b> (If you have \(n\) boxes and more than \(n\) items, at least one box will have two items in), there must be a loop in the list of states. That is, 
						\[\exists j_1, j_2 : j_1 < j_2 \land r_{j_1} = r_{j_2}\]
						Let's say this is the smallest possible \(j\)s; the earliest possible loop. This may be a self loop. 
						<br>
						<span class="grey">This is why we have to \(|w| \geq m\). There are only \(m-1\) "boxes" (\(q_0\) doesn't count the first time round, since we enter without reading) so we can pideonhole.</span>
					</li>
					<li>
						Since we say \(j_1\) is the <b>smallest possible</b>, either \(j_1 = 0\) or the partial run \((r_0 \cdots r_{j_1})\) has no repeating states, \(\therefore j_1 \leq |Q| = m\). <br>
						Also \((r_{j_1} \cdots r_{j_2})\) is a loop in the graph.
					</li>
					<li>
						Let \(x\) be the substring that runs over \((r_0 \cdots r_{j_1})\). <br>
						Let \(y\) be the substring that loops \((r_{j_1} \cdots r_{j_2})\).
						<br>
						Let \(z\) be the rest of \(w\). 
					</li>
					<li>
						Thus \(|y| &gt; 0 \land |xy| \leq m\).
					</li>
					<li>
						This loop of \(y\) can be repeated infinitely, or skipped entirely, thus it should be trivial that 
						\[\forall i \geq 0,\; x y^i z \in L. \tag*{$\Box$}\]
						
					</li>
				</ul>
			</div>

			<p>
				<span style="color: red;"><b>NOTE WELL</b></span> that this is <b>not an if and only if</b>. , and , but <b>not</b> pumpable strings \(\implies\) L regular.
				<ul>
					<li>L regular \(\implies\) pumpable strings</li>
					<li>Contrapositively unpumpable strings \(\implies\) L irregular</li>
					<li><b>but</b> pumpable strings \(\mathrel{\rlap{\hskip .75em/}}\implies\) L regular. You <b>cannot</b> use the pumping lemma to prove something <i>is</i> regular.</li>
				</ul>
			</p>
			<p>
				<b>Use the contrapositive</b> (unpumpable strings \(\implies\) L irregular) to prove irregular languages.
			</p>

			<div class="side">
				<p>
					Proof structure for using pumping lemma: <span class="bigred">This is mandatory and must be clearly shown</span>
				</p>
				<ol>
					<li>Suppose L is regular (for contrapositive). Then, there must be a pumping number \(m\) for L.</li>
					<li>Choose some string \(w \in L : |w| \geq m\).</li>
					<li>Let \(w = xyz\) be some arbitrary decomposition such that \(|xy| \leq m,\; |y| \geq 1\)</li>
					<li>Pick any integer \(i\) which breaks the pumping lemma: \(xy^iz \not \in L\)</li>
				</ol>
			</div>
			<p></p>

			<button class="collapsible">Example \(L = \{1^n : n \textrm{ is prime.}\} \)</button>
			<div class="ccontent">
				<ol>
					<li>
						<b><i>Proof.</i></b> Suppose L is reguar. Let \(m\) be the pumping length of L.
					</li>
					<li>
						Let our string \(w = 1^q : q \geq m\) and \(q\) is prime. 
					</li>
					<li>
						Split \(w\) arbitrarily into \(1^\alpha 1^\beta 1^\gamma : \alpha + \beta + \gamma = q.\)
					</li>
					<li>
						Let \(i = \alpha + \gamma\). Then \(xy^iz = 1^\alpha 1^{\alpha+\gamma} 1^\gamma = 1^{2\alpha + 2\gamma} = 1^{2(\alpha + \gamma)}\) which is <b>not</b> prime.
					</li>
				</ol>
				<p>
					Thus L is not regular by contrapositive of the pumping lemma. $$\tag*{$\Box$}$$
				</p>
			</div>
		</div>

		<div class="colourband">
			<h2 id="grammars">Grammars</h2>
		</div>

		<div class="cbox">
			<h3>Contents</h3>

			<ul>
				<li><a href="#gra-1">Grammars</a></li>
				<li><a href="#gra-2">Derivation</a></li>
				<li><a href="#gra-3">Chomsky's Heirarchy</a></li>
				<li><a href="#gra-4">DFA to Linear Grammars</a></li>
			</ul>
			<h3 id="gra-1">Grammars</h3>

			<p>
				A grammar is a series of rules to form words: <code>&lt;sentence&gt; -&gt; &lt;noun_phrase&gt; &lt;verb phrase&gt; &lt;noun phrase&gt;</code>
			</p>
			<p>
				Recall <i>Backus-Naur form</i> from A level Comp Sci. 
			</p>
			<div class="blue">
				<p>
					A grammar is a tuple \((V, \Sigma, R, S)\) where
					<ul>
						<li>\(V\) is a finite set of <b>variables</b> or non-terminals</li>
						<li>\(\Sigma\) is a finite alphabet (of <b>terminals</b>)</li>
						<li>\(R\) is a finite set of "production rules": the things that go \(\alpha \longrightarrow \beta\) where if you have an \(\alpha\) you can apply the rule and replace it with \(\beta\)</li>
						<li>
							\(S \in V\) is the <b>start variable</b>
						</li>
					</ul>
				</p>
			</div>

			<p>
				If \(\alpha \implies \beta\) then \(\alpha\) <b>yields</b> \(\beta\) (it might be a single not a double arrow but what do I care -- it's just an arrow.)
			</p>
			<p>
				If you can have a path of successive yields from the start variable, to a desired string \(w\), this is a <b>derivation</b> of \(w\) from G (the grammar). We write \(S \overset{*}{\implies} w\).
			</p>
			
			<button class="collapsible ">Example 1...</button>
			<div class="ccontent" >

				<p>
					<b><i>Example.</i></b> Let \(G = (\{S\}, \{0,1\}, R, S):\)
					\begin{align}
						R := S &\longrightarrow 0S1 \\
						S &\longrightarrow \epsilon
					\end{align}
				</p>
				<p>
					We can have \(S \implies 0S1 \implies 00S11 \implies 000S111 \implies 000111\)
				</p>
				<p>
					This path is a <b>derivation</b> of 000111 from G. S <b>yields</b> 0S1 which yields 00S11, etc. 
				</p>
				<p>
					We can see that these grammars are more powerful than Regular languages already, since this is \(\{0^n1^n\} \).
				</p>
			</div>

			<p class="blue">
				The <b>language</b> of a grammar \(L(G) = \{w \in \Sigma* : s \overset{*}{\implies} w \}\) -- that is, all strings derivable via G.
			</p>

			<button class="collapsible">Example 2...</button>
			<div class="ccontent">
				<p>
					<b><i>Example.</i></b> Take \(G = (\{S\}, \Sigma, R, S) :\)
					\[R := S \longrightarrow S\]
					\(L(G) = \varnothing\), since this grammar can never yield anything (because it never terminates)
				</p>
			</div>

			<h3 id="gra-2">Derivation</h3>

			<p>
				Take \(G = (\{S\}, \{0,1\}, R, S :\)
				\begin{align}
					R:= S &\longrightarrow 0S1S &\pod{r_1} \\
					S &\longrightarrow 1S0S &\pod{r_2} \\ 
					S &\longrightarrow \epsilon &\pod{r_0}
				\end{align}
			</p>
			<p>
				A <b>leftmost derivation</b> means always expanding the leftmost variable. 
				\[S \implies 0S1S \implies 01S0S1S \implies 0010S1S0S1S \implies \cdots \implies 010101.\]
				A rightmost derivation should thus be obvious.
			</p>
			<p>
				A <b>parse tree</b> shows the order of derivation in, unsurprisingly, a tree.
			</p>
			<figure>
				<img src="./cfgparsetree.png" alt="" style="max-width: 480px;">
			</figure>
			<p class="blue">
				A grammar is <b>ambiguous</b> if it can be generated via multiple parse trees (of a single directional derivation).
			</p>

			<p>
				Ambiguity is generally not desired, however it is a part of the <b>grammar</b>, and not the language itself.
			</p>
			<p>
				Most grammars can be rewritten to be non-ambiguous, but there are some <i>"inherently ambiguous"</i> grammars. 
			</p>

			<h3 id="gra-3">Chomsky's Heirarchy of Grammars</h3>

			<p>
				Yes, <i>That</i> Chomsky, the guy who also wrote stuff like <i>Manufacturing Consent</i>. 
			</p>
			<p>
				Chomsky puts grammars in a heirarchy, with each larger rank containing all the languages of the previous rank. 
			</p>
			<p>
				Given \(G = (V, \Sigma, R, S)\) and \(A, B \in V, x \in \Sigma*, \alpha, \beta, \gamma, w \in (V \cup \Sigma*)\), if
			</p>
			<ul>
				<li>
					<b><i>Type 3.</i></b>  
					\[
					\begin{array}{} A \longrightarrow xB \\ A \longrightarrow x \end{array} \;\;\textrm{  xor  }\;\;
					\begin{array}{} A \longrightarrow Bx \\ A \longrightarrow x \end{array}
					\]
					Are the only rule forms permitted, it is a <b>Regular language</b>, with the two forms being called <b>right</b> and <b>left</b> linear grammars respectively. 
				</li>
				<li>
					<b><i>Type 2.</i></b>
					\[A \longrightarrow w\]
					where \(w\) is any comibnation of variables and terminals, the language is a <b>context free language</b>
				</li>
				<li>
					<b><i>Type 1.</i></b>
					\[\alpha A \gamma \longrightarrow \alpha \beta \gamma\]
					i.e. we care what's around \(A\), then it is a <b>context sensitive language</b>.
				</li>
				<li>
					<b><i>Type 0.</i></b>
					\[\alpha \longrightarrow \beta\]
					i.e. go nuts, then it is a <b>recursively enumerable language</b>.
				</li>
			</ul>
			<p>
				In summary, 
				\[\textrm{Regular } \subset \textrm{ Cont. free } \subset \textrm{ Cont. Sens. } \subset \textrm{ Rec. Enumerable} \]
			</p>

			<h3 id="gra-4">DFA to L/R Linear Grammars</h3>

			<p>
				Whilst for a linear grammar \(x\) can be any string, in a <b>strictly</b> linear grammar, \(x\) has to be a single letter. This doesn't make the grammar any less powerful, just simpler to work with.
			</p>

			<h4>Right Linear</h4>

			<p>
				The general rule is
				\[
				\forall q, q' \in Q, a \in \Sigma,\textrm{ if } \delta(q,a) = q', \textrm{add rule } q \longrightarrow aq'
				\]
				\[
				\forall q \in F, \textrm{ add rule } q \longrightarrow \epsilon\]
			</p>
			
			<button class="collapsible">Example 3... </button>
			<div class="ccontent">
				<p>
					<b><i>Example.</i></b> Take the DFA shown with \(M = (Q = \{X,Y,S\}, \Sigma = \{a,b\}, S, F=\{S\}, \delta)\): 
					<figure>
						<img src="./dfa-to-linear-dfa.png" alt="" style="max-width: 300px;">
					</figure>
					This will make a grammar \(G = (V = \{S,X,Y\}, \Sigma, R, S)\) where the variables are just the states, however we now need to figure out what the production rules lead to. 
				</p>
				<p>
					The idea is to find all strings which will take us from the given one to an accept state. But we can start with just rewriting the state transition function:
					\begin{align}
						S &\longrightarrow \epsilon | bS | aX \\
						X &\longrightarrow bS | aY \\
						Y &\longrightarrow aY | bY 
					\end{align}
					We can then strip away dead states (Y) to get 
					\begin{align}
						R := S &\longrightarrow \epsilon | bS | aX \\
						X &\longrightarrow bS.
					\end{align}
					Which is a left linear grammar.
				</p>
			</div>
			
			<p>
				Again, cleaning up dead states is helpful, but <b>not necessary in the exam</b>.
			</p>

			<h4>Left Linear</h4>

			<p>
				Left linear grammars are slightly more difficult, since we're effectively <i>working backwards</i> from end to beginning. Thus, our accept state is our starting variable. 
			</p>
			<p>
				If there are multiple accept states, we can just \(\epsilon\)-transition all the accept states into one single state (since NFA \(\leq\) DFA, to use reducibility syntax)
			</p>
			<p>
				The start state \(q_0\) must of course also yield \(\epsilon\).
			</p>

			<button class="collapsible">Example 4...</button>
			<div class="ccontent">
				<p>
					<b><i>Example.</i></b> Take the following DFA 
					<figure>
						<img src="./dfa-to-left-lienar.png" alt="" style="max-width: 300px;">
					</figure>
					Our grammar will be \(G = (\{A,B,C,D,E\}, \{0,1\}, R, E)\) and 
					\begin{align}
						R := E &\longrightarrow B1 | A0 \\
						D &\longrightarrow E0 | E1 | C1 | D0 | D1 \\
						C &\longrightarrow B0 \\
						B &\longrightarrow A1 | C0 \\
						A &\longrightarrow \epsilon | C0
					\end{align}
					And since D is a dead state, we can clean it up to get
					\begin{align}
						R := E &\longrightarrow B1 | A0 \\
						C &\longrightarrow B0 \\
						B &\longrightarrow A1 \\
						A &\longrightarrow \epsilon | C0
					\end{align}
				</p>
			</div>
		</div>

		<div class="colourband">
			<h2 id="cfl">Context Free Languages</h2>
		</div>

		<div class="cbox">
			<h3>Introduction</h3>

			<ol>
				<li><a href="#cfl-1">Pushdown Automata</a></li>
				<li><a href="#cfl-2">CFGs to PDAs</a></li>
				<li><a href="#cfl-3">PDAs to CFGs</a></li>
				<li><a href="#cfl-4">Chomsky Normal Form</a></li>
				<li><a href="#cfl-5">String Testing</a></li>
				<li><a href="#cfl-6">Pumping Lemma</a></li>
				<li><a href="#cfl-7">Properties of CFLs</a></li>
			</ol>


			<p>
				A context free language (CFL) is simply one that is written using a <b>context free grammar</b>.
			</p>
			<p>
				Some examples of CFLs are
				\begin{align}
					L &= \{0^n1^n : n \geq 0\} \\
					L &= \{[(+)]*:\textrm{ brackets are balanced}\} \\
					L &= \{w\#w^R\} \pod{w^R\textrm{ meaning w is reversed}}
				\end{align}
				And we want a way to be able to parse them.
			</p>

			<h3 id="cfl-1">Pushdown Automata</h3>
			<p>
				We already have DFA and NFA for regular languages, why not augment them with something? A lot of context free languages can be parsed if you have a LiFo data structure, so why not add a <b>stack</b>?
			</p>
			<p>
				This makes a <b>push-down automaton</b>.
			</p>

			<div class="blue">
				<p>
					A <b>Pushdown Automaton (PDA)</b> is a machine \(M = (Q, \Sigma, \Gamma, \delta, q_0, F)\) where 
					<ul>
						<li>\(Q, \Sigma, q_0, F\) should all be things we've seen</li>
						<li>
							\(\Gamma\) is the <b>stack alphabet:</b> what symbols can be pushed to the stack. Usually includes all of \(\Sigma\) and a special \(\$\) symbol, which we'll use to represent <b>empty stack</b>.
						</li>
						<li>
							\(\delta : Q \times \Sigma_\epsilon \times \Gamma_\epsilon \longrightarrow 2^{Q \times \Gamma_\epsilon}\)
						</li>
					</ul>
					By default PDAs are <b>non-deterministic</b> -- we don't include dead states like NFAs.
				</p>
			</div>
			<p>
				PDA transitions are annotated \(a,c \longrightarrow b\), meaning <b>read</b> \(a\), <b>pop</b> \(c\), <b>push</b> \(b\):
				<figure><img src="./pda-notation.png" alt="" style="max-width: 160px;"></figure>
			</p>
			<ul>
				<li>
					Any of \(a,b,c\) can be \(\epsilon\) (i.e. don't pop, don't push, etc.)
				</li>
				<li>
					\(\epsilon,\epsilon \longrightarrow \$\) is what denotes the starting transition: "push $ and move".
				</li>
				<li>
					\(\epsilon, \$ \longrightarrow \epsilon\) is what denotes the end transition: "pop $ and move".
				</li>
			</ul>
			<p>
				The reason why we use $ is that, like C and arrays, a PDA doesn't know the length of its stack, so it's helpful to have an indicator (like <code>\0</code>)
			</p>

			<button class="collapsible">Example 1...</button>
			<div class="ccontent">
				<p>
					<b><i>Example.</i></b> The PDA for \(L = \{0^n1^n : n \geq 0 \} \) is 
					<figure><img src="./pda-1.png" alt="" style="max-width: 480px;"></figure>
				</p>
			</div>
			<button class="collapsible">Example 2...</button>
			<div class="ccontent">
				<p>
					<b><i>Example.</i></b> The PDA for \(L = \{w\#w^R\} \pod{w^R\textrm{ meaning w is reversed}}\) is 
					<figure><img src="./pda-2.png" alt="" style="max-width: 480px;"></figure>

				</p>
				<p class="grey">
					The language  \(L = \{w\#w\}\) is actually much more difficult, and is not solvable with a stack.
				</p>
			</div>
			<button class="collapsible">Example 3...</button>
			<div class="ccontent">
				<p>
					<b><i>Example.</i></b> The PDA for \(L = \{ww^R\}\) is slightly harder, since there's no indication of when they reverse. 
					<figure><img src="./pda-3.png" alt="" style="max-width: 630px;"></figure>
					Essentially at any time they could reverse, and we just non-deterministically move to the other state.s
				</p>
			</div>
			<p>
				Sometimes, we want to push a whole bunch of things for one input. The transition function can be <b>extended</b> to push a <b>string</b> instead: 
				\[a, c \longrightarrow b_1b_2\cdots b_r\]
				Which is equivalent to \(a,c \longrightarrow b_1\) followed by \(\epsilon,\epsilon \longrightarrow b_2\), ..., \(\epsilon, \epsilon \longrightarrow b_r\).
			</p>

			<div class="side">
				<p>
					A PDA \(M = (Q, \Sigma, \Gamma, q_0, F, \delta\) <b>accepts</b> a string \(w \in \Sigma*\) if 
					\begin{align}
						\exists w_1w_2 \cdots w_r &\in \Sigma_\epsilon \\ 
						\exists x_1x_2 \cdots x_r &\in Q \\
						\exists s_0s_1 \cdots s_r &\in \Gamma
					\end{align}
					such that \(x_0 = q_0, x_r \in F\); \(s_0 = \epsilon\), and 
					\[\forall i \in [0..r-1]\;\delta(x_i, w_{i+1}, a) \ni (x_{i+1}, b) \]
					where \(s_i = a \cdot t\) and \(s_{i+1} = b \cdot t\) for some \(a,b \in \Gamma_\epsilon\) and \(t \in \Gamma*\)
				</p>
				<p>
					Which is a complex way of saying, well, pretty much what you'd think "accept" means.
				</p>
				<p>
					But the thing to note somewhat is that the pairs of states and stack letters \((x_i, s_i)\) in sequence form the <b>run</b>.
				</p>
			</div>
			<blockquote>Pushdown Automata accept precisely the set of all context-free languages.</blockquote>

			<h3 id="cfl-2">CFGs to PDAs</h3>

			<p>
				We have a non-deterministic algorithm to compute the leftmost derivation of a string, should it exist.
			</p>
			<ul class="side">
				<li>Set <code>currentString</code> to \(s\)</li>
				<li>
					Do:
					<ul>
						<li>
							<b>if</b> the leftmost element of <code>currentString</code> is a variable A, <b>then</b> select any grammar rule for A, replace A by the other side of this rule, and record.
						</li>
						<li>
							<b>if</b> the leftmost is a terminal \(a\), <b>then</b> read next input, and check if is the same as \(a\). If so, remove \(a\). Else, <i>reject</i> the branch.
						</li>
						<li>
							<b>if</b> string is now empty, <b>then</b> <i>accept</i>, output recorded rules.
						</li>
					</ul>
				</li>
			</ul>
			<p>
				Thus, we have an algorithm to make a string from a grammar. 
			</p>
			<p>
				We can then convert this to a PDA compatible algorithm, namely:
			</p>

			<ul class="side">
				<li>
					Push \(s \cdot \$ \) onto the stack (last in first). 
				</li>
				<li>
					Do:
					<ul>
						<li>
							<b>If</b> top is a variable A, <b>then</b> select node for A, pop A and push right hand side. 
						</li>
						<li>
							<b>If</b> top is a terminal \(a\), <b>then</b> read the next symbol. If it's the same, pop \(a\).
						</li>
						<li>
							<b>If</b> top is \(\$\), <b>then</b> pop $ and accept.
						</li>
					</ul>
				</li>
			</ul>
			<p>
				We can thus make a machine with three states: a start \(q_s\), a loop \(q_2\), and an accept \(q_f\).
			</p>
			<figure class="blue"><img src="./cfg-to-pda-generic.png" alt="" style="max-width: 540px;"></figure>

			<p>
				i.e. just write all the rules on the middle \(q_2\).
			</p>

			<button class="collapsible">Example 4... </button>
			<div class="ccontent">
				<p>
					<b><i>Example.</i></b> Take \(L = \{0^n 1^n : n \geq 0\}\) which gives 
					\begin{align}
					R := S &\longrightarrow 0S1 \\
					S &\longrightarrow \epsilon
					\end{align}
					This makes a PDA which looks like 
				</p>
				<figure>
					<img src="./cfg-to-pda-ex4.png" alt="" style="max-width: 630px;">
				</figure>
			</div>

			<p>
				This is effectively brute forcing, but we can convert the grammar into a specific form which makes this deterministic (which will be covered later.)
			</p>

			<h3 id="cfl-3">PDAs to CFGs</h3>
			
			<p>
				To convert a PDA to a CFG, we want to first transform it into a <b>normalised</b> form:
			</p>

			<div class="blue">
				<p>
					A <b>normalised PDA</b> is:
				</p>
				<ul>
					<li>Has a single accept state \(q_f\). <span class="grey">Epsilon transition to a single \(q_f\) </span></li>
					<li>Never accept if the stack is non-empty <span class="grey">Have a state after original accepts which just empties the stack</span></li>
					<li>Each transition either pushes or pops, <b>not both, not none</b> <span class="grey">Separate out a push and pop transition into two, separate out an empty transition into one that pushes and one that pops the same item</span></li>
				</ul>
			</div>

			<p>
				Thus \(\forall p, q \in Q\), we have a variable \(A_{pq}\) (p can equal q)
			</p>
			<p>
				And \(A_pq\) generates all strings that can transition from \(p\) to \(q\), <i>with an empty stack at start and end</i>.
			</p>
			<p>
				Thus the language accepted is generated by \(A_{q_s q_f} \).
			</p>

			<ol class="side">
				<li>
					\(\forall p \in Q\), make a rule \(A_{pp} \longrightarrow \epsilon\). 
				</li>
				<li>
					\(\forall p,q,r \in Q\), make rule \(A_{pq} \longrightarrow A_{pr} A{_rq} \)
				</li>
				<li>
					\(\forall p,q,r,s \in Q,\; u \in \Gamma,\; \alpha, \beta \in \Sigma_\epsilon\) <span class="grey">(every 4 states, a stack letter \(u\), and letters \(\alpha, \beta\)))</span>, if the transition \(\delta(p,\alpha,\epsilon)\) can go to the state \(r\) and pushes \(u\) (contains \((r,u)\)), make a rule \(A_{pq} \longrightarrow \alpha A_{rs} \beta\).
					<figure>
						<img src="./pda-to-cfg-general.png" alt="" style="max-width: 630px;">
					</figure>
				</li>
			</ol>

			<h3 id="cfl-4">Chomsky Normal Form</h3>

			<p>
				Chomsky normal form is a normalised form of a CFG, which is helpful for certain algorithms. 
			</p>

			<div class="blue">
				<p>
					A CFG grammar \(G = (V,\Sigma,R,S)\) is in <b>Chomsky Normal Form (CNF)</b> if <b>every</b> production rule looks like one of the following
				</p>
				<ul>
					<li>\(S \longrightarrow \epsilon\)</li>
					<li>\(A \longrightarrow x\) where \(x\) is a terminal</li>
					<li>\(A \longrightarrow BC\) where \((B, C \in V) \land (B, C \neq S)\)</li>
				</ul>
			</div>
			<p class="side">
				<b><i>Theorem</i> (Sipser).</b> <b>Any</b> CFG can be converted to CNF. 
			</p>

			<h4>Conversion into CNF</h4>

			<p>
				"See violation, change violation":
			</p>
			<ul class="side">
				<li>
					Create a new start \(S_0 \longrightarrow S\) (if needed for start restriction)
					<button class="collapsible nul">Expand... </button>
					<div class="ccontent cnul">
						\[
					\begin{array}{rl}
						&S &\longrightarrow ASB \\
						&A &\longrightarrow aAS | a | \epsilon \\
						&B &\longrightarrow SbS | A | bb
					\end{array}
					\implies 
					\begin{array}{rl}
						&S_0 &\longrightarrow S \\
						&S &\longrightarrow ASB \\
						&A &\longrightarrow aAS | a | \epsilon \\
						&B &\longrightarrow SbS | A | bb
					\end{array}
					\]
					<!-- <hr> -->
					</div>
					
				</li>
				<li>
					Eliminate all \(A \longrightarrow \epsilon : A \neq S_0\), by essentially creating an new rule for every other variable, removing \(A\) (and replacing into \(\epsilon\) if needed):
					<button class="collapsible nul">Expand... </button>
					<div class="ccontent cnul">
						\[
					\begin{array}{rl}
						&S_0 &\longrightarrow S \\
						&S &\longrightarrow ASB \\
						&A &\longrightarrow aAS | a | \epsilon \\
						&B &\longrightarrow SbS | A | bb
					\end{array}
					\implies 
					\begin{array}{rl}
						&S_0 &\longrightarrow S \\
						&S &\longrightarrow ASB | SB \\
						&A &\longrightarrow aAS | a | aS \\
						&B &\longrightarrow SbS | A | bb | \epsilon
					\end{array}
					\implies 
					\begin{array}{rl}
						&S_0 &\longrightarrow S \\
						&S &\longrightarrow ASB | SB | AS | S \\
						&A &\longrightarrow aAS | a | aS \\
						&B &\longrightarrow SbS | A | bb 
					\end{array}
					\]
					</div>
					
					And repeat until all epsilons, including newly introduced ones, are gone (except on \(S_0\)). <b>Do not reintroduce \(\epsilon\) on variables that already had it eliminated.</b>
				</li>
				<li>
					Eliminate unit variables \(A \longrightarrow B\). Replace with \(A \longrightarrow w\) for every \(B \longrightarrow w\) production. Delete self references. 
					<button class="collapsible nul">Expand... </button>
					<div class="ccontent cnul">
						\[
						\begin{array}{rl}
						&S_0 &\longrightarrow S \\
						&S &\longrightarrow ASB | SB | AS | S \\
						&A &\longrightarrow aAS | a | aS \\
						&B &\longrightarrow SbS | A | bb 
					\end{array}
						\implies 
						\begin{array}{rl}
							&S_0 &\longrightarrow S \\
							&S &\longrightarrow ASB | SB | AS \\
							&A &\longrightarrow aAS | a | aS \\
							&B &\longrightarrow SbS | bb | aAS | a | aS
						\end{array}
						\implies 
						\begin{array}{rl}
						&S_0 &\longrightarrow ASB | SB | AS \\
						&S &\longrightarrow ASB | SB | AS \\
						&A &\longrightarrow aAS | a | aS \\
						&B &\longrightarrow SbS | bb | aAS | a | aS
					\end{array}
						\]
					</div>
				</li>
				<li>
					Add variables and rules to remove occurences \(A \longrightarrow u\) where \(u\) is either a string longer than 1, or a mixture of terminals and non-terminals.

					<button class="collapsible nul">Expand... </button>
					<div class="ccontent cnul">
						\[
						\begin{array}{rl}
							&S_0 &\longrightarrow ASB | SB | AS \\
							&S &\longrightarrow ASB | SB | AS \\
							&A &\longrightarrow aAS | a | aS \\
							&B &\longrightarrow SbS | bb | aAS | a | aS
						\end{array}
						\implies
						\begin{array}{rl}
							&S_0 &\longrightarrow AU_1 | SB | AS \\
							&S &\longrightarrow AU_1 | SB | AS \\
							&A &\longrightarrow aU_2 | a | aS \\
							&B &\longrightarrow SU_3 | bb | aU_2 | a | aS \\
							&U_1 &\longrightarrow SB \\
							&U_2 &\longrightarrow AS \\
							&U_3 &\longrightarrow bS \\
						\end{array}
						\implies
						\begin{array}{rl}
							&S_0 &\longrightarrow AU_1 | SB | AS \\
							&S &\longrightarrow AU_1 | SB | AS \\
							&A &\longrightarrow V_1 U_2 | a | V_1 S \\
							&B &\longrightarrow SU_3 | V_2 V_2 | V_1 U_2 | a | V_1 S \\
							&U_1 &\longrightarrow SB \\
							&U_2 &\longrightarrow AS \\
							&U_3 &\longrightarrow V_2 S \\
							&V_1 &\longrightarrow a \\
							&V_2 &\longrightarrow b
						\end{array}
						\]
						(The rule \(A \longrightarrow a\) is allowed.)
					</div>
				</li>
			</ul>

			<p >
				In CNF every string of length \(n\) can be derived in <b>exactly</b> \(2n-1\) steps,
			</p>
			<p>
				Since from 1 start variable, we get to \(n\) variables in \(n-1\) steps, and each variable maps to one terminal, adding \(n\) steps, \(\therefore 2n-1\) steps exactly.
			</p>

			

			<h3 id="cfl-5">String Testing</h3>

			<p>
				The <b>Cocke Younger Kasami (CYK) Algorithm</b> is used to test if a string is generated by a CFG (in CNF). 
			</p>
			<p>
				It is based off dynamic programming: for a string \(y = y_1y_2 \cdots y_n\), column \(j\) are the substrings that start at \(y_j\), and row \(i\) of column \(j\) means a substring starting with \(y_j\) and \(i\) letters long.
			</p>
			<p>
				Inside the array are stored <b>variables</b> which can generate that substring.
			</p>
			<p>
				The <b>top left</b> cell (\(6, y_0\), i.e. the entire string) <b>must contain</b> \(S\) for the derivation to be a success.
			</p>
			<p>
				The way the dynamic programming works is that for a square \(i, j\), it'll search <b>up</b> the columns, and <b>down</b> the diagonal, seeing if there's a production rule that makes this substring with any pair. 
			</p>
			<figure>
				<img src="./cyk-looking.png" alt="" style="max-width: 440px;">
			</figure>
			<p>
				For reference, here's an animation of a CYK run from wikipedia. 
			</p>
			<figure>
				<img src="https://upload.wikimedia.org/wikipedia/commons/thumb/f/f5/CYK_algorithm_animation_showing_every_step_of_a_sentence_parsing.gif/440px-CYK_algorithm_animation_showing_every_step_of_a_sentence_parsing.gif" alt="" title="(Wikimedia Commons)" style="max-width: 440px;">
			</figure>
			<p>
				We can even stop the algorithm early if an entire row yields \(\varnothing\), since if a substring cannot be generated, how can the whole string?
			</p>
			<p>
				Given a string of length \(l\):
			</p>

			<div class="codediv">for \(i = 2 \cdots l-1\):
	for \(j = 1 \cdots l -(i-1)\):
		for \(p = 1 \cdots i-1\):
			\(M[i][j] \longleftarrow M[i][j] \cup LHS(M[p,j] \times M[i-p][j-p])\)</div>

			<p>
				Where \(LHS(P \times Q)\) are all variables \(J \in V :\) there exists a rule \(J \longrightarrow XY : X \in P, Y \in Q\).
			</p>
			<p>	
				With an efficiency of \(O(n^3 r)\) where \(n\) is the length of the string, and \(r\) is the number of grammar rules. 
			</p>


			<h3 id="cfl-6">Pumping Lemma</h3>

			<p>
				The idea is to look at parse trees. If a derived string is too long, a non terminal R must <b>repeat</b> on the <b>same branch</b> of a parse tree. 
			</p>

			<p>
				Thus we can define a \(w = uvxyz\), where \(x\) is created by the second R and \(v\) and \(y\) are the pre- and suffixes of \(x\) created by the first R:
			</p>
			<figure>
				<img src="./cfg-pumplemma-tree.png" alt="" style="max-width: 480px;">
			</figure>
			<p>
				Similar to the DFA loop, we can remove the second R, or reduplicate and add more Rs, giving us 
			</p>
			<div class="blue">
				<p>
					<b><i>Pumping Lemma.</i></b> Let L be a CFL. There exists a positive integer \(m : \forall w \in L \pod{|w| \geq m},\; \exists\) a <b>decomposition</b> \(uvxyz:\)
				</p>
				<ul>
					<li>
						\(|vxy| \leq m\) (\(vxy\) is short)
					</li>
					<li>\(|vy| \geq 1\)</li>
					<li>\(\forall i \in \mathbb{N}_0,\; uv^ixy^iz \in L.\)</li>
				</ul>
			</div>
			<p>
				But what is the pumping number? 
			</p>
			<ul>
				<li>
					Let \(b\) be the longest RHS generation (the longest single rule on a RHS). \(b\) is generally a "small" number (mathematically speaking), like 10.
				</li>
				<li>
					No leaf will have more than \(b\) children; the max degree is \(b\)
				</li>
				<li>
					For a tree of height \(h\), the number of leaves is at most \(b^h\)
				</li>
				<li>
					If a string is very long, and \(b\) is small, then the height must increase along with string length; longer string -> heigher height. 
				</li>
				<li>
					If \(h &gt; |V|\) (no. variables) then there must be a repeat of a variable. Thus, we want a parse tree height \(\geq |V| + 1\).
				</li>
			</ul>
			<p class="blue">
				Thus the pumping number \(m = b^{|V| + 1}\).
			</p>
			<p class="grey">
				This is by no means the smallest possible number -- it's an upper bound, which is sufficient.
			</p>

			<button class="collapsible">Proof... </button>
			<div class="ccontent">
				<p>
					<b><i>Proof.</i></b> Given L as a CFL, where \(\exists m &gt; 0 : \forall w \in L : |w| \geq m\), there is a decomposition \(w = uwxyz\) which satisfies the pumping lemma conditions. 
				</p>
				<ul>
					<li>
						Let \(G = (V,\Sigma, S, R)\) be the CFG generating L. 
					</li>
					<li>
						Let \(b = \max_{\textrm{rule }X \longrightarrow Y} |Y|\) (longest RHS rule)
					</li>
					<li>
						Let \(m = b^{|V| + 1} \)
					</li>
					<li>
						By <b>pidgeonhole principle</b>, \(\exists A \in V,\; \exists\) nodes \(\alpha, \beta \in\) internal nodes of the tree T, such that 
						<ul>
							<li>
								\(val(\alpha) = val(\beta) = A\)
							</li>
							<li>
								\(\alpha\) is the ancestor of \(\beta\)
							</li>
						</ul>
					</li>
					<li>
						<b>Claim</b> that the subtree of T rooted at \(\alpha\) has \(\leq b^{|V|+1} \) leaves. <b>Ensure</b> by picking \(\alpha\) such that its height \(\leq |V| + 1\).
					</li>
					<li>
						Let string \(x\) be yield of subtree rooted at \(\beta\).
					</li>
					<li>
						Let us have strings \(v,y : vxy\)  is yielded by subtree rooted at \(\alpha\).
					</li>
					<li>
						Let strings \(u,z : uvxyz\) is the yield of the root T. 
					</li>
					<li>
						\(\forall i \geq 0,\; uv^i xy^i z \in L\), since we can <b>pump up</b> by repeating \(\beta\), turning it into \(\beta \cdots \alpha\), and can <b>pump down</b> by removing \(\alpha\), and \(\alpha\) just having \(\beta\).
						<figure>
							<img src="./cfg-pumpup-pumpdown.png" alt="" style="max-width: 630px;">
						</figure>
					</li>
					
				</ul>
				<p>
					Thus the pumping lemma. \[\tag*{$\Box$}\]
				</p>
				
			</div>
			<h4>Using the Pumping Lemma</h4>

				<div class="side">
					<p>
						Proof structure for lemma:
					</p>
					<ol>
						<li>Suppose L is a CFL (for contrapositive)</li>
						<li>
							Let \(m\) be the pumping length of L
						</li>
						<li>
							Choose any string \(w \in L : |w| \geq m\)
						</li>
						<li>
							Take some decomposition \(uvxyz\) which meet the criteria of the lemma. 
						</li>
						<li>
							Choose an \(i : uv^i xy^i z \not \in L\)
						</li>
					</ol>
				</div>
				<p></p>
				<button class="collapsible">Example \(L = \{a^n b^n c^n : n \geq 0 \} \)</button>
				<div class="ccontent">
					<p>
						<b><i>Proof.</i></b> Assume L is context free, and \(m\) is its pumping length
					</p>
					<ul>
						<li>
							Pick a string \(a^m b^m c^m \in L\)
						</li>
						<li>
							Decompose the string into \(uvxyz\) -- this is not as straight forward as for regular languages, because there are <b>multiple possibilities</b> for where the \(vxy\) bit, the bit that matters, appears. 
						</li>
						<li>
							All the cases (to use regex):
							<ol>
								<li>
									\(vxy \in a*\)
								</li>
								<li>\(vxy \in b* \)</li>
								<li>\(vxy \in c* \)</li>
								<li>\(vxy \in a*b*\)</li>
								<li>\(vxy \in b*c*\)</li>
							</ol>
							(Since \(|vxy| \leq m\) and so cannot contain all three numbers)
						</li>
						<li>
							For all of these, simply set \(i\) to zero to disprove. $$\tag*{$\Box$}$$
						</li>
						
					</ul>
				</div>

			<h3 id="cfl-7">Properties of CFLs</h3>
				<hr>
			<p>
				To test if a CFG <b>generates an empty language</b>, we can: 
			</p>
			<ol>
				<li>
					Mark all variables which produce a terminal on the RHS. 
				</li>
				<li>
					Mark all variables which produce a combination of terminals and already marked variables on the RHS 
				</li>
				<li>
					If S is not marked, then \(L(G) = \varnothing\).
				</li>
			</ol>
			<hr>
			<p>
				To test if a CFL is <b>finite</b> given its grammar, we
			</p>
			<ul>
				<li>
					Check for no reachable "grammar loops" ~ a parse tree with no same-branch repeats. 
				</li>
				<li>
					i.e. The grammar is finite <b>if and only if</b> it cannot generate strings longer than the pumping length. 
				</li>
			</ul>
			<hr>
			<p>
				CFLS are closed under <b>union, concactenation, and kleene (*) closure</b>
			</p>
			<p>
				and are <span style="color: red;"><b>not closed</b></span> under intersection and complement.
			</p>
			<button class="collapsible">On intersection...</button>
			<div class="ccontent">
				<p>
					Let \(P = \{a^i b^j c^j : i,j \geq 0\}\) and \(Q = \{a^i b^i c^j : i,j \geq 0\}\)
					\[P \cup Q = \{a^i b^i c^i : i \geq 0 \}\]
					which is obviously not context free.
				</p>
			</div>
			<button class="collapsible">On union... </button>
			<div class="ccontent">
				<p>
					Let \(G_1 = (V_1, \Sigma_1, R_1, S_1)\) and \(G_2 = (V_2, \Sigma_2, R_2, S_2\).
				</p>
				<p>
					Simply create a new start variable \(S \longrightarrow S_1 | S_2\). Also assume \(V_1\) and \(V_2\) are disjoint (i.e. bag union, not set union).
				</p>
			</div>
			<button class="collapsible">On concatenation... </button>
			<div class="ccontent">
				<p>
					Simply create a new start variable \(S \longrightarrow S_1S_2\).
				</p>
			</div>
			<button class="collapsible">On Kleene closure</button>
			<div class="ccontent">
				<p>
					(This is the star in regex) this derives from concatenation. 
				</p>
				<p>
					If we have a grammar \(G\) with start \(S_1\), simply create a new start variable \(S \longrightarrow S_1S | \epsilon\). 
				</p>
			</div>
			<button class="collapsible">On complement... </button>
			<div class="ccontent">
				<p>
					CFLs are <b>not</b> closed under intersection, and are closed under union. We know that if intersection were closed,
					\[
					\overline{\overline{P} \cup \overline{Q}} \textrm{ closed } \implies P \cap Q \textrm{ closed. }
					\]
					which means CFLs are not closed under complement.
				</p>
			</div>
		</div>

		<div class="colourband">
			<h2 id="turing">Turing Machines</h2>
			<p class="subheading">Recursive Enumeration</p>
		</div>

		<div class="cbox">

			<h3>Contents</h3>

			<ol>
				<li><a href="#tur-1">Turing Machines</a></li>
				<li><a href="#tur-2">Turing Recognisability</a></li>
				<li><a href="#tur-3">Recursive Enumerability</a></li>
				<li><a href="#tur-4">Universal Turing Machines (Halting Problem)</a></li>
				<li><a href="#tur-5">Mapping and Reductions</a></li>
				<li><a href="#tur-6">Closure of Turing Languages</a></li>
				<li><a href="#tur-7">Assorted Questions</a></li>
			</ol>

			<h3 id="tur-1">Turing Machines</h3>
			<p>
				A turing machine has a <b>tape</b> and a <b>moveable read-write head</b>, with an internal state machine. 
			</p>
			<p>
				The tape is infinite, technically in both directions, but often it is easier for it only to be infinite in one.
			</p>
			<div class="blue">
				<p>
					A <b>Turing Machine</b> is a 7-tuple
					\[T = (Q, \Sigma, \Gamma, \delta, q_0, q_{accept}, q_{reject})\]
					where 
				</p>
				<ul>
					<li>
						\(Q\) is the set of states 
					</li>
					<li>
						\(\Sigma\) is the <b>input alphabet</b> -- this excludes blank symbols (<code>␣</code>)
					</li>
					<li>
						\(\Gamma\) is the <b>tape/writable alphabet</b> -- this includes all elements of \(\Sigma\) and the blank symbol ␣.
					</li>
					<li>
						\(\delta: Q \times \Gamma \longrightarrow Q \times \Gamma \times \{L,R\}\) -- every delta takes a state and reads a symbol from the tape, and returns a new state, the letter to write on the tape, and whether to move the head to the left or right. 
					</li>
					<li>
						\(q_0 \in Q\) is the start state 
					</li>
					<li>
						\(q_{accept} \in Q\) is the <b>singular</b> accept state.
					</li>
					<li>
						\(q_{reject} \in Q\) is teh <b>singular</b> reject state, and must not equal \(q_{accept}\).
					</li>
				</ul>
			</div>
			<p>
				A turing machine is <b>deterministic</b> by default.
			</p>
			<p>
				\(\vdash\) denotes the end / start of the tape to the left (for convenience), and ␣ is the blank "no characters here" symbol.
			</p>
			<p>
				A state transition is described \(a \longrightarrow b, D\) where \(a\) is the <b>read in</b>, \(b\) is the <b>write out</b>, and \(D\) is the <b>direction</b>, which can be \(L, R\) or \(S\) (stay), which is a shorthand for convenience.
			</p>
			<p>
				Input strings are generally <b>written to the start of the tape</b> in order.
			</p>
			<p>
				Since all programming languages are turing complete, and can replicate a turing machine, it is sufficient to use <b>pseudocode</b> or <b>structured english</b> to describe a machine's operation, unless specified to draw the thing down.
			</p>

			<button class="collapsible">Example 1... </button>
			<div class="ccontent">
				<p>
					<b><i>Exampe.</i></b> Take the language \(L = \{ w\#w : w \in \{0,1\}*\} \) (all binary strings, replicated, with a # between).
				</p>
				<p>
					The machine's operation can be described as 
				</p>
				<div class="codediv">Mark the first symbol \(a \in \Sigma\)
Go to the first unmarked symbol \(b\) after #
If \(a = b\):  mark
else:  REJECT
Return to earlist unmarked symbol. 
Repeat until all symbols marked, then ACCEPT</div>
				
				<p>
					And can be represented by the following state diagram (where any missing transitions are implied to go to \(q_{reject}\))
				</p>
				<figure>
					<img src="./turing-example-1.png" alt="">
				</figure>
			</div>

			<h3 id="tur-2">Turing Recognisability</h3>

			<p>
				A <b>configuration</b> of a TM is a snapshot of the execution at any point. This includes the current state, tape contents, and reader position, denoted
				\[x = (u, q, v)\]
				Where \(q\) is the current state, and \(u \cdot v\) is the contents of the tape. The <b>first symbol</b> of \(v\) is where the reader is. 
			</p>
			<p>
				A configuration <b>yields</b> another if it can be reached in 1 step.
			</p>
			<ul>
				<li>
					The <b>start</b> configuration is \((\vdash, q_0, w)\) for an input string \(w\)
				</li>
				<li>
					The <b>accepting</b> configuration is \(u, q_{accept}, v\) for some \(u,v\)
				</li>
				<li>
					The <b>rejecting</b> configuration is \(u, q_{reject}, v\) for some \(u,v\)
				</li>
			</ul>
			<p>
				The TM halts as soon as ACCEPT or REJECT is encountered.
			</p>
			<p>
				The <b>run</b> of a turing machine on \(w\) is thus a series of configrations 
				([c_1 c_2 \cdots c_n\)
				where \(c_1\) is the start config, and \(c_i\) yields \(c_{i+1} \). it is accepting if \(c_n\) is an accepting configuration.
			</p>
			<p>
				A TM run has three outcomes:
				<ul>
					<li>Accept</li>
					<li>Reject</li>
					<li>Never halts</li>
				</ul>
			</p>
			<p>
				The language \(L(M)\) is thus all words where \(M\) has an accepting run.
			</p>

			<p class="blue">
				A language L is <b>turing recongnisable</b> if L is accepted by some machine M. 
			</p>
			<p>
				<span class="sc"><b><i>Note.</i></b></span> For \(w \not \in L\), a TM can <b>either</b> reject <b>or</b> never halt.
			</p>
			<p>
				This set of languages is also called <b>recursively enumerable</b>, and is Type 0 on Chomsky's heirarchy. 
			</p>

			<p class="blue">
				<b>Decider/Total Turing Machines</b> are TMs that <b>always</b> halt with either accept or reject. 
			</p>
			<p>
				For a turing machine M, \(L(M)\) is said to be <b>decided</b> by M. These languages are <b>turing decidable</b>. 
				\[\textrm{turing decidable } \subset \textrm{ turing recognisable}. \]
			</p>
			<p>
				A turing machine is <b>no more powerful</b> if you have more reader heads, more tapes, etc. It is thus <b>allowed</b> to design a TM with a more complex tape structure if easier. 
			</p>

			<h3 id="tur-3">Recursive Enumerability</h3>

			<div class="blue">
				<img src="./enummachine.png" alt=""  style="padding-top: 8px; padding-right: 8px; float: right;">
				<p>
					An <b>Enumeration machine</b> (EM) is a Turing machine with a printer, or <b>output tape</b>.
				</p>
				<p>
					The enumerator has <b>no input</b>. When the EM enters an <i>enumeration state</i>, all symbols on the internal tape get printed out: "enumerated".
				</p>
				<p>
					Thus \(L(M)\) is enumerable by an EM, thus "recursively enumerable".
				</p>
			</div>

			<p class="side">
				<b><i>Claim.</i></b> Enumerable machines are turing machines. 
			</p>
			<button class="collapsible">Proof... </button>
			<div class="ccontent">
				<p>
					<b><i>Proof.</i></b> This is a \(\iff\) proof. 
				</p>
				<p>
					For \(\implies\): We have an enumerator. Let us make a turing machine M, where M =
				</p>
				<div class="codediv">on input \(w\):
	run enumerator
	when enumerator outputs a string \(a\):
		if \(a = w\), ACCEPT. </div>
				<p>
					If \(w\) is not enumerable, the machine will never halt. 
				</p>
				<p>
					For \(\impliedby\) we hav a turing machine M. Let us define an enumerator E such that:
				</p>
				<div class="codediv">for \(i = 1, 2, \dots\):
	run M for \(i\) steps on input \(s_1, s_2, \dots, s_i\)
	if any computations on \(s_j\) accepts:
		print(\(s_j\))</div>
				<p>
					Eventually, if M accepts, E will print that string out.
				</p>
			</div>

			<h3 id="tur-4">Universal Turing Machines (Halting Problem)</h3>

			
			<div class="blue">
				<p class="">
					A <b>Universal Turing Machine (UTM)</b> is a turing machine that takes the <b>encoding</b> of another machine, and a string \(w\): <code>"ENC(M)#w"</code>
				</p>
				<p>
					Usually this input is denoted \(\langle M,w \rangle\).
				</p>
			</div>

			<p class="side">
				The <b>halting problem</b> is defined as 
				\[HP = \{\langle M, x \rangle : M \textrm{ halts on }x\}\]
			</p>
			<p class="side">
				The <b>membership problem</b> is defined as
				\[MP = \{\langle M, x \rangle : x \in L(M)\}\]
			</p>
			<p>
				The halting problem is turing recognisable: just simulate M on \(x\), and accept when it does.
			</p>
			<p>
				The crucial point however is: <i>Is the halting problem decidable?</i>
			</p>
			<p class="small">well, no</p>
			<p class="side">
				<b><i>Theorem.</i></b> The Halting Problem is indecidable.
			</p>

			<button class="collapsible">Proof (plain english)... </button>
			<div class="ccontent">
				<p class="grey">
					So the "given proof" was incredibly ??? when we first got it, so I went away and thought about it for ages, then wrote this down, which is an as-plain-english-as-possible way of expressing it, I hope.
				</p>

				<p><b><i>Proof.</i></b> Suppose we have all possible turing machines (there are countably infinitely many), and we match each machine up to a binary number (which are also countably infinite)</p>

				<p>Machine \(M_n\) would then run over string \(n\). This machine can halt, or it can not. </p>

				<p>Now this machine can run over any other string that's not \(n\), sure, and it could halt or not for them, but that isn't important. What is important is just \(n\). </p>

				<p>Assume there is a decider \(N\) for the halting problem. We can use \(N\) to construct a new machine that is different from all machines. How?</p>

				<p>This new machine, let's call it \(K\), when ran over all strings \(i = 1, 2, \dots\) forever, will halt when \(M_i\) loops, and loop when \(M_i\) halts. Thus, since it's different to every machine in at least one value (i.e. along the diagonal), it is different to all machines. </p>

				<p>How do we construct \(K\)? Inside \(K\), we have a "subroutine", which is \(N\), the assumed decider. When \(K\) recieves an input \(y\), it constructs the encoding \(\langle M_y, y \rangle\) (i.e. gets the corresponding machine for string \(y\)), and passes it to \(N\).</p>

				<p>If \(N\) accepts (\(M_y\) halts), then \(K\) will go into an infinite loop. If \(N\) does not accept (\(M_y\) loops), then \(K\) will accept (halt). Thus completes our construction.</p>

				<p>\(K\) then contradicts the fact that we already have all machines M \(\implies\) by contradiction \(K\) cannot exist \(\implies\) \(N\) cannot exist </p>

				$$\tag*{$\Box$}$$
			</div>
			<button class="collapsible">Proof (whatever I wrote down from the lecture)... </button>
			<div class="ccontent">
				<p>
					<b><i>Proof.</i></b> So this proof will use <i>Cantor's diagonalisation theorem</i>. <span class="grey">real strong start huh</span>
				</p>
				<p>
					If we treat <i>every</i> binary string as an encoding of a unique TM, we can create a table which has all the turing machines as binary on the axes. 
				</p>
				<p>
					The cell on row \(i\) and column \(j\) means running machine \(i\) on string \(j\). We can mark this as a H if the machine halts, and a L if the machine loops. 
				</p>
				<p>
					Every TM ever is present in this table. 
				</p>
				<p>
					Suppose there exists a decider \(N\) for the halting problem. 
				</p>
				<ul>
					<li>
						Make a new machine \(k\) that <i>halts</i> when any existing machine loops, and <i>loops</i> when any existing machine halts. 
					</li>
					<li>
						Which makes this machine not in the table. 
					</li>
					<li>
						\(N\) when given \(\langle M, x \rangle\) will accept if M halts and reject if M loops. 
					</li>
					<li>
						Construct \(K\) in the following way:
						<figure>
							<img src="./hpproofdiagram.png" alt="" style="max-width: 600px;">
						</figure>
					</li>
					<li>
						\(K\) is not the same as all machines for all binary values. If \(M_\epsilon\) halts, then \(K\) loops, etc, etc. 
					</li>
					<li>...</li>
				</ul>
				<p>
					Proof by contradiction. $$\tag*{$\Box$}$$
				</p>
			</div>

			<p class="side">
				<b><i>Theorem.</i></b> Membership (MP) is not decidable. 
			</p>

			<button class="collapsible">Proof... </button>
			<div class="ccontent">
				<p>
					<b><i>Proof.</i></b> Suppose MP is decidable, and let N be a decider for MP. 
				</p>
				<p>
					We claim that N can be used to construct a decider K for HP. 
				</p>
				<p>
					Construct K by, on input \(\langle M, x \rangle\): 
				</p>
				<ol>
					<li>
						Alter \(M\) into \(M'\) by
						<ul>
							<li>Adding a new accept state to \(M'\)</li>
							<li>Transitioning all accept/reject states of \(M\) to the new accept state of \(M'\)</li>
						</ul>
						meaning that if \(M'\) accepts, \(M\) halts. 
					</li>
					<li>
						Simulate N on \(\langle M', x \rangle\)
					</li>
					<li>
						Link up the machines like so:
						<figure>
							<img src="./mp-decidability.png" alt="" style="max-width: 500px;">
						</figure>
					</li>
				</ol>
				<p>
					This is a decider for the halting problem (which is undecidable), thus MP must be undecidable. $$\tag*{$\Box$}$$
				</p>
			</div>

			<h3 id="tur-5">Mappings and Reductions</h3>

			<div class="blue">
				<p>
					Given languages \(A \subseteq \Sigma *, B \subseteq \Delta *\) (note \(\Sigma, Delta\) are both alphabets),
				</p>
				<p>
					There is a <b>Mapping Reduction</b> \(\sigma : \Sigma * \longrightarrow \Delta *\) if  
				</p>
				<ul>
					<li>
						\(\forall x \in \Sigma*, x \in A \iff \sigma(x) \in B\): all words in A map to a word in B, and all words not in A do not map to a word in B. 
					</li>
					<li>
						\(\sigma\) is a <b>compatible</b> function. That is, there is a decider that can take \(x\) and halt with \(\sigma(x)\) on the tape.
					</li>
					<p class="grey">
						This is, as far as I can see, means the mapping should be describable with an algorithm.
					</p>
				</ul>
				<p>
					If there is a mapping reduction from A to B, we write 
					\[A \leq_m B\]
					"A is no more complex than B", same as 260.
				</p>
			</div>
			<p></p>
			

			<p></p>
			<button class="collapsible">Example \(HP \leq_m MP\)...</button>
			<div class="ccontent" >
				<p>
					<b><i>Example.</i></b> Let's show that HP reduces to MP. Consider \(\langle M, x \rangle\), which is an instance of HP.
				</p>
				<p>
					Define a TM \(M'_x\) as
				</p>
				<div class="codediv">\(M'_x(y)\):
	ignore \(y\)
	run \(M\) on \(x\)
	if \(M\) halts:
		ACCEPT</div>
				<p>
					<b><i>Claim.</i></b> \(\langle M, x \rangle \in HP \iff \langle M'_x, x \rangle \in MP\).
				</p>
				<p>
					<b><i>Proof.</i></b> \(\implies\): if \(\langle M,x \rangle \in HP\), then M halts on \(x\). Thus \(M'_x(x)\) accepts. Thus \(\langle M'_x, x \rangle \in MP\) by definition. \(\vartriangleright\)
				</p>
				<p>
					\(\impliedby\): if \(\langle M'_x, x \rangle \in MP\), \(M'_x\) accepts \(x\). Thus \(M\) halts on \(x\). Thus \(\langle M, x \rangle\) in HP. $$\tag*{$\Box$}$$
				</p>
			</div>

			<p>
				Since \(HP \leq_m MP\), and HP is undecidable, we have another way to prove that MP is undecidable.
			</p>
			<p>
				Other problems, like 
				<ul>
					<li>\(\epsilon\)-acceptance: \(|{\langle M \rangle : \epsilon \in L(M)\}|}\)</li>
					<li>
						\(\exists\)-acceptance: \(\{\langle M \rangle : L(M) \neq \varnothing\}\)
					</li>
					<li>
						\(\forall\)-acceptance: \(\{ \langle M \rangle : L(M) = \Sigma * \} \)
					</li>
				</ul>
				<b>all reduces HP</b> (by the exact same construction as for HP -> MP)
			</p>
			<p>
				However, these problems are defined by default over turing machines. It is comparatively extremely easy to verify that a DFA is \(\epsilon\)-accept, or \(\exists\)-accept, etc. 
			</p>

			<div class="side">
				<p>
					<b><i>Theorem (a).</i></b> <b>If</b> \(A \leq_m B\) and B is decidable, then A is too.
				</p>
				<p>
					<b><i>Theorem (b).</i></b> <b>If</b> \(A \leq_m B\) and <b>A</b> is <b>un</b>decidable, then B is too.
				</p>
			</div>

			<p></p>
			<button class="collapsible">Proof... </button>
			<div class="ccontent">
				<p>
					<b><i>Proof.</i></b>
				</p>
				<ul>
					<li>
						Let M be a <i>recogniser</i> machine for B, and \(f\) be the mapping reduction A to B. 
					</li>
					<li>
						We can describe a recogniser N for A where:
						<div class="codediv">N(\(w\)):
	compute \(f(w)\)
	run M(\(f(w)\)) and output what M outputs</div>
					</li>
					<li>
						Since \(f\) is a reduction, \(w \in A \iff f(w) \in B\), thus M accepts \(f(w)\) when \(w \in A\). 
					</li>
					<li>
						Thus A is decidable when B is, and by that logic B can't be decidable when A isn't. $$\tag*{$\Box$}$$
					</li>
				</ul>
			</div>

			<p class="side">
				<b><i>Theorem.</i></b> A language L is decidable <b>if and only if</b> both \(L\) and \(\overline{L} \) are turing recognisable.
			</p>

			<button class="collapsible">Proof... </button>
			<div class="ccontent">
				<p>
					<b><i>Proof.</i></b> <br>
					\(\implies\): If L is decidable, then a decider for L is also a recogniser for L. 
				</p>
				<p>
					Simply use the same decider for \(\overline{L}\), and complement the answer. $$\tag*{$\vartriangleright$}$$
				</p>
				<p>
					<b><i>Corollary.</i></b> Decidable langauges are closed under complementation.
				</p>
				<p>
					\(\impliedby\): If \(L, \overline{L} \) are both recognisable, \(\exists\) a machine P that recognises \(L\), and \(\exists\) a machine Q that recognises \(\overline{L}\)
				</p>
				<p>
					Define a decider \(M\) for L that
				</p>
				<div class="codediv">M(\(x\)):
	simulate P(\(x\), Q(\(x\))
	simultaneously:
		if P accepts first: ACCEPT
		if Q accepts first: REJECT</div>
				<p>
					Which will always halt. $$\tag*{$\Box$}$$
				</p>
			</div>
			
			<h3 id="tur-6">Closure of Turing Languages</h3>

			<hr>

			<p>
				<b><i>Complement.</i></b> Is a turing recognisable (TR) language closed under complementation?
			</p>
			<p>
				<b>No.</b> We know that HP is T.R. but not decidable. If \(\overline{HP}\) is decidable, then HP is decidable (because of our theorem) -- contradiction.
			</p>
			<p>
				Complement is closed for <i>decidable</i> languages, however. 
			</p>

			<hr>

			<p>
				<b><i>Union.</i></b> Yes! See the machine:
				<figure>
					<img src="./turing-union.png" alt="">
				</figure>
			</p>

			<hr>

			<p>
				<b><i>Intersection.</i></b> Also yes:
				<figure>
					<img src="./turing-intersection.png" alt="" >
				</figure>
			</p>

			<hr>
			<p>
				<b><i>Kleene Star.</i></b> \(L* \) Yes. 
			</p>
			<ul>
				<li>On input \(w\)</li>
				<li>Go over every partition of \(w\) into substrings</li>
				<li>For each substring run L</li>
				<li>If \(\exists\) a partition : all substrings are accepted, then ACCEPT.</li>
			</ul>

			<hr>

			<p>
				We can also produce different languages by tring to combine different "types" of languages:
			</p>

			<table>
				<tr>
					<th>\(\cup\)</th>
					<th>Reg</th>
					<th>CFL</th>
					<th>T. Dec</th>
					<th>T. Rec</th>
				</tr>
				<tr>
					<th>Reg</th>
					<td>Reg</td>
					<td></td>
					<td></td>
					<td></td>
				</tr>
				<tr>
					<th>CFL</th>
					<td>CFL</td>
					<td><i>T. Dec</i></td>
					<td></td>
					<td></td>
				</tr>
				<tr>
					<th>T. Dec</th>
					<td>T. Dec</td>
					<td>T. Dec</td>
					<td>T. Dec</td>
					<td></td>
				</tr>
				<tr>
					<th>T. Rec</th>
					<td>T. Rec</td>
					<td>T. Rec</td>
					<td>T. Rec</td>
					<td>T. Rec</td>
				</tr>
			</table>
			<p>
				In essense, the "strongest" langauge wins, <b>except</b> for the case of two CFLs, whch make a decidable language.
			</p>
			<p>
				The complement of TR languages are called <b>co-turing recognisable</b>, and can be represented with this diagram:
			</p>
			<figure>
				<img src="./coturingrecognisable.png" alt="">
			</figure>

			<h3 id="tur-7">Assorted Questions</h3>

			<p>
				These questions' answers will be collapsed as per usual, which allows one to have a go first (if they can be bothered).
			</p>

			<p>
				<b><i>Q1.</i></b> Is there a decider D, when given a TM M, that decides whether
				<ol type="A">
					<li>
						The TM has over 481 states?
					</li>
					
					<li>
						The TM takes \(\geq 481\) steps on the input \(\epsilon\)?
					</li>
					
					<li>
						The TM takes \(\geq 481\) steps for <i>some</i> input?
					</li>
					<li>
						The TM takes \(\geq 481\) steps for <i>all</i> inputs?
					</li>
					<li>
						The read head moves more than 481 cells from \(\vdash\) on \(\epsilon\)?
					</li>
					<li>
						Accepts \(\epsilon\)?
					</li>
					<li>
						Accepts any string? 
					</li>
					<li>
						Accept every string?
					</li>
				</ol>
			</p>

			<button class="collapsible">Answer 1A... </button>
			<div class="ccontent">
				<p>
					Yes... just count them.
				</p>
			</div>

			<button class="collapsible">Answer 1B... </button>
			<div class="ccontent">
				<p>
					Yes. Just run M on \(\epsilon\) for 481 steps.
				</p>
			</div>

			<button class="collapsible">Answer 1C... </button>
			<div class="ccontent">
				<p>
					Yes. Since \(\forall s \in \Sigma* : |s| \leq 481\), run M on \(s\) for 482 steps, or until it halts. 
				</p>
				<p>
					If any go to 482, accept. Else, reject. 
				</p>
				<p>
					Since for a string \(|s| &gt; 481\), only the first 481 symbols matter, since moving the reader head one space is one action (and thus state transition). Thus, we only need to consider the first 481 symbols of any string.
				</p>
			</div>

			<button class="collapsible">Answer 1D... </button>
			<div class="ccontent">
				<p>
					Yes. Run the machine on all strings 481 long and shorter. If any fail to take enough steps, reject.
				</p>
			</div>

			<button class="collapsible">Answer 1E... </button>
			<div class="ccontent">
				<p>
					<i>Observe</i> that if M never goes past cell 481, the machine can only ever be in a finitely many number of configurations (\(481\cdot |Q| \cdot |T|^{481}\))
				</p>
				<p>
					Just run for that many steps.
				</p>
			</div>
			<button class="collapsible">Answer 1F... </button>
			<div class="ccontent">
				<p>
					No, that's a membership problem.
				</p>
			</div>
			<button class="collapsible">Answer 1G...</button>
			<div class="ccontent">
				<p>
					See F.
				</p>
			</div>
			<button class="collapsible">Answer 1H...</button>
			<div class="ccontent">
				<p>
					See F.
				</p>
			</div>

			<p>
				<b><i>Q2.</i></b> \(A \leq_m B\) and B is a CFL, is A a CFL?
			</p>

			<button class="collapsible">Answer 2...</button>
			<div class="ccontent">
				<p>
					No. Let 
					\begin{align}
						A &= \{a^n b^n c^n : n \geq 0\} \\
						B &= \{0\} \pod{\subseteq \{0,1\} }
					\end{align}
					Let a mapping from A to B be \(\sigma(w):\)
				</p>
				<div class="codediv">if \(w \in A\): output 1
else: output 0</div>
				<p>
					Thus \(A \leq_m B\), and B is a CFL whilst A clearly is not. 
				</p>
			</div>

			<p>
				<b><i>Q3.</i></b> If \(A \leq_m B\) and B is regular, is A?
			</p>
			<button class="collapsible">Answer 3... </button>
			<div class="ccontent">
				<p>
					No. Use the same proof as (2)
				</p>
			</div>

			<p>
				<b><i>Q4.</i></b> Are Turing Recognisable languages closed under set difference>?
			</p>
			<button class="collapsible">Answer 4... </button>
			<div class="ccontent">
				<p>
					No. Take \(L_1 = \Sigma*, L_2 = HP\). \(L_1 \setminus L_2 = \overline{HP}\) which is not turing recognisable.
				</p>
			</div>

			<p>
				<b><i>Q5.</i></b> Is there a decider D, that given a <i>DFA</i> M with a binary alphabet, decides whether M accepts a string with more zeroes than ones?
			</p>

			<button class="collapsible">Answer 5... </button>
			<div class="ccontent">
				<p>
					Yes. For the decider:
				</p>
				<ul>
					<li>
						Construct a PDA N, which accepts all words with more zeroes than ones. 
					</li>
					<li>
						Construct the intersection PDA with M \(M' = M \cup N\), and check if this accepts \(\geq 1\) string.
					</li>
				</ul>
			</div>

			<p>
				<b><i>Q6.</i></b> Is there a decider D for the problem, given a regex \(r\), is there another regex \(p\) that 
				\begin{array}{} |p| < |r|, &L(r) = L(p) \end{array} 
			</p>
			<button class="collapsible">Answer 6... </button>
			<div class="ccontent">
				<p>
					We essentially are detecting whether two regexes get the same language.
				</p>
				<p>
					For two regexes (that match criteria), construct their DFAs. Then check if the DFAs both accept the same language, by checking if their symmetric difference \(L_1 \triangle L_2 (L_1 \setminus L_2 \cup L_2 \setminus L_1)\) doesn't accept a word. 
				</p>
				<p>
					So yes.
				</p>
			</div>

			<p>
				<b><i>Q7.</i></b> Is \(L_c = \{\langle M \rangle : M \textrm{ is a TM, } L(M) \textrm{ is countable}\}\) decidable?
			</p>

			<button class="collapsible">Answer 7... </button>
			<div class="ccontent">
				<p>
					Yes. \(\Sigma *\) is countable, and \(L(M) \subseteq \Sigma* \), thus \(L(M)\) is <b>always</b> coutnable. 
				</p>
				<p>
					So this is just checking that M is a turing machine. 
				</p>
			</div>

			<p>
				<b><i>Q8.</i></b> Is \(L_h - \{\langle M, x \rangle : M \textrm{ is a } DFA,\; M \textrm{ halts on }x\) decidable? 
			</p>

			<button class="collapsible">Answer 8...</button>
			<div class="ccontent">
				<p>
					Yes. DFAs always halt. 
				</p>
			</div>
		</div>

		<footer>
			<div class="cbox">
                <div class="columncontainer ctwo" id="fc2">
                </div>
                <script type="text/javascript" src="../../js/footerGen.js"></script>
            </div>
		</footer>

	</div>

	<script type="text/javascript" src="../../js/collapsible.js"></script>  <!--This stays at the end-->
	<script type="text/javascript" src="../../js/toggle-darklight.js"></script>
	<script type="text/javascript" src="../../js/prism.js"></script>
</body>
</html>