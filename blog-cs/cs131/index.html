<!DOCTYPE html>
<html>
<head>
	<title>CS131</title>
	<meta charset="utf-8">
	<link rel="stylesheet" type="text/css" href="../../style/style.css" media="all" id="theme-link">  <!--TODO: CHANGE HREF-->
	<!--<link rel="stylesheet" type="text/css" href="../../style/prism.css" media="all">-->
	<meta name="viewport" content="width=device-width" initial-scale=1.0>  <!--TODO: CHANGE LINKS ON BOTTOM OF SHEET FOR COLLAPSIBLE-->
	<link rel="icon" type="image/png" href="../../style/images/DragonIcon.png">
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

	<div class="hidden">
		<header>
			<div class="parallax parsmaller">
				<div  style="display: grid; grid-template-columns: 1fr 1fr 1fr 9fr 1fr; grid-column-gap: 10px; padding: 5px; ">
					<div class="column tinycolumn">
                        <a href="../../index.html" class="nav">Home</a>
                    </div>
                    <div class="column tinycolumn">
                        <a href="../../blog.html" class="nav">Back</a>
                    </div>
                    <div class="column tinycolumn">
                        <a href="../../about.html" class="nav">About</a>
                    </div>
					<div></div>
					<div class="column">
						<button class="nav dark-light">Dark Mode</button>
					</div>
				</div>
				<div class="cbox"> 		
					<h1>CS131</h1>
					<p class="subheading">Mathematics For Computer Scientists 2</p>
				</div>
			</div>
		</header>

		<header>
			<div class="cbox">
				<h1>Contents</h1>
			</div>
		</header>

		<div class="cbox">
			<ol>
				<li><a href="#zrc">Number Systems</a></li>
				<li><a href="#vec">Vectors</a></li>
				<li><a href="#matrices">Matrices</a></li>
				<li><a href="#sequences">Sequences and Series</a></li>
			</ol>

			<p>
				Yulia has already provided very comprehensive notes on all topics of 131, so these will summarise those and only include the most important points. Said notes are linked to when required (you will need an ITS account). 
			</p>
		</div>


		<div class="colourband" id="zrc">
			<h2>Number Systems</h2>
		</div>

		<div class="cbox">
			<h2>Introduction</h2>
			<ol>
				<li><a href="#zrc-1">Integers</a></li>
				<li><a href="#zrc-2">Reals</a></li>
				<li><a href="#zrc-3">Complex Numbers</a></li>
			</ol>

			<h2 id="zrc-1">Integers</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part1/note1.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				Integers, denoted \(\mathbb{Z}\). We use a denary/decimal (base-10) system with 10 digits, but there is also binary, which uses 2 digits.
			</p>

			<p>
				Subscripts are used to denote base; \(10011_{\textrm{two}} = 19_{\textrm{ten}}\) or \(10011_{2} = 19_{10}\).
			</p>

			<p class="side">
				<b><i>Decimal to Binary Conversion Alg.</i></b> Divide decimal number repeatedly by 2 to get remainders \(r_0, r_1, r_2,...r_n\). The binary representation is \(r_{n}r_{n-1}...r_{1}r_0\) (note the switched order).
			</p>

			<button class="collapsible">Problems...</button>
			<div class="ccontent">
				<p>
					<b><i>Q.</i></b> Convert \(244_{10}\) to binary.
				</p>

				<p>
					<b><i>Q.</i></b> The <i>hexadecimal</i> system is base 16, with digits 0123456789ABCDEF. Convert \(21BAD_{16}\) to decimal.
				</p>
			</div>


			<p class="side">
				<b><i>Generic Base Conversion Alg.</i></b> Let us have an integer \(b\). To convert a base 10 integer to a base \(b\) integer, divide repeatedly by \(b\) to get remainders \(r_0, r_1,...r_n\), thus the base \(b\) representation would be \(r_{n}r_{n-1}...r_{1}r_0\) (note the switched order).
			</p>

			<p class="side">
				<b><i>Division Algorithm.</i></b> If \(a, b \in \mathbb{Z}\) with \(b \neq 0\), then there exist unique \(q, r \in \mathbb{Z}\) with
				\begin{align}
				&a = qb + r, &0 \leq r < |b|
				\end{align}
				Where \(q\) is the <b>quotient</b> and \(r\) the <b>remainder</b>.
			</p>

			<p>
				If \(0 < b < a\) then an algorithm to compute \(q, r\) would be to iteratively compute \(a - b, a - 2b, ..., a-nb, a - (n-1)b\) where \(a - (n-1)b < 0\) is the first strictly negative number. Then \(q = n, r = a-nb\).
			</p>

			<p>
				If \(a = qb\) (all integers) then \(b\) <i>divides</i> \(a\). The greatest common denominator is denoted \(\gcd(a, b)\).
			</p>

			<p>
				\(\gcd(0, n) = n \; \forall n \in \mathbb{Z}^+\)
			</p>

			<div class="blue">
				<p>
					<b><i>EUCLIDEAN ALGORITHM.</i></b> Let \(r_1, r_0\) be integers s.t. \(0 < r_1 < r_0\).
				</p>

				<ol>
					<li>
						For each \(i\), define \(r_{i+1}\) as the remainder of \(\frac{r_{i-1}}{r_i}\). <br>The <b>last</b> non-zero remainder \(r_N = \gcd(r_1, r_0)\).
					</li>
					<br>
					<li>

						\(r_{i-1} = q_i r_i + r_{i+1} \; (1 \leq 1 \leq N\) can be used to write this last nonzero remainder, thus
						\[\gcd(r_1, r_0) = xr_1 + yr_0 \textrm{ for some integers } x, y.\]
					</li>
				</ol>
			</div>
			<br>
			<button class="collapsible">Problems...</button>
			<div class="ccontent">
				<p>
					<b><i>Q.</i></b> Find the greatest common divisor of 16579 and 30031, and determine integers \(x\) and \(y\) such that \(\gcd(16579, 30031) = x16579 + y30031\).

				</p>
			</div>

			<p>
				Of Modular Arithmetic, two integers \(a, b\) are congruent modulo \(n\) (another integer) if \(a-b = kn \; k \in \mathbb{Z}\), i.e. \(a = b + kn\). Written \(a \equiv b \mod n\) or \(a \stackrel{\mod{}}{\equiv} b\).
			</p>

			<p>
				Two congruencies with the same mod \(n\) can be added, subtracted, multiplied just like normal equations. 
			</p>

			<p>
				In a computer, for negative integers we use two's complement, see <a href="../cs132/index.html#datarep" class="text">here</a>.
			</p>

			<p>
				We are also working with a system modulo \(2^N\) where \(N\) is the number of bits. Thus the 32 bit limit of \([2^{31}, 2^{31} - 1]\) which is \(2^{32}\) integers.
			</p>

			<h2 id="zrc-2">Reals</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part1/note2.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				Reals are denoted \(\mathbb{R}\), and have a subset \(\mathbb{Q}\) which are numbers definable as \(\frac{m}{n}, \; m, n \in \mathbb{Z}, \; n \neq 0\). We can always pick rationals such that \(n \geq 1\) and \(\gcd(m, n) = 1\). Every nonzero rational has an inverse. 
			</p>

			<p>
				Reals which are the solutions of polynomial equations are called <b>algebraic</b>, an example would be \(\sqrt{2}\) (being the solution of \(x^2 = 2\)).
			</p>

			<p>
				Those which are not are called <b>transcendental</b>, such as \(\pi, e\).
			</p>

			<p>
				A real number can be thought of as a sequence of rational numbers, which converges to said real. e.g. \(\pi\) is the limit of \(3, 3.1, 3.14, 3.141, 3.1415...\)
			</p>

			<p>
				All properties of real numbers come from <b>13 axioms</b>, of which 1-8 are <b>algebraic</b> properties, and 9-12 are <b>order properties</b>.
			</p>

			<div class="blue">
				<p>
				For all \(x, y, z \in \mathbb{R}\):
			</p>

			<ol>
				<li><b>Commutativity</b>: \(x + y = y + x, \;  xy = yx\)</li>
				<li><b>Associativity</b>: \(x + (y + z) = (x + y) + z\) (same with multiplication)</li>
				<li>Multiply <b>distributes</b> over add: \(x(y + z) = xy + xz\)</li>
				<li><b>Additive Identity</b>: \(\exists 0 \in \mathbb{R }: x + 0 = x\)</li>
				<li><b>Multiplicative identity</b>: \(\exists 1 \in \mathbb{R} : x \cdot 1 = x\)</li>
				<li>Multiplicative and additive identites are <b>distinct</b>: \(1 \neq 0\)</li>
				<li>Every element has an <b>additive inverse</b>: \(\exists (-x) \in \mathbb{R}: x + (-x) = 0\)</li>
				<li>Every \(\neq 0\) element has a <b>mul. inverse</b>: \(x \neq 0 \implies \exists x^{-1} \in \mathbb{R} : x \cdot x^{-1} = 1\)</li>
				<li><b>Transitivity</b> of ordering: \(x < y \land y < z \implies x < z\)</li>
				<li><b>Trichotomy Law</b>: only <b>one</b> of \(x < y,\; x > y,\; x = y\)</li>
				<li><b>Order preserved</b> under add: \(x < y \implies x + z < y + z\)</li>
				<li><b>Order preserved</b> under mul: \(0 < z \land x < y \implies xz < yz\)</li>
				<li><b>Completeness</b>: <i>Every non-empty subset of \(\mathbb{R}\) that is bounded above has a least upper bound</i></li>
			</ol>
			</div>

			

			<p class="side">
				<b><i>Excersise.</i></b> Show that \(0 < 1 \).
			</p>
			<button class="collapsible">Answer...</button>
			<div class="ccontent">
				<p>
					We first need a lemma.
				</p>

				<p>
					<b><i>Lemma 1.</i></b> \(\forall x ,\; x^2 \geq 0\).
				</p>

				<p>
					<b><i>Proof of Lemma 1.</i></b> Consider the cases where \(x < 0\) and \(x \geq 0\).
				</p>

				<p>
					When \(x \geq 0\),
					\begin{align}
					x \geq 0 &\implies x^2 \geq 0 \cdot 0 \textrm{ by ax. 12}\\
					&\implies \geq 0.
					\end{align}
				</p>

				<p>
					When \(x < 0\), \(-x \geq 0\), so:
					\begin{align}
					x^2 = x \cdot x &= (-x)(-x) \\
					&\geq 0 \cdot 0 \textrm{ by prev case}\\
					&\geq 0. &\triangleright
					\end{align}
				</p>

				<p>
					Then, we can prove. <br>
					<b><i>Proof.</i></b>
					\begin{align}
					1^2 &\geq 0 \textrm{ by lemma}\\
					\implies 1 &\geq 0\\
					1 &\neq 0 \textrm{ by ax. 6 } \therefore 1 > 0.
					\end{align}
					$$\tag*{$\Box$}$$
				</p>
			</div>

			<p class="side">
				<b><i>Excersise.</i></b> Show that \(a > 0 \implies \frac{1}{a} > 0\).
			</p>
			<button class="collapsible">Answer...</button>
			<div class="ccontent">
				<p>
					<b><i>Proof.</i></b> Let \(a > 0\)
					\begin{align}
					\textrm{If } \frac{1}{a} &= 0 \\
					\implies 1 &= a(\frac{1}{a}) = a \cdot 0 = 0 \\
					&\textrm{which is a contradiction to ax. 6.}
					\end{align}

					\begin{align}
					\textrm{If } \frac{1}{a} &< 0 \\
					\implies a (\frac{1}{a}) &< a \cdot 0 \textrm{ by ax. 12} \\
					\implies 1 &= 0 \textrm{ which is a contradiction.}
					\end{align}

					By axiom 10 we get that \(\frac{1}{a} > 0\). $$\tag*{$\Box$}$$
				</p>
			</div>

			<p></p>
			<button class="collapsible">More Problems...</button>
			<div class="ccontent">
				<p>
					<b>Q.</b> Show if \(a, b > 0\) then \(a < b \Longleftrightarrow a^2 < b^2\). <i>Note: you have to prove both ways.</i>
				</p>

				<p>
					<b>Q.</b> Show if \(a < b \land c < 0 \implies ac > bc\).
				</p>
			</div>

			<p></p>

			<button class="collapsible">Intervals, n<sup>th</sup> roots and Modulus/Abs basics...</button>
			<div class="ccontent">
				<p>
					<b>Intervals</b> are ranges represented by brackets. \((a, b)\) ranges are called <b>open</b>, \([a, b), \; (a, b]\) are called <b>semi-open</b> or <b>semi-closed</b> and \([a, b]\) ranges are called <b>closed</b>. \(\infty\) is not a real number and cannot appear in closed ranges.
				</p>

				<p>
					Let \(n \in \mathbb{Z}^+\). For any \(a \in \mathbb{R}_{\geq 0}, \; \exists! x \geq 0\) with \(x^n = a\). This \(x\) is the <b>\(n^{th}\) root</b> of \(a\), \(a^{\frac{1}{n}}\). For any positive real \(a, b\) and \(n \in \mathbb{Z}^+\) we have

					\[a < b \Longleftrightarrow a^{\frac{1}{n}} < b^{\frac{1}{n}}\]

					There's also of course \(a^\frac{1}{2} \equiv \sqrt{a}\) and all that comes with it.
				</p>

				<p>
					The <b>Modulus or Absolute</b> of \(x\), \(|x|\) is basically \(x\) but without negatives. \(|x| = \sqrt{x^2} \; \forall x \in \mathbb{R}\).
				</p>
			</div>
			<p></p>

			<div class="blue">
				<p>
				There are 4 properties of modulus:
			</p>

			<ol>
				<li>\(-|x| \geq x \geq |x|\)</li>
				<li>\(|xy| = |x||y|\)</li>
				<li>\(|x + y| \geq |x|+|y|\)</li>
				<li>\(||x| - |y|| \leq |x - y|\)</li>
			</ol>
			</div>

			

			<p>
				For a set of real numbers \(S\)
			</p>

			<ul>
				<li>\(u\) is an <b>upper bound</b> of S if \(u \geq x \forall x \in S\)</li>
				<li>\(U\) is the <b>least upper bound (supremum)</b> of S if \(U\) is an UB of S and \(U \leq u \forall u\)</li>
				<li>\(l\) is a <b>lower bound</b> of S if \(l \leq x \forall x \in S\)</li>
				<li>\(L\) is the <b>greatest lower bound (infimum)</b> of S if \(L\) is a LB of S and \(L \geq l \forall l\)</li>
			</ul>

			<img src="bounds.svg" style="max-width: 100%; width: 600px">

			<p>
				The <i>completeness axiom</i> suggests that for every set which has a lower bound has a greatest lower bound. 
			</p>

			<div class="blue">
				<p>
					<b>Important consequences of the completeness axiom:</b>
				</p>

				<ul>
					<li><b>The ARCHIMEDIAN PROPERTY</b> of \(\mathbb{R}\): <br>if \(\epsilon \in \mathbb{R}; \epsilon > 0\) then \(\exists n \in \mathbb{Z}^+ : n\epsilon > 1\).</li> 
					<li>Between any two real numbers there are both rational and irrational numbers.</li>
					<li>Every real number can be represented by a (possibly infinite) decimal expansion.</li>
				</ul>
			</div>


			<h2 id="zrc-3">Complex Numbers</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part1/note3.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				In the set \(\mathbb{C}\), of the form \(a + ib\) where \(i^2 = \sqrt{-1}\). Often denoted \(z\).
			</p>

			<p>
				Representable by an ordered pair \(z = (a, b)\) where \(Re_z = a\) and \(Im_z = b\). Also represnetable as a point on a 2d plane, the <i>complex plane</i> or <i>argand diagram</i>.
			</p>

			<p>
				For \(a, b \in \mathbb{R}\) the <b>complex conjugate</b> of \(z = a + ib\) is \(\overline{z} = a - ib\) (overline). Effectively reflecting along x axis. 
			</p>

			<p>
				<b>Properties of complex conjugates (\(\forall z, w \in \mathbb{C}\)):</b>
			</p>

			<div class="columncontainer ctwo" style="grid-column-gap: 20px">
				<div>
					<ul>
						<li>\(\overline{z + w} = \overline{z} + \overline{w}\)</li>
				<li>\(\overline{zw} = \overline{z}\overline{w}\)</li>
				<li>\(\overline{(\frac{z}{w})} = \frac{\overline{z}}{\overline{w}}\)</li>
				<li>\(\overline{\overline{z}} = z\)</li>
					</ul>
				</div>
				<div>
					<ul>
						<li>\(z \in \mathbb{R} \Longleftrightarrow \overline{z} = z\)</li>
				<li>\(Re_z = \frac{z + \overline{z}}{2}\)</li>
				<li>\(Im_z = \frac{z - \overline{z}}{2i}\)</li>
					</ul>
				</div>
			</div>

			<div class="blue">
			<p>
				If \(x, y \in \mathbb{R}\) and \(x + iy \neq 0\) we can express \(x\) and \(y\) in polar coordinates,
				\begin{align}
				&x = r \cos(\theta) &y = r \sin(\theta)
				\end{align}
				\[\therefore x + iy = r(\cos(\theta) + i\sin(\theta).\]
				\begin{align}
				&r = \sqrt{x^2 + y^2} &\theta \textrm{ satisfies } \tan(\theta) = \frac{y}{x}.
				\end{align}

				\(\theta\) is the <b>argument</b>, with the <b>principal argument</b> being a \(\theta \in (-\pi, \pi]\).
			</p>

			<p>
				\(r\) is the <b>modulus</b>, often denoted \(|x + iy|\).
			</p>
			</div>
			
			<p>
				<b>Properties of modulus</b>, for all \(z, w \in \mathbb{C}\):
			</p>

			<div class="columncontainer ctwo" style="grid-column-gap: 20px">
				<div>
					<ul>
						<li>\(|z| = |\overline{z}|\)</li>
						<li>\(|z| = \sqrt{z\overline{z}}\)</li>
						<li>\(z\overline{z} = |z|^2\)</li>
					</ul>
				</div>
				<div>
					<ul>
						<li>\(|zw| = |z||w|\)</li>
						<li>\(|z + w| \leq |z| + |w|\), <i>(triangle inequality)</i></li>
						<li>\(||z| - |w|| \leq |z - w|\)</li>
					</ul>
				</div>
			</div>

			<p>
				Proof of the triangle inequality is omitted.
			</p>

			<p>
				You can multiply two complex numbers in polar form, \(r_{1} (\cos(\theta) + i\sin(\theta)) \cdot r_{2} (\cos(\phi) + i\sin(\phi)) = r_{1}r_{2}(\cos(\theta + \phi) + i\sin(\theta + \phi))\). 
			</p>

			<div class="blue">
				<p>
					<b><i>De Moivre's Theorem.</i></b> \(\forall n \in \mathbb{Z}\):
					\[(r(\cos{\theta} + i\sin \theta))^n = r^{n}(\cos{n\theta} + i\sin{n\theta}).\]
				</p>
			</div>

			<p class="side">
				<b><i>Q.</i></b> Find all complex numbers \(z : z^3 = 1\).
			</p>

			<p class="side">
				The <b><i>Fundamental Theorem of Algebra</i></b> (Gauss) states that an \(n\) degree polynomial must have \(n\) roots. 
			</p>

			<p class="side">
				<b><i>Other Notation.</i></b> The conjugate \(\overline{z}\) can also be written \(z*\). Sometimes (often in engineering) \(i\) is \(j\).
			</p>
			

		</div>

		<div class="colourband" id="vectors">
			
			<h2>Vectors</h2>
		</div>

		<div class="cbox">
			<h2>Introduction</h2>

			<ol>
				<li><a href="#vec-1">Basics</a></li>
				<li><a href="#vec-2">Linear Combinations and Subspaces</a></li>
				<li><a href="#vec-3">Linear Independence</a></li>
			</ol>

			<h2 id="vec-1">Basics</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part2/note4.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				Vectors in 2 and 3D are members of the sets \(\mathbb{R}^2\) and \(\mathbb{R^3}\) respectively. <i>(Note, thus ordered pairs)</i>
			</p>

			<p>
				Can be treated as coordinate points. 
			</p>

			<p>
				Denoted either with arrow (\(\vec{x}\)), underline (\(\underline{x}\)), or bold (\(\mathbfit{x}\)). I'll be using the arrow.
			</p>

			<p>
				Addition and scalar multplication are done element-wise. For \(\vec{x} = (x_1, x_2, ..., x_n)\) and \(\vec{y} = (y_1, y_2, ..., y_n)\)

				\[\lambda \vec{x} = (\lambda x_1, \lambda x_2, ..., \lambda x_n)\]
				\[\vec{x}\vec{y} = (y_1 + x_1, y_2 + x_2, ...,y_3 + x_n)\]

				\(\vec{x} - \vec{y}\) and \(-\vec{x}\) are also defined accordingly from these.
			</p>

			<p>
				In \(\mathbb{R}^2\) if \(\vec{p} = (p_1, p_2)\) then this is the directed line segment \(\overrightarrow{OP}\) starting at origin \(O\) and ending at point P \((p_1, p_2)\). \(\vec{p}\) is then the <b>position vector</b> of P.
			</p>

			<p>
				Two line segments are equivalent if they have the same length and direction. 
			</p>

			<p>
				For points \(A, B\) with vecs \(\vec{a}, \vec{b}\) then \(\overrightarrow{AB} = \vec{b} - \vec{a}\).
			</p>

			<div class="blue">
				<p>
					For \(\vec{a} = (a_1, a_2) \in \mathbb{R}^2\)
				</p>

				<p>
					The <b>length of \(\vec{a}\)</b> \(|\vec{a}| = \sqrt{a_{1}^{2} + a_{2}^{2}}\); similarly in 3D.
				</p>

				<p>
					A <b>unit vector</b> has length 1. The <b>distance</b> between \(\vec{a}, \vec{b} = |\vec{b} - \vec{a}|\).
				</p>
			</div>

			<p></p>

			<div class="blue">
				<p>
					The <b>scalar (dot) product</b>, \(\vec{a} \cdot \vec{b}\) is the real number \(a_1 b_1 + a_2 b_2 + ... + a_n b_n\).
				</p>
				
				<p>
					The angle between two position vectors, \(\theta\) between vectors \(\vec{a}, \vec{b}\) is given by

					\[\cos \theta = \frac{\vec{a} \cdot \vec{b} }{|\vec{a}||\vec{b}|}.\]

					Two vectors are <b>orthogonal</b> (perpendicular) if dot product is 0.
				</p>
			</div>

			<p>
				All definitions (if not already) can be extended to \(n\) dimensions.
			</p>

			<p class="blue">
				The <b>zero vector</b>, \(\vec{0}\) has all zeros in it.
			</p>

			<h2 id="vec-2">Linear Combinations and Subspaces</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part2/note5.pdf" class="text">Link to the PDF.</a>
			</p>

			<div class="blue">
				<p>
					<b><i>Linear Combination.</i></b> If \(\vec{u}_1, \vec{u}_2, ..., \vec{u}_m \in \mathbb{R}^n\) and \(a_1, a_2, ..., a_m \in \mathbb{R}\), then any vector of the form

					\[a_1 \vec{u}_1 + a_2 \vec{u}_2 + ... + a_m \vec{u}_m\]

					is a <b>linear combination</b> of \(\vec{u}_1, \vec{u}_2, ..., \vec{u}_m \).
				</p>
			</div>

			<p>
				A linear comb. of a single vector is defined as a multiple of that vector.
			</p>

			<p>
				In \(\mathbb{R}^3\) if \(\vec{u}, \vec{v}\) are not parallel, then \(\alpha \vec{u} + \beta \vec{v}\) represents the vertex of a parallelogram having \(\alpha \vec{u}, \beta \vec{v}\) as sides - a vector in the <b>plane</b> containing \(\vec{u}, \vec{v}, \vec{0}\).
			</p>

			<div class="blue">
				<p>
					<b><i>Span.</i></b> If \(U = \{\vec{u}_1, \vec{u}_2, ..., \vec{u}_m\}\) is a finite set of vectors in \(\mathbb{R}^n\), then the <b>span</b> of U is the set of all linear combinations of vectors in U and is denoted \(\textrm{span } U\);

					\[\textrm{span } U = \{a_1 \vec{u}_1 + a_2 \vec{u}_2 + ... + a_m \vec{u}_m : a_1, a_2, ..., a_n \in \mathbb{R}\}.\]
				</p>
			</div>

			<ul>
				<li>
					If \(U = \{\vec{u}\}\) then the span is the set of all multiples of \(\vec{u}\). 
				</li>
				<li>
					Note that for <i>basis</i> spans, 1 vector is a line, 2 vectors is a plane, and onwards to hyperplanes. (Basis is covered in next section)
				</li>
				<li>
					Elementary spans of \(\mathbb{R}^2, \mathbb{R}^3\) are \(\{(1, 0), (0, 1)\}\) and \(\{(1, 0, 0), (0,1,0), (0,0,1)\}\) respectively. 
				</li>
			</ul>

			<div class="blue">
				<p>
					<b><i>Subspaces.</i></b> A <b>subspace</b> of \(\mathbb{R}^n\) is a non-empty subset \(S \subseteq \mathbb{R}^n\) such that:
					\begin{align}
					(1) &\vec{u}, \vec{v} \in S \implies \vec{u} + \vec{v} \in S;\\
					(2) &\vec{u} \in S, \lambda \in \mathbb{R} \implies	\lambda \vec{u} \in S.
					\end{align}
					i.e. closed on addition and multiplication.
				</p>
			</div>

			<p>
				Means if a set of vectors is in a subspace, any linear combinations of those vectors is also in.
			</p>

			<p>
				Two elementary subspaces of \(\mathbb{R}^n\) are \(\{\vec{0}\}\) (just empty) and \(\mathbb{R}^n\) itself.
			</p>

			<button class="collapsible">Problem...</button>
			<div class="ccontent">
				<p>
					<b><i>Problem.</i></b> Determine if \(S\) is a subspace of \(\mathbb{R}^n\):
				</p>

				<ol>
					<li>\(S = \{(x, y, 0) : x, y \in \mathbb{R}\} \in \mathbb{R}^3\)</li>
					<li>\(S = \{(1, 1)\} \in \mathbb{R}^2\)</li>
					<li>\(S = \{(x, y) : x^2 + y^2 \leq 1\} \in \mathbb{R}^2\)</li>
				</ol>
			</div>
			<button class="collapsible">Answer...</button>
			<div class="ccontent">
				<p>
					<b><i>Answer.</i></b>(1) We need to show closure on addition and scaling. Let \(\vec{u}, \vec{v} \in S : \vec{u} = (a, b, 0), \vec{v} = (c, d, 0)\) for some \(a, b, c, d \in \mathbb{R}\).

					\[\vec{u} + \vec{v} = (a, b, 0) + (c, d, 0) = (a+c, b+d, 0) \in S.\]

					For any \(\lambda \in \mathbb{R}\)

					\[\lambda \vec{u} = \lambda (a, b, 0) = (\lambda a, \lambda b, 0) \in S.\] 
				</p>

				<p>
					(2) Nope, since \(2(1,1) \not \in S\), so no scaling closure.
				</p>

				<p>
					(3) Nope. Let \(\vec{u} = (1, 0), \vec{v} = (0, 1)\), both of which \(\in S\), however \(\vec{u} + \vec{v} = (1, 1)\). \(1^2 + 1^2 = 2 \not \leq 1\), so not closed under addition.
				</p>
			</div>

			<p></p>
			<div class="blue">
				<p>
					<b><i>Properties of Subspaces.</i></b>
				</p>

				<ol>
					<li>Every subspace contains \(\vec{0}\).</li>
					<li>If \(U\) is a nonempty finite subset of \(\mathbb{R}^n\) then \(\textrm{span } U\) is a subspace, the subspace <b>spanned or generated</b> by U.</li>
				</ol>
			</div>

			<h2 id="vec-3">Linear Independence</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part2/note5.pdf" class="text">Link to the PDF.</a>
			</p>

			<div class="blue">
				<p>
				A set of vectors \(\{\vec{u}_1, \vec{u}_2, ..., \vec{u}_m\} \in\mathbb{R}^n\) are <b>linearly <i>dependent</i></b> IF there are real numbers \(a_1, a_2, ..., a_n\) which are NOT ALL ZERO such that \(a_1 \vec{u}_1 + a_2 \vec{u}_2 + ... + a_m \vec{u}_m = \vec{0}.\)

				
			</p>
			<p>
				Thus a <b>linearly <i>independent</i></b> set is where IF \(a_1 \vec{u}_1 + a_2 \vec{u}_2 + ... + a_m \vec{u}_m = \vec{0}.\)
				THEN ALL \(a_i\) are <b>0</b>.
			</p>
			</div>
			

			<p>
				i.e. if you can't find a nonzero linear combination that makes zero vector, then the set is linearly independent.
			</p>

			<ul>
				<li>If a set contains one nonzero vector, it is lin. indep.</li>
				<li>If it contains the zero vector, it is lin. dep.</li>
			</ul>

			<p>
				In a set of three vectors, you can fairly easily solve three simultanous equations all with the sum of zero. Then, you either find that your three coefficients \(\alpha, \beta, \gamma\) has to be 0 (indep) or there is some non-zero relationship between at least two of them (dep)
			</p>

			<p class="side">
				<b><i>Theorem.</i></b> A set \(\{\vec{u}_1, \vec{u}_2, ..., \vec{u}_m\}\) of nonzero vectors is linearly <i>depending</i> <b>iff</b> some / any vector \(\vec{u}_r\) is a linear combination of its predecessors \{\vec{u}_1, \vec{u}_2, ..., \vec{u}_m{r-1}\}
			</p>

			<p><i>(proof omitted)</i>
			</p>

			<h2 id="vec-4">Basis and Dimension</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part2/note7.pdf" class="text">Link to the PDF.</a>
			</p>

			<p class="blue">
				<b><i>Basis.</i></b> Let \(S\) be a subspace of \(\mathbb{R}^n\). A set of vectors is a <b>basis</b> of S if it is a <i>linearly independent</i> set which spans S.
			</p>

			<p> 
				e.g. The set \(\{(1,0,0), (0,1,0), (0,0,1)\}\) is a basis for \(\mathbb{R}^3\). In fact, it is the <b>standard basis</b>.
			</p>

			<p class="side">
				<b><i>Theorem.</i></b> Let \(S\) be subspace of \(\mathbb{R}^n\). If a set \(\vec{v}_1, \vec{v}_2, ..., \vec{v}_m\) spans S, then any <i>linearly indep.</i> subset of S has <i>at most</i> \(m\) vectors.
			</p>

			<p><i>(proof omitted)</i></p>

			<p>
				This leads to the fact that any two bases for a subpace S have the <b>same</b> number of elems. 
			</p>

			<p class="blue">
				<b><i>Dimension.</i></b> The <b>dimension</b> of a subspace of \(\mathbb{R}^n\) is the number of vectors in the basis.
			</p>

			<button class="collapsible">Problem...</button>
			<div class="ccontent">
				<p>
					<b><i>Problem.</i></b> Show that the set \(S = \{(x, y, z) : x + 2y - z = 0\}\) is a subspace of \(\mathbb{R}^3\), and find a basis and dimension of \(S\).
				</p>
			</div>
			<p></p>
			<button class="collapsible">Answer...</button>
			<div class="ccontent">
				<p>
					<b><i>Answer.</i></b> We can rewrite S as:
					\begin{align}
					S &= \{(x, y, x+2y = 0) : x, y \in \mathbb{R}\} \\
					&= \{x(1, 0, 1) + y(0, 1, 2) : x, y \in \mathbb{R}\} \\
					&= \textrm{ span } \{(1, 0, 1), (0, 1, 2)\}.
					\end{align}

					Whih shows that S is a subspace, since the span of any nonempty finite set is a subspace (known property). 
				</p>

				<p>
					By inspection we can see that the two vectors in the set are independent, thus it is a basis. Thus the dimension of S is 2. 
				</p>
			</div>

			<p>
				(Supposedly) we can use the theorem from <a href="#vec-3">lineaer independence</a> to construct a basis from as panning set. 
			</p>

			<div class="blue">
				<p>
					Let \(\{\vec{v}_1, \vec{v}_2, ..., \vec{v}_m\}\) be a basis of a subspace S of \(\mathbb{R}^n\). Then removing each \(\vec{v}_i\) which is a linear combination of its "predecessors" will leave a basis for S. 
				</p>
			</div>
			<p></p>
			<button class="collapsible">Problem...</button>
			<div class="ccontent">
				<p>
					<b><i>Problem.</i></b> Find a basis for and dimension of a subspace S (of \(\mathbb{R}^4\)) spanned by
					\[\{(2,1,0,-3), (-1,0,-1,2), (1,2,-3,0), (0,0,0,1), (0,1,-2,0)\}.\]
				</p>
			</div>
			<p></p>
			<button class="collapsible">Answer...</button>
			<div class="ccontent">
				<p>
					<b><i>Answer.</i></b> Let's look at (1, 2, -3, 0) and see if it is a lin. comb. of predecessors. 
					\[(1, 2, -3, 0) = \alpha(2,1,0,-3) + \beta(-1,0,-1,2)\]
					\begin{align}
					&\implies \begin{cases} 2\alpha - \beta &= 1 \\ \alpha &= 2 \\ -\beta &= -3 \\ -3\alpha + 2\beta &= 0 \end{cases}
					&\implies \begin{cases} \alpha &= 2 \\ \beta &= 3. \end{cases}
					\end{align}
					We can see it is a linear combination, so we remove, giving
					\[\{(2,1,0,-3), (-1,0,-1,2), (0,0,0,1), (0,1,-2,0)\}.\]
				</p>

				<p>
					Now we next check \((0,0,0,1)\). 
					\[(0,0,0,1) = \alpha(2,1,0,-3) + \beta(-1,0,-1,2)\]
					\begin{align}
					&\implies \begin{cases} 2\alpha - \beta &= 0 \\ \alpha &= 0 \\ -\beta &= 0 \\ -3\alpha + 2\beta &= 1 \end{cases}
					&\implies \begin{cases} \alpha &= 0 \\ \beta &= 0 \\ -3\alpha + 2\beta &= 1. \end{cases}
					\end{align}

					Which have no solution of \(\alpha, \beta\) and thus (0, 0, 0, 1) is not a linear combination of priors. Thus \(\{(0,0,0,1),(2,1,0,-3),(-1,0,-1,2)\}\) is a lin. indep. set.
				</p>

				<p>
					Check the last one against all others,
					\[(0,1,-2,0) = \alpha(2,1,0,-3) + \beta(-1,0,-1,2) + \gamma(1, 2, -3, 0)\]
					\begin{align}
					&\implies \begin{cases} 2\alpha - \beta &= 0 \\ \alpha &= 1 \\ \beta &= 2 \\ -3\alpha + 2\beta + \gamma &= 0 \end{cases}
					&\implies \begin{cases} \alpha &= 1 \\ \beta &= 2 \\ \gamma &= -1. \end{cases}
					\end{align}
					So we remove that, thus finally the remaining set \(\{(0,0,0,1),(2,1,0,-3),(-1,0,-1,2)\}\) is the final basis of \(S\), which gives \(S\) a dimension of 3.
				</p>
			</div>

			<p>
				There are a few quick checks one can do beforehand. 
			</p>

			<div class="blue">
				<p>
					Let S be an \(m\)-dimensional subspace of \(\mathbb{R}^n\) then
				</p>
				<ol>
					<li>Any subset of S with more than \(m\) vectors is linearly <i>dependent</i>;</li>
					<li>A subset of S is a basis <i>if and only if</i> it is a linearly independent set containing \(m\) vectors.</li>
				</ol>

				<p>
					It then follows that any subset of \(\mathbb{R}^n\) is linearly <i>dependent</i>, and a subset of \(\mathbb{R}^n\) <i>iff</i> it is a linearly independent set containing \(n\) vectors. 
				</p>
			</div>
			<p></p>

			<button class="collapsible">\(\mathbb{R}^2, \mathbb{R}^3\) properties...</button>
			<div class="ccontent">
				<p>
					Subspaces of \(\mathbb{R}^2\):
				</p>
				<ol>
					<li>There is one 0 dim subspace \(\{\vec{0}\}\)</li>
					<li>A 1D subspace is spanned by a single non-zero vector: straight lines through origin.</li>
					<li>The only 2D subspace is \(\mathbb{R}^2\)</li>
				</ol>

				<p>
					Subspaces of \(\mathbb{R}^3\):
				</p>
				<ol>
					<li>There is one 0 dim subspace \(\{\vec{0}\}\)</li>
					<li>A 1D subspace is spanned by a single non-zero vector: straight lines through origin.</li>
					<li>A 2D subspace is spanned by 2 lin. indep. vectors: plains containing the origin</li>
					<li>The only 3D subspace is \(\mathbb{R}^3\)</li>
				</ol>
			</div>

			
		</div>

		<div class="colourband" id="matrices">
			<h2>Matrices</h2>
		</div>

		<div class="cbox">
			<h2>Introduction</h2>

			<ol>
				<li><a href="#mat-1">Matrix Algebra</a></li>
				<li><a href="#mat-2">Matrix Inverse, Linear Equations</a></li>
				<li><a href="#mat-3">Matrix Inverse, Determinants</a></li>
				<li><a href="#mat-4">Linear Transformations</a></li>
				<li><a href="#mat-5">Matrices and Linear Transformations</a></li>
			</ol>

			<h2 id="mat-1">Matrix Algebra</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part2/note8.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				Matrices are rectangular arrays of elements. It's order is its \(\textrm{row } \times \textrm{ column}\). Note that an \(m \times 1\) matrix is called a <b>column matrix/vector</b>, and \(1 \times n\) matrices are similarly named as rows. Elements are referred to with subscript row column: \(a_{ij}\).
			</p>

			<p>
				Sum of two matrices is only defined if they have the same order, and is <i>elementwise</i> addition. Scalar multiplication is also done elementwise.
			</p>

			<p>
				The Zero matrix, denoted \(O_{m \times n}\) is a matrix of all zeros. 
			</p>

			<div class="blue">
				<p>
					<b><i>Properties of addition and scalar multiplication.</i></b> \(\forall m \times n\) matrices \(A, B, C\), \(\forall \lambda, \mu \in \mathbb{R}\):
				</p>

				<ol>
					<li>\(A + (B+C) = (A+B)+C\) (associativity of addition)</li>
					<li>\(A + O = A = O + A\)</li>
					<li>\(A + (-A) = O = (-A) + A\)</li>
					<li>\(A+B=B+A\) (commutativity of addition)</li>
					<li>\((\lambda + \mu)A = \lambda A + \mu A\)</li>
					<li>\(\lambda (A+B) = \lambda A + \lambda B\)</li>
					<li>\(\lambda(\mu A) = (\lambda \mu ) A\)</li>
				</ol>
			</div>

			<p>
				Matrix multiplication can only happen between an \(A_{m \times \mathbfit{n}}\) and a \(B_{\mathbfit{n} \times p}\) (note the highlighted dimensions) and will produce a matrix \(C_{m \times p}\). 
			</p>

			<p>
				Matrix multiplication is hard to explain in text, so <a href="https://www.youtube.com/watch?v=as8C8w-Nz94">see this video</a> if you're not sure (by blackpenredpen).
			</p>

			<p>
				A square matrix \(A_{n \times n}\) is said to be of <i>order \(n\)</i>
			</p>

			<p>
				<b>Diagonal matrices</b> only have elements on the leading diagonal; \(a_{ii}\) for some \(i : [1..n]\).
			</p>

			<p>
				The <b>identity matrix</b> \(I\) (or \(I_n\)) is the \(n \times n\) diagonal matrix whose diagonal elements are all 1. 
			</p>

			<p>
				For a square matrix \(A\), \(A, AA, AAA, ...\) are defined as \(A, A^2, A^3,...\) respectively. \(A^0 = I\). Functions \(\exp(A), \cos(A), \sin(A)\) can also be defined <i>(hint: taylor series)</i>.
			</p>

			<div class="blue">
				<p>
					<b><i>Properties of matrix multiplicaiton.</i></b> whenever the products exist:
				</p>
				<ol>
					<li>\((AB)C = A(BC)\) (associativity)</li>
					<li>\(A(B+C) = AB + AC\), \((A+B)C = AC + BC\)</li>
					<li>\(IA = A = AI\)</li>
					<li>\(OA = O = AO\)</li>
					<li>\(A^p A^q = A^{p+q} = A^q A^p\), \((A^p)^q = A^{pq}\)</li>
				</ol>
				<p>
					Note that matrix multiplication is <b>not commutative</b>: \(AB \neq BA\) (for all but specific circumstances).
				</p>
			</div>

			<p>
				The <b>transpose</b> \(A^T\) of a matrix is obtained by swapping rows and columns (i.e. reflecting on leading diagonal).
			</p>

			<div class="blue">
				<p>
					<b><i>Properties of transposition.</i></b>
				</p>
				<ol>
					<li>\((A^T)^T=A\)</li>
					<li>\((A+B)^T = A^T + B^T\) if \(A+B\) exists</li>
					<li>\((\lambda A)^T = \lambda A^T\) for any \(\lambda \in \mathbb{R}\)</li>
					<li>\((AB)^T = B^T A^T\) if \(AB\) exists.</li>
				</ol>
			</div>

			<p>
				For same order square matrices \(A, B\), \(B\) is the inverse of \(A\) if and only if \(AB = I = BA\). The inverse (should it exist) is <b>unique</b> and denoted \(A^{-1}\).
			</p>

			<p>
				The <b>determinant</b> of a \(2 \times 2\) matrix \(A = \begin{bmatrix} a & b \\ c & d \end{bmatrix}\) is \(ad-bc\) and denoted \(|A|, \det(A)\).
			</p>

			<p>
				If a \(2 \times 2\) matrix is invertible, then \(\det(A)det(A^{-1}) = \det(AA^{-1}) = \det(I) = 1\). Thus \(\det(A) \neq 0\) and in that case,
			</p>

			<p class="blue">
				The inverse of \(A = \begin{bmatrix} a & b \\ c & d \end{bmatrix}\) is

				\[A^{-1} = \frac{1}{\det A} \begin{bmatrix} d & -b \\ -c & a \end{bmatrix}\]
				(a particular case of a general result)
			</p>

			<h2 id="mat-2">Matrix Inverse, Linear Equations</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part2/note9.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				A system of linear equations can be written in matrix form.

				\begin{align}
				ax_1 + bx_2 &= y_1 \\
				cx_1 + dx_2 &= y_2 
				\end{align}

				\[
				\equiv \begin{bmatrix} a & b \\ c & d \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} = \begin{bmatrix} y_1 \\ y_2 \end{bmatrix}.
				\]

				Which can be extrapolated to general form.
			</p>

			<div class="blue">
				<p>
				The following operations can be performed to solve a system (<b>Gaussian Elimination</b>):
			</p>

			<ul>
				<li>Swap two rows (equations)</li>
				<li>Multiply a row (both sides of an eqn) by a nonzero number</li>
				<li>Add a multiple of one row (eqn) to another</li>
			</ul>
			</div>
			

			<p>
				Which can be done over the <i>augmented matrix</i>, which is gotten by combining \(\begin{bmatrix} a & b \\ c & d \end{bmatrix}\) and \(\begin{bmatrix} y_1 \\ y_2 \end{bmatrix}\) (the coefficients and the result).

				\[
				\left[\begin{array}{cc|c} a & b & y_1 \\ c & d & y_2 \end{array}\right]
				\]
			</p>

			<p>
				Two matrices \(A, B\) are <b>row equivalent</b> if we can use row operations to get from A to B. Denoted \(A \sim B\).
			</p>

			<p class="blue">
				A matrix is in <b>row echelon form</b> if the first nonzero entry in each row is further to the right of said entry in the previous row. By reducing to row echelon form we can solve a system of linear equations. 
			</p>

			<p>
				See the pdf for sample problems. <i>Note: there also exists <b>reduced row echelon form</b>, where each leading entry is a 1, and each column with a 1 in has 0s for all other entries.</i>
			</p>

			<p>
				Elementary row ops can be done by multiplying by so-called <i>elementary matrices</i>. These are defined for (\E_{n \times n}\):
			</p>

			<ul>
				<li>\(E_{ij}\) obtained from \(I\) by exchanging rows \(i, j\)</li>
				<li>For \(\lambda \neq 0, \; E_i(\lambda)\) obtained from \(I\) by multiplying row \(i\) by \(\lambda\)</li>
				<li>\(E_{ij}(\mu)\) obtained from \(I\) by adding \(\mu \cdot\) row \(j\) to row \(i\)</li>
			</ul>

			<p>
				Every elementary matrix is invertible.
			</p>

			<p class="blue">
				If a sequence of row operations transforms a square matrix \(A\) into \(I\). then \(A^{-1}\) exists and the same sequence transforms \(I\) into \(A\).
			</p>

			<p>
				This is best done with an augmented matix, like
				\[
				\left[\begin{array}{cc|cc} a & b & 1 & 0 \\ c & d & 0 & 1 \end{array}\right]
				\]
			</p>

			<h2 id="mat-3">Matrix Inverse, Determinants</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part2/note10.pdf" class="text">Link to first PDF.</a> <br>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part2/note11.pdf" class="text">Link to second PDF.</a>
			</p>

			<p>
				The determinant of a \(3 \times 3\) matrix is denoted the same way, and is defined

				\[
				\begin{vmatrix}
				a_{11} & a_{12} & a_{13} \\ a_{21} & a_{22} & a_{23} \\ a_{31} & a_{32} & a_{33}
				\end{vmatrix} =

				a_{11} \begin{vmatrix} a_{22} & a_{23} \\ a_{32} & a_{33}\end{vmatrix}
				- a_{12} \begin{vmatrix}a_{21} & a_{23} \\ a_{31} & a_{33}\end{vmatrix}
				+ a_{32} \begin{vmatrix}a_{21} & a_{22} \\ a_{31} & a_{32}\end{vmatrix}

				\]

				i.e. all elements on the first row multiplied (respecting +/- grid) with the determinant of the minor matrix (the cofactor) - the matrix gotten by deleting the row and column with said element. 
			</p>

			<p>
				\[\begin{bmatrix}+&-&+\\-&+&-\\+&-&+\end{bmatrix}\]
			</p>

			<p>
				This can be done with any row or column.
			</p>

			<div class="blue">
				<p>
					On elementary row operations and determinants (\(B\) obtained from \(A\)):
				</p>
				<ol>
					<li>Multiplying a row in A by a \(\lambda\): \(|B| = \lambda|A|\)</li>
					<li>Swapping 2 rows of A: \(|B| = -|A|\)</li>
					<li>Adding a multiple of one row to another: \(|B| = |A|\)</li>
				</ol>
			</div>

			<p></p>
			<div class="blue">
				<p>
					A square matrix is inversible <i>iff</i> its determinant is not 0. If \(A\) is invertible,
				\[A^{-1} = \frac{1}{|A|} \textrm{adj}(A)\]
					where \(\textrm{adj}(A)\) is the <b>transposed matrix of cofactors</b>.
				</p>
				
			</div>

			<p>
				You can also use matrix inverses to calculate equations:
				\begin{align}
				\textrm{if } &A\vec{x} = \vec{y}\\
				\textrm{then } &A^{-1} A \vec{x} = A^{-1} \vec{y} \implies \vec{x} = A^{-1}\vec{y}
				\end{align}
				Where the column vector x are the variables, and column vector y are the values of the equations. 
			</p>

			<p class="blue">
				<b><i>Linear independence via determinants.</i></b> A set of \(n\) vectors in \(\mathbb{R}^n\) is linearly independent <i>if and only if</i> it is the set of column vectors of a matrix with nonzero determinant.
			</p>

			<p>
				Basically, bang \(n\)  \(\mathbb{R}^n\) vectors into a square matrix, compute the determinant, and if it is 0, then those vectors are linearly dependent.
			</p>

			<h2 class="mat-4">Linear Transformations</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part2/note12.pdf" class="text">Link to the PDF.</a>
			</p>

			<div class="blue">
				<p>
					A function \(T : \textrm{R}^m \longrightarrow \mathbb{R}^n\) is a <b>linear transformation</b> if, \(\forall \vec{u}, \vec{v} \in \mathbb{R}^n, \lambda \in \mathbb{R}\), we have:

					\[ T(\vec{u} + \vec{v}) = T(\vec{u}) + T(\vec{v}), \]
					\[ T(\lambda \vec{u}) = \lambda T(\vec{u}). \]

					Which are preservation of addition and scaling respectively. Also,	
				</p>

				<p>
					\[T(\vec{0}) = \vec{0}.\]
				</p>
			</div>

			<p>
				For simple problems, verifying that the transformation fits the two rules of addition and scaling is sufficient.
			</p>

			<div class="side">
				<p>
					<b><i>Example.</i></b> Let \(\vec{u}\) be a nonzero 2D vector. If \(\vec{x} \in \mathbb{R}^2\) then we define the <b>projection</b> of \(\vec{x}\) onto \(\vec{u}\) to be a vector \(P_{\vec{u}}(\vec{x})\) such that
				</p>
				<ol>
					<li>\(P_{\vec{u}}(\vec{x})\) is a multiple of \(\vec{u}\)</li>
					<li>\(\vec{x} - P_{\vec{u}}(\vec{x})\) is perpendicular to \(\vec{u}\).</li>
				</ol>
				<p>
					We have by (1) that \(P_{\vec{u}}(\vec{x}) = \alpha \vec{u}\) for some \(\alpha \in \mathbb{R}\), so by (2)
					\[0 = (\vec{x} - P_{\vec{u}}(\vec{x})) \cdot \vec{u} = (\vec{x} - \alpha \vec{u}) \cdot \vec{u} = \vec{x} \cdot \vec{u} - \alpha |\vec{u}|^2,\]
					\[\implies \alpha = \frac{\vec{x}\cdot\vec{u}}{|\vec{u}|^2}.\]
				</p>
				<p>
					The projection can then be regarded as a function \(P_\vec{u} : \mathbb{R}^2 \longrightarrow \mathbb{R}^2\) defined \(\forall \vec{x} \in \mathbb{R}^2\):
					\[P_{\vec{u}}(\vec{x}) = (\frac{\vec{x}\cdot\vec{u}}{|\vec{u}|^2})\vec{u}.\]
					This function can be verified to be a linear transformation.
				</p>
			</div>
			<p></p>
			<div class="side">
				<p>
					<b><i>Example.</i></b> For \(\theta \in [0, 2\pi)\) define \(R_\theta : \mathbb{R}^2 \longrightarrow \mathbb{R^2}\) to be a function describing rotation about angle \(\theta\) through origin. After a bit of derivation, we get

					\[R_\theta (x, y) = (x\cos\theta - y\sin\theta, x\sin\theta - y\cos\theta).\]

					Or alternatively in matrix form (let \((x', y')\) be \(R_\theta (x, y)\)) as

					\[
					\begin{bmatrix} x' \\ y' \end{bmatrix} = \begin{bmatrix}\ \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta \end{bmatrix} \begin{bmatrix} x \\y \end{bmatrix}.
					\]
				</p>
			</div>

			<h2 id="mat-5">Linear Transformations and Matrices</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part2/note13.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				Referring back to the last example in the last section, it is further true that <b>every</b> \(M_{m \times n}\) matrix can act as a linear transformation (\(T(\vec{x}) = M\vec{x}\)). Vectors are column vectors.
			</p>

			<p>
				For a basis \(V = \{\vec{v}_1, \vec{v}_2, ... \vec{v}_n\}\) of \(\mathbb{R}^n\), every \(\vec{x} \in \mathbb{R}^n\) has a linear expansion \(\vec{x} = a_1 \vec{v}_1 + a_2 \vec{v}_2 + ... + a_n \vec{v}_n\).
			</p>

			<p>
				These coefficients \(a_1 ... a_n\) are the <b>coordiates of \(x\) with respect to basis \(V\)</b>.
			</p>

			<p>
				Let \(T : \mathbb{R}^m \longrightarrow \mathbb{R}^n\) be a linear transformation, V be a basis in \(\mathbb{R}^m\) and W a basis in \(\mathbb{R}^n\).
			</p>

			<p>
				For each vector \(\vec{v}\) in V \(T(\vec{v})\) has an expansion in W. The <b>Matrix of a linear transformation</b> T with respect to V and W is the \(m \times n\) matrix where each column \(i\) contains the coefficients of the expansion of \(T(\vec{v}_i)\) for each \(\vec{v}_i \in V\).
			</p>

			<p>
				When \(m = n, \; W = V\) then it is referred to as the <b>matrix of T with respect to basis V</b>.
			</p>

			
			<div class="blue">
				<p>
					<b><i>Matrix of a linear transformation.</i></b> For a linear transformation T (as above), M the matrix of T with respect to bases V, W (as above); the columns of M contain the coordinates of the <i>images</i> of the basis vectors in V w/ respect to W. 
				</p>

				<p>
					If \(\vec{x} \in \mathbb{R}^m\) has coordinates \([x_1,...,x_n]\) with respect to V then the coordinates with respect to W, \([y_1, ... , y_n]\) are
					\[\begin{bmatrix} y_1 \\ \vdots \\ y_n \end{bmatrix} = M \begin{bmatrix} x_1 \\ \vdots \\ x_n \end{bmatrix}.\]
				</p>
			</div>

			<p>
				A matrix that changes between two different bases in \(\mathbb{R}^n\) is called a <b>transition matrix</b>.
			</p>

			<p>
				The definition on the notes is uh, <!-- fuck awful --> just do the same thing as above but the matrix will be square.
			</p>

			<h2 id="mat-6">Eigenvalues and Eigenvectors</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part2/note14.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				Relating to matrices multiplying vectors, and especially where the vectors don't change direction. 
			</p>

			<p class="blue">
				For a matrix A and a vector \(\vec{r}\), if \(A\vec{r} = \lambda \vec{r}, \; \lambda \in \mathbb{R}\), then \(\vec{r}\) is the <b>eigenvector</b> and \(\lambda\) is the <b>eigenvalue</b>.
			</p>

			<p class="blue">
				A number \(\lambda\) is an eigenvalue of A if and only if it satisfies the <b>characteristic equation</b>
				\[|A - \lambda I| = 0.\]
			</p>

			<p>
				For an order \(n\) matrix there are \(n\) (not necessarily unique) eigenvalues. Eigenvalues can also be \(\in \mathbb{C}\).
			</p>

			<p>
				Recall that diagonal matrices are written \(\textrm{diag}[a_{11}, a_{22}, ..., a_{nn}]\).
			</p>

			<div class="blue">
				<p>
					<b><i>Diagonalisation of Matrices.</i></b> For an order \(n\) matrix A:
					\[A = UDU^{-1}\]
					Where \(D = \textrm{diag}[\lambda_1, \lambda_2, ..., \lambda_n]\) (the eigen values), and
					\(U = [\vec{v}_1, \vec{v}_2, \dots, \vec{v}_n]\) are the <i>corresponding</i> eignvectors of said eigenvalues.
				</p>

				<p>
					Note that if you have repeated eigenvalues, you have to find multiple <i>distinct</i> (lin. indep.) eigenvectors for that eigenvalue.
				</p>
			</div>
		</div>

		<div class="colourband" id="sequences">
			<h2>Sequences and Series</h2>
		</div>

		<div class="cbox">
			<h2>Introduction</h2>

			<ol>
				<a href="#seq-1">Sequences</a>
				<a href="#seq-3">Series</a>
				<a href="#seq-2">Recurrences</a>
			</ol>

			<p class="small">
				By the way, did I ever mention I hate sequences and series?
			</p>

			<h2 id="seq-1">Sequences</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part3/note15.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				A sequence \((a_n)\) is an infinite list of numbers \((a_0, a_1,...)\). We can define sequences through <i>n<sup>th</sup> term</i> rules or <i>recursively</i>.
			</p>

			<div class="blue">
				<p>
					<b><i>Convergent Sequence.</i></b> A sequence \(a_n\) is said to <b>converge </b>to a <b>limit</b> \(l \in \mathbb{R}\) if for every small \(\epsilon > 0\) there is a related integer \(N\) such that \(|a_n - l| < \epsilon \; \forall n > N\). This is denoted as
					\begin{align}
					&\lim_{n \rightarrow \infty} a_n = l; &a_n \rightarrow l.
					\end{align}
				</p>
				
			</div>

			<p>
				In layman's terms, if a sequence converges, then for every (increasingly small) positive number, the difference between the sequence's terms and the limit will be eventually smaller.
			</p>
			<p>
				\(N\) here is like a <i>threshold indicator</i>, where every term of the sequence after \(N\) will be within the \(\epsilon\) difference.
			</p>
			<p>
				We generally worth with \(n \in \mathbb{N}\).
			</p>			

			<div class="side">
				<p>
					<b><i>Example.</i></b> The sequence \(a_n = \frac{1}{n}\) converges to 0. We can prove this by going to the definition - let us have a small \(\epsilon > 0\). 
				</p>
				<p>
					Then \(\exists N : a_N - 0 < \epsilon\), or \(\frac{1}{N} < \epsilon\). We can choose any integer \(N > \frac{1}{e}\), to demonstrate that this is possible for any \(\epsilon\). For any \(n > N\):

					\[|\frac{1}{n} - 0| = \frac{1}{n} < \frac{1}{N} < \epsilon,\]

					to write it out as an equation.
				</p>
			</div>

			<p>
				If possible, try break a large sequence down into simpler components. They can be combined using the following:
			</p>

			<div class="blue">
				<p>
					<b><i>Combination Rules for Convergent Sequences.</i></b> For convergent sequences \(a_n \rightarrow \alpha, b+n \rightarrow \beta, c_n \rightarrow \gamma\):
				</p>

				<ol>
					<li><b>Sum</b> rule: \(a_n + b_n \rightarrow \alpha + \beta\)</li>
					<li><b>Scalar multiple</b> rule: \(\lambda a_n \rightarrow \lambda\alpha, \; \lambda \in \mathbb{R}\)</li> 
					<li><b>Product</b> rule: \(a_n b_n \rightarrow \alpha\beta\)</li>
					<li><b>Reciprocal</b> rule: \(\frac{1}{a_n} \rightarrow \frac{1}{\alpha}\)</li>
					<li><b>Quotient</b> rule: \(\frac{b_n}{a_n} \rightarrow \frac{\beta}{\alpha}\)</li>
					<li><b><i>Hybrid</i></b> rule: \(\frac{b_n c_n}{a_n} \rightarrow \frac{\beta\gamma}{\alpha}\)</li>
				</ol>

			</div>
			<p></p>
			<button class="collapsible">Problem...</button>
			<div class="ccontent">
				<p>
					<b><i>Problem.</i></b> Show that the following sequence converges, find its limit:
					\[ a_n = \frac{(n+2)(2n-1)}{3n^2 + 1} \]
				</p>
			</div>
			<p></p>
			<button class="collapsible">Answer...</button>
			<div class="ccontent">
				<p>
					The components do not converge themselves, a technique here is <i>dividing by the fastest increasing term</i>. Dividing by \(n^2\),

					\[ a_n = \frac{\frac{(n+2)}{n}\frac{(2n-1)}{n}}{\frac{3n^2 +1}{n^2}} = \frac{(1 + \frac{2}{n})(2 - \frac{1}{n})}{3 + \frac{1}{n^2}}. \]
				</p>
				<p>
					Now the components \(\frac{1}{n}\) and \(\frac{1}{n^2}\) converge to 0, so applying combination rules we can get

					\[a_n \rightarrow \frac{(1+0)(2-0)}{3+0} = \frac{2}{3}. \]
				</p>
			</div>

			<p>
				A sequence \(a_n\) is <b>bounded above</b> if there is a number \(U : a_n \leq U \forall n\). \(a_n\) is <b>bounded below</b> if there is a number \(L : L \leq a_n \forall n\). A sequence is <b>bounded</b> if it is bounded both above and below.
			</p>

			<p>
				A <b>subsequence</b> of a sequence is obtained from the original sequence by deleting some terms. We can say \(a_{2n}, a_{2n+1}\) are the even and odd subsequences respectively of \(a_n\).
			</p>

			<p>
				A sequence \(a_n\) is an <b>increasing</b> sequence if \(a_{n+1} \geq a_n \;\forall n\). It is  a <b>decreasing</b> sequence if \(a_{n+1} \leq a_n \;\forall n\). 
			</p>

			<div class="blue">
				<p><b><i>Basic Properties of Convergent Sequences.</i></b></p>

				<ol>
					<li>A convergent sequence has a <i>unique</i> limit.</li>
					<li>If \(a_n \rightarrow l\) then <i>every subsequence</i> of \(a_n\) also converges to \(l\).</li>
					<li>If \(a_n \rightarrow l\) then \(|a_n| \rightarrow |l|\).</li>
					<li><b>The squeeze rule.</b> If \(a_n \rightarrow l, b_n \rightarrow l; a_n < c_n < b_n \; \forall n\) then \(c_n \rightarrow l\).<sup>1</sup></li>
					<li>A convergent sequence is always bounded.<sup>2</sup></li>
					<li>An increasing sequence which is bounded above converges. A decreasing sequence which is bounded below converges.</li>
				</ol>

				<p class="small">
					<sup>1</sup>The sequence \(c_n\) is "squeezed" between two sequences which both converge to the same limit, so naturally it will too.<br>
					<sup>2</sup>\(\exists B > 0 : - B \leq a_n \leq B, \; \forall n\).
				</p>
			</div>

			<p>
				You can demonstrate an alternating sequence (e.g. \((-1)^n\)) doesn't converge by looking at <i>subsequences</i>.
			</p>

			<p>
				Reminder: the binomial theorem is
				\[(1 + x)^n = 1 + nx + \frac{n(n-1)}{2!}x^2 + ... + \frac{n!}{k!(n-k)!}x^k\]
			</p>

			<button class="collapsible">Problem...</button>
			<div class="ccontent">
				<p>
					<b><i>Problem.</i></b> Show that for \(x \geq 0, n > 0\), this: \((1+x)^{\frac{1}{n}} \leq 1 + \frac{x}{n}\).
				</p>

				<p>
					Hence deduce/show that if \(c > 0\) then \(c^\frac{1}{n} \rightarrow 1\).
				</p>
			</div>
			<p></p>
			<button class="collapsible">Answer...</button>
			<div class="ccontent">
				<p>
					<b><i>Answer.</i></b> Firstly, we can rearrange and use the binomial theorem.
					\begin{align}
					1 + x &\leq (1 + \frac{x}{n})^n. \\
					(1 + \frac{x}{n})^n &= 1 + n\frac{x}{n} + \textrm{ (other positive terms) via binomial exp, so} \\
					1 + x &\leq 1 + x + \textrm{ (other positive terms)} \\
					\end{align}
					Thus if we take \(n^\textrm{th}\) roots of each side we will demonstrate that
					\[(1+x)^\frac{1}{n} \leq 1 + \frac{x}{n}.\]
				</p>
				<p>
					For the second part, we need to consider separately the cases \(c \geq 1\) and \(c < 1\).
				</p>
				<p>
					If \(c \geq 1\) then \(c^\frac{1}{n} \geq 1\). If we use the inequality we demonstrated in the first part, letting \(x = c-1 \geq 0\) we get
					\[1 \leq c^\frac{1}{n} \leq 1 + \frac{c-1}{n}.\]
				</p>
				<p>
					By the squeeze rule, we can (in an ideal world) see that \(c^\frac{1}{n} \rightarrow 1\). 
				</p>
				<p>
					Finally if \(c < 1\) then \(\frac{1}{c} > 1\) and by the reciprocal rule \(\frac{1}{c^\frac{1}{n}} \rightarrow 1\).
				</p>
				<p class="small">
					Did you get that? Me neither.
				</p>
			</div>

			<p>
				<b><i>Divergent Sequence.</i></b> A squence \(a_n\) is said to <b>diverge to infinity</b> if \(\forall K \in \mathbb{R}\; \exists N : n > N \implies a_n > K\). 
			</p>

			<p>
				In plain english, there is a point in \(a_n\) where the terms are greater than any real number one picks.
			</p>

			<p>
				We denote this as \(a_n \rightarrow \infty\). \(a_n\) diverges to \(-\infty\) if \(-a_n \rightarrow \infty\). 
			</p>

			<p>
				A divergent sequence that doesn't go off to infinity is said to <b>oscillate</b>.
			</p>

			<div class="blue">
				<p>
					<b><i>Basic convergent sequences.</i></b>
					\begin{align}
					& \lim_{n \rightarrow \infty} \frac{1}{n^p} = 0 & \forall p > 0 \\
					& \lim_{n \rightarrow \infty} c^n = 0 & \forall c : |c| < 1 \\
					& \lim_{n \rightarrow \infty} c^\frac{1}{n} = 1 & \forall c > 0 \\
					& \lim_{n \rightarrow \infty} n^p c^n = 0 & \forall p > 0 \land |c| < 1 \\
					& \lim_{n \rightarrow \infty} \frac{c^n}{n!} = 0 & \forall c \in \mathbb{R} \\
					& \lim_{n \rightarrow \infty} (1 + \frac{c}{n})^n = e^c & \forall c \in \mathbb{R}
					\end{align}
				</p>
				
			</div>

			

			<h2 id="seq-3">Series</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part3/note17.pdf" class="text">Link to the PDF.</a>
			</p>

			<button class="collapsible">Addendum: Partial Fractions</button>
			<div class="ccontent">
				<p>
					Partial fractions can be important in series.
				</p>
				<p>
					Where a rational function is decomposed into a sum of simpler fractions, such as
					\[\frac{cx+d}{(x-a)(x-b)} = \frac{A}{x-a} + \frac{B}{x-b}.\]
				</p>
				<p>
					When there is no repeated factor, simply substituting \(x = a, x=b\) can eliminate a term and make it easy to find the unknowns \(A, B\). When there is however, we need to just pick values of \(x\) and solve from there.
				</p>
				<p>
					If there is a repeated factor \((x-a)^n\), the partial sum will have all the fractions with denominations \((x-a), (x-a)^2,...\) up to \((x-a)^n\)
				</p>
				<p>
					If the degree of the numerator is higher than the denominator, then we have to divide out the numerator (polynomial long division) to get a valid separable fraction,
					\[\frac{x^3 + 3x}{(x+1)(x-3)} = x+2 + \frac{10x+6}{(x+1)(x-3)}.\]
				</p>
			</div>

			<p>
				A series \(\sum a_n\) is a pair of sequences:
			</p>
			<ol>
				<li>A sequence \(a_n\) called the <b>sequence of terms</b></li>
				<li>A sequence \(s_n\) called the <b>sequence of partial sums</b> defined as
				\[s_n = \sum_{k=0}^{n} a_k.\]</li>
			</ol>

			<p>
				If the sequence of partial sums converges to \(s\), then the series converges to the sum \(s\);
				\[\sum_{n=0}^{\infty} a_n = s.\]
				Divergent if not. 
			</p>

			<p>
				A standard one is the geometric series, \(\sum r^n\) which will always converge to \(\frac{1}{1-r}\) when \(|r| < 1\). You can prove this by working out \(rs_n - s_n\).

				\begin{align}
				s_n - rs_n = 1 - r^{n+1} &\Longleftrightarrow s_n(1-r) = 1 - r^{n+1}\\
				&\Longleftrightarrow s_n = \frac{1 - r^{n+1}}{1-r}.
				\end{align}
				And \(|r| < 1\) means that \(r\)-power will converge to 0.
			</p>

			<p>
				A standard divergent series is the harmonic series, \(\sum \frac{1}{n}\). You can prove this by estimating partial sums \(s_2, s_4, s_8, s_{16}, ...\) and see that it will forever build to \(1 + 0.5 + 0.5 + 0.5 + ...\).
				\[s_{2^n} > 1 + \frac{n}{2}.\]
			</p>

			<div class="blue">
				<p><b><i>Basic Properties of Convergent Series.</i></b></p>
				<ol>
					<li><b>Sum rule</b>, \(\sum a_n\) converges to \(s,\; \sum b_n\) converges to \(t \implies \sum (a_n + b_n)\) converges to \(s + t\).</li>
					<li><b>Multiple rule</b>, \(\sum a_n\) converges to \(s, \; \lambda \in \mathbb{R} \implies \sum \lambda a_n\) converges to \(\lambda s\).</li>
					<li>\(\sum a_n\) converges \(\implies a_n \rightarrow 0\).</li>
					<li>\(\sum |a_n|\) converges \(\implies \sum a_n\) also converges.</li>
				</ol>
			</div>




			<h2 id="seq-2">Recurrences</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part3/note16.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				<i>Like the differential equations of sequences.</i>
			</p>

			<p>
				A recurrence is a sequence defined, funnily enough, recursively.
			</p>
			<p>
				For example, the fibonacci sequence \(F_n\) is defined as
				\[F_n = F_{n-1} + F_{n-2}\]
				\[F_0 = 0, F_1 = 1.\]
			</p>
			<p>
				The <i>Towers of Hanoi</i> game's number of steps taken was computed to be the recurrence
				\[T_n = 2T_{n-1} + 1.\]
				For \(T_0 = 0\) this gives \(0, 1, 3, 7, 15, ...\) which we can see is \(T_n = 2^n - 1\). This latter form is the <b>closed form</b> of \(T_n\) and allows for immediate computation.
			</p>

			<p>
				We are looking at solving linear recurrences with constant coefficients, of the form
				\[x_n + a_1x_{n-1} + ... a_kx_{n-k} = f(n)\]
				where \(f\) is a given function. (If the terms from 1 to k are given, then this describes a unique sequence.)
			</p>
			<p>
				More importantly, we will look at <b>homogenous</b> (\(f(n) = 0\)) recurrences with \(k = 2\). Thus, we want the general solution of
				\[x_n + ax_{n-1} + bx_{n-2} =0.\]

			</p>
			<p>
				In the general case, we want to look for solutions of the form \(A\lambda^n\) where \(\lambda, A\) are constants. A bit of deriving later, we can get the auxillary equation in lambda.
			</p>
			<p class="blue">
				The <b>auxillary equation</b> of the recurrence \(x_n + ax_{n-1} + bx_{n-2} = 0\) is
				\[\lambda^2 + a\lambda + b = 0.\]
			</p>

			<div class="blue">
				<p>
					<b><i>General Solution.</i></b> of the recurrence \(x_n + ax_{n-1} + bx_{n-2} = 0\),
				</p>
				<p>
					Let \(\lambda_1, \lambda_2\) be the roots of the auxillary equation.
				</p>
				<ul>
					<li>\(\lambda_1 \neq \lambda 2 \implies x_n = A\lambda_1^n + B\lambda_2^n\)</li>
					<li>\(\lambda_1 = \lambda_2 \implies x_n = A\lambda_1^n + Bn\lambda_2^n\)</li>
				</ul>
				<p>
					For constants \(A, B\), which can be found if the first two terms of the sequence are known.
				</p>
			</div>
			<p></p>
			<button class="collapsible">Problem...</button>
			<div class="ccontent">
				<p>
					<b><i>Problem.</i></b> Find a closed form for the fibonacci sequence.
				</p>
			</div>
			<p></p>
			<button class="collapsible">Answer...</button>
			<div class="ccontent">
				<p>
					<b><i>Answer.</i></b> We have \(F_n = F_{n-1} + F_{n-2}\) so \(F_n - F_{n-1} - F_{n-2} = 0\). The auxillary equation is
					\[\lambda^2 - \lambda - 1 = 0\]
					Which has roots
					\[\lambda = \frac{1 \pm \sqrt{5}}{2}\]
					Or \(\phi\) and \(-(\frac{1}{\phi})\) (the golden ratio phi). Hence
					\[F_n = A(\frac{1 + \sqrt{5}}{2}) + B(\frac{1 - \sqrt{5}}{2}).\]
					We know \(F_0 = 0, F_1 = 1\) so if we substitue these values in, we get that \(A = \frac{1}{\sqrt{5}}, B = -\frac{1}{\sqrt{5}}\).

					\begin{align}
					F_n &= \frac{1}{\sqrt{5}}(\frac{1 + \sqrt{5}}{2}) -\frac{1}{\sqrt{5}}(\frac{1 - \sqrt{5}}{2}). \\
					&= \frac{1}{\sqrt{5}}(\phi^n + \phi^{-n}).
					\end{align}
				</p>
				<p>
					Actually by some magic we can further simplify down to
					\[F_n = \left \lfloor{\frac{\phi^n}{\sqrt{5}}}\right \rfloor\]
				</p>
			</div>

			<p>
				Non-homogenous recurrences have the \(f(n)\) bit not 0. 
			</p>

			<div class="blue">
				<p><b><i>Finding solutions to non-homogenous recurrences.</i></b> of form \(x_n + ax_{n-1} + bx_{n-2} = f(n)\)</p>
				<ol>
					<li>
						Find the general solution \(x_n = h_n\) of the homogenous recurrence:
						\[x_n + ax_{n-1} + bx_{n-2} = 0.\]
						(will have 2 arbitrary constants)
					</li>
					<li>
						Find <i>any</i> particular solution \(x_n = p_n\) of the original recurrence. 
					</li>
					<li>
						The general solution will be \(x_n = h_n + p_n\).
					</li>
				</ol>
			</div>

			<p>
				Finding the particular solution \(p_n\) is not straight forward, but the technique is to try solutions that are <i>similar in form</i> to \(f(n)\). Substitue these into the original recurrence (as they are solutions!) and try solve. 
			</p>

			<p>
				If \(f(n)\) is a constant, try find a constant \(k\).
			</p>
			<p>
				If \(f(n)\) is a polynomial, try find a <i>same degree</i> polynomial. (substitute in a general polynomial)
			</p>
			<p>
				Etc. just like diff. eqns. 
			</p>
		</div>
		

		<footer>
			<div class="cbox">
				<div class="columncontainer ctwo">
					<div>
						<p class="small">
							© 2020-2021 Yijun Hu, all rights reserved.
						</p>
					</div>
					<div>
						<p class="small rj">
							Designed by Yijun Hu
						</p>
					</div>
				</div>
			</div>
		</footer>

	</div>

	<script type="text/javascript" src="../../js/collapsible.js"></script>  <!--This stays at the end-->
	<script type="text/javascript" src="../../js/toggle-darklight.js"></script>
	<!--<script type="text/javascript" src="../../js/prism.js"></script>-->
</body>
</html>