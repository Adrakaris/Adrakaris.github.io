<!DOCTYPE html>
<html>
<head>
	<title>CS131</title>
	<meta charset="utf-8">
	<link rel="stylesheet" type="text/css" href="../../style/style.css" media="all" id="theme-link">  <!--TODO: CHANGE HREF-->
	<!--<link rel="stylesheet" type="text/css" href="../../style/prism.css" media="all">-->
	<meta name="viewport" content="width=device-width" initial-scale=1.0>  <!--TODO: CHANGE LINKS ON BOTTOM OF SHEET FOR COLLAPSIBLE-->
	<link rel="icon" type="image/png" href="../../style/images/DragonIcon.png">
	<script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>

	<div class="hidden">
		<header>
			<div class="parallax parsmaller">
				<div  style="display: grid; grid-template-columns: 1fr 1fr 1fr 9fr 1fr; grid-column-gap: 10px; padding: 5px; ">
					<div class="column tinycolumn">
                        <a href="../../index.html" class="nav">Home</a>
                    </div>
                    <div class="column tinycolumn">
                        <a href="../../blog.html" class="nav">Back</a>
                    </div>
                    <div class="column tinycolumn">
                        <a href="../../about.html" class="nav">About</a>
                    </div>
					<div></div>
					<div class="column">
						<button class="nav dark-light">Dark Mode</button>
					</div>
				</div>
				<div class="cbox"> 		
					<h1>CS131</h1>
					<p class="subheading">Mathematics For Computer Scientists 2</p>
				</div>
			</div>
		</header>

		<header>
			<div class="cbox">
				<h1>Contents</h1>
			</div>
		</header>

		<div class="cbox">
			<ol>
				<li><a href="#zrc">Number Systems</a></li>
				<li><a href="#vec">Vectors</a></li>
				<li><a href="#matrices">Matrices</a></li>
				<li><a href="#sequences">Sequences and Series</a></li>
				<li><a href="#calculus">Calculus</a></li>
			</ol>

			<p>
				Yulia has already provided very comprehensive notes on all topics of 131, so these will summarise those and only include the most important points. Said notes are linked to when required (you will need an ITS account). 
			</p>
		</div>


		<div class="colourband" id="zrc">
			<h2>Number Systems</h2>
		</div>

		<div class="cbox">
			<h2>Introduction</h2>
			<ol>
				<li><a href="#zrc-1">Integers</a></li>
				<li><a href="#zrc-2">Reals</a></li>
				<li><a href="#zrc-3">Complex Numbers</a></li>
			</ol>

			<h2 id="zrc-1">Integers</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part1/note1.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				Integers, denoted \(\mathbb{Z}\). We use a denary/decimal (base-10) system with 10 digits, but there is also binary, which uses 2 digits.
			</p>

			<p>
				Subscripts are used to denote base; \(10011_{\textrm{two}} = 19_{\textrm{ten}}\) or \(10011_{2} = 19_{10}\).
			</p>

			<p class="side">
				<b><i>Decimal to Binary Conversion Alg.</i></b> Divide decimal number repeatedly by 2 to get remainders \(r_0, r_1, r_2,...r_n\). The binary representation is \(r_{n}r_{n-1}...r_{1}r_0\) (note the switched order).
			</p>

			<button class="collapsible">Problems...</button>
			<div class="ccontent">
				<p>
					<b><i>Q.</i></b> Convert \(244_{10}\) to binary.
				</p>

				<p>
					<b><i>Q.</i></b> The <i>hexadecimal</i> system is base 16, with digits 0123456789ABCDEF. Convert \(21BAD_{16}\) to decimal.
				</p>
			</div>


			<p class="side">
				<b><i>Generic Base Conversion Alg.</i></b> Let us have an integer \(b\). To convert a base 10 integer to a base \(b\) integer, divide repeatedly by \(b\) to get remainders \(r_0, r_1,...r_n\), thus the base \(b\) representation would be \(r_{n}r_{n-1}...r_{1}r_0\) (note the switched order).
			</p>

			<p class="side">
				<b><i>Division Algorithm.</i></b> If \(a, b \in \mathbb{Z}\) with \(b \neq 0\), then there exist unique \(q, r \in \mathbb{Z}\) with
				\begin{align}
				&a = qb + r, &0 \leq r < |b|
				\end{align}
				Where \(q\) is the <b>quotient</b> and \(r\) the <b>remainder</b>.
			</p>

			<p>
				If \(0 < b < a\) then an algorithm to compute \(q, r\) would be to iteratively compute \(a - b, a - 2b, ..., a-nb, a - (n-1)b\) where \(a - (n-1)b < 0\) is the first strictly negative number. Then \(q = n, r = a-nb\).
			</p>

			<p>
				If \(a = qb\) (all integers) then \(b\) <i>divides</i> \(a\). The greatest common denominator is denoted \(\gcd(a, b)\).
			</p>

			<p>
				\(\gcd(0, n) = n \; \forall n \in \mathbb{Z}^+\)
			</p>

			<div class="blue">
				<p>
					<b><i>EUCLIDEAN ALGORITHM.</i></b> Let \(r_1, r_0\) be integers s.t. \(0 < r_1 < r_0\).
				</p>

				<ol>
					<li>
						For each \(i\), define \(r_{i+1}\) as the remainder of \(\frac{r_{i-1}}{r_i}\). <br>The <b>last</b> non-zero remainder \(r_N = \gcd(r_1, r_0)\).
					</li>
					<br>
					<li>

						\(r_{i-1} = q_i r_i + r_{i+1} \; (1 \leq 1 \leq N\) can be used to write this last nonzero remainder, thus
						\[\gcd(r_1, r_0) = xr_1 + yr_0 \textrm{ for some integers } x, y.\]
					</li>
				</ol>
			</div>
			<br>
			<button class="collapsible">Problems...</button>
			<div class="ccontent">
				<p>
					<b><i>Q.</i></b> Find the greatest common divisor of 16579 and 30031, and determine integers \(x\) and \(y\) such that \(\gcd(16579, 30031) = x16579 + y30031\).

				</p>
			</div>

			<p>
				Of Modular Arithmetic, two integers \(a, b\) are congruent modulo \(n\) (another integer) if \(a-b = kn \; k \in \mathbb{Z}\), i.e. \(a = b + kn\). Written \(a \equiv b \mod n\) or \(a \stackrel{\mod{}}{\equiv} b\).
			</p>

			<p>
				Two congruencies with the same mod \(n\) can be added, subtracted, multiplied just like normal equations. 
			</p>

			<p>
				In a computer, for negative integers we use two's complement, see <a href="../cs132/index.html#datarep" class="text">here</a>.
			</p>

			<p>
				We are also working with a system modulo \(2^N\) where \(N\) is the number of bits. Thus the 32 bit limit of \([2^{31}, 2^{31} - 1]\) which is \(2^{32}\) integers.
			</p>

			<h2 id="zrc-2">Reals</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part1/note2.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				Reals are denoted \(\mathbb{R}\), and have a subset \(\mathbb{Q}\) which are numbers definable as \(\frac{m}{n}, \; m, n \in \mathbb{Z}, \; n \neq 0\). We can always pick rationals such that \(n \geq 1\) and \(\gcd(m, n) = 1\). Every nonzero rational has an inverse. 
			</p>

			<p>
				Reals which are the solutions of polynomial equations are called <b>algebraic</b>, an example would be \(\sqrt{2}\) (being the solution of \(x^2 = 2\)).
			</p>

			<p>
				Those which are not are called <b>transcendental</b>, such as \(\pi, e\).
			</p>

			<p>
				A real number can be thought of as a sequence of rational numbers, which converges to said real. e.g. \(\pi\) is the limit of \(3, 3.1, 3.14, 3.141, 3.1415...\)
			</p>

			<p>
				All properties of real numbers come from <b>13 axioms</b>, of which 1-8 are <b>algebraic</b> properties, and 9-12 are <b>order properties</b>.
			</p>

			<div class="blue">
				<p>
				For all \(x, y, z \in \mathbb{R}\):
			</p>

			<ol>
				<li><b>Commutativity</b>: \(x + y = y + x, \;  xy = yx\)</li>
				<li><b>Associativity</b>: \(x + (y + z) = (x + y) + z\) (same with multiplication)</li>
				<li>Multiply <b>distributes</b> over add: \(x(y + z) = xy + xz\)</li>
				<li><b>Additive Identity</b>: \(\exists 0 \in \mathbb{R }: x + 0 = x\)</li>
				<li><b>Multiplicative identity</b>: \(\exists 1 \in \mathbb{R} : x \cdot 1 = x\)</li>
				<li>Multiplicative and additive identites are <b>distinct</b>: \(1 \neq 0\)</li>
				<li>Every element has an <b>additive inverse</b>: \(\exists (-x) \in \mathbb{R}: x + (-x) = 0\)</li>
				<li>Every \(\neq 0\) element has a <b>mul. inverse</b>: \(x \neq 0 \implies \exists x^{-1} \in \mathbb{R} : x \cdot x^{-1} = 1\)</li>
				<li><b>Transitivity</b> of ordering: \(x < y \land y < z \implies x < z\)</li>
				<li><b>Trichotomy Law</b>: only <b>one</b> of \(x < y,\; x > y,\; x = y\)</li>
				<li><b>Order preserved</b> under add: \(x < y \implies x + z < y + z\)</li>
				<li><b>Order preserved</b> under mul: \(0 < z \land x < y \implies xz < yz\)</li>
				<li><b>Completeness</b>: <i>Every non-empty subset of \(\mathbb{R}\) that is bounded above has a least upper bound</i></li>
			</ol>
			</div>

			

			<p class="side">
				<b><i>Excersise.</i></b> Show that \(0 < 1 \).
			</p>
			<button class="collapsible">Answer...</button>
			<div class="ccontent">
				<p>
					We first need a lemma.
				</p>

				<p>
					<b><i>Lemma 1.</i></b> \(\forall x ,\; x^2 \geq 0\).
				</p>

				<p>
					<b><i>Proof of Lemma 1.</i></b> Consider the cases where \(x < 0\) and \(x \geq 0\).
				</p>

				<p>
					When \(x \geq 0\),
					\begin{align}
					x \geq 0 &\implies x^2 \geq 0 \cdot 0 \textrm{ by ax. 12}\\
					&\implies \geq 0.
					\end{align}
				</p>

				<p>
					When \(x < 0\), \(-x \geq 0\), so:
					\begin{align}
					x^2 = x \cdot x &= (-x)(-x) \\
					&\geq 0 \cdot 0 \textrm{ by prev case}\\
					&\geq 0. &\triangleright
					\end{align}
				</p>

				<p>
					Then, we can prove. <br>
					<b><i>Proof.</i></b>
					\begin{align}
					1^2 &\geq 0 \textrm{ by lemma}\\
					\implies 1 &\geq 0\\
					1 &\neq 0 \textrm{ by ax. 6 } \therefore 1 > 0.
					\end{align}
					$$\tag*{$\Box$}$$
				</p>
			</div>

			<p class="side">
				<b><i>Excersise.</i></b> Show that \(a > 0 \implies \frac{1}{a} > 0\).
			</p>
			<button class="collapsible">Answer...</button>
			<div class="ccontent">
				<p>
					<b><i>Proof.</i></b> Let \(a > 0\)
					\begin{align}
					\textrm{If } \frac{1}{a} &= 0 \\
					\implies 1 &= a(\frac{1}{a}) = a \cdot 0 = 0 \\
					&\textrm{which is a contradiction to ax. 6.}
					\end{align}

					\begin{align}
					\textrm{If } \frac{1}{a} &< 0 \\
					\implies a (\frac{1}{a}) &< a \cdot 0 \textrm{ by ax. 12} \\
					\implies 1 &= 0 \textrm{ which is a contradiction.}
					\end{align}

					By axiom 10 we get that \(\frac{1}{a} > 0\). $$\tag*{$\Box$}$$
				</p>
			</div>

			<p></p>
			<button class="collapsible">More Problems...</button>
			<div class="ccontent">
				<p>
					<b>Q.</b> Show if \(a, b > 0\) then \(a < b \Longleftrightarrow a^2 < b^2\). <i>Note: you have to prove both ways.</i>
				</p>

				<p>
					<b>Q.</b> Show if \(a < b \land c < 0 \implies ac > bc\).
				</p>
			</div>

			<p></p>

			<button class="collapsible">Intervals, n<sup>th</sup> roots and Modulus/Abs basics...</button>
			<div class="ccontent">
				<p>
					<b>Intervals</b> are ranges represented by brackets. \((a, b)\) ranges are called <b>open</b>, \([a, b), \; (a, b]\) are called <b>semi-open</b> or <b>semi-closed</b> and \([a, b]\) ranges are called <b>closed</b>. \(\infty\) is not a real number and cannot appear in closed ranges.
				</p>

				<p>
					Let \(n \in \mathbb{Z}^+\). For any \(a \in \mathbb{R}_{\geq 0}, \; \exists! x \geq 0\) with \(x^n = a\). This \(x\) is the <b>\(n^{th}\) root</b> of \(a\), \(a^{\frac{1}{n}}\). For any positive real \(a, b\) and \(n \in \mathbb{Z}^+\) we have

					\[a < b \Longleftrightarrow a^{\frac{1}{n}} < b^{\frac{1}{n}}\]

					There's also of course \(a^\frac{1}{2} \equiv \sqrt{a}\) and all that comes with it.
				</p>

				<p>
					The <b>Modulus or Absolute</b> of \(x\), \(|x|\) is basically \(x\) but without negatives. \(|x| = \sqrt{x^2} \; \forall x \in \mathbb{R}\).
				</p>
			</div>
			<p></p>

			<div class="blue">
				<p>
				There are 4 properties of modulus:
			</p>

			<ol>
				<li>\(-|x| \geq x \geq |x|\)</li>
				<li>\(|xy| = |x||y|\)</li>
				<li>\(|x + y| \geq |x|+|y|\)</li>
				<li>\(||x| - |y|| \leq |x - y|\)</li>
			</ol>
			</div>

			

			<p>
				For a set of real numbers \(S\)
			</p>

			<ul>
				<li>\(u\) is an <b>upper bound</b> of S if \(u \geq x \forall x \in S\)</li>
				<li>\(U\) is the <b>least upper bound (supremum)</b> of S if \(U\) is an UB of S and \(U \leq u \forall u\)</li>
				<li>\(l\) is a <b>lower bound</b> of S if \(l \leq x \forall x \in S\)</li>
				<li>\(L\) is the <b>greatest lower bound (infimum)</b> of S if \(L\) is a LB of S and \(L \geq l \forall l\)</li>
			</ul>

			<img src="bounds.svg" style="max-width: 100%; width: 600px">

			<p>
				The <i>completeness axiom</i> suggests that for every set which has a lower bound has a greatest lower bound. 
			</p>

			<div class="blue">
				<p>
					<b>Important consequences of the completeness axiom:</b>
				</p>

				<ul>
					<li><b>The ARCHIMEDIAN PROPERTY</b> of \(\mathbb{R}\): <br>if \(\epsilon \in \mathbb{R}; \epsilon > 0\) then \(\exists n \in \mathbb{Z}^+ : n\epsilon > 1\).</li> 
					<li>Between any two real numbers there are both rational and irrational numbers.</li>
					<li>Every real number can be represented by a (possibly infinite) decimal expansion.</li>
				</ul>
			</div>


			<h2 id="zrc-3">Complex Numbers</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part1/note3.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				In the set \(\mathbb{C}\), of the form \(a + ib\) where \(i^2 = \sqrt{-1}\). Often denoted \(z\).
			</p>

			<p>
				Representable by an ordered pair \(z = (a, b)\) where \(Re_z = a\) and \(Im_z = b\). Also represnetable as a point on a 2d plane, the <i>complex plane</i> or <i>argand diagram</i>.
			</p>

			<p>
				For \(a, b \in \mathbb{R}\) the <b>complex conjugate</b> of \(z = a + ib\) is \(\overline{z} = a - ib\) (overline). Effectively reflecting along x axis. 
			</p>

			<p>
				<b>Properties of complex conjugates (\(\forall z, w \in \mathbb{C}\)):</b>
			</p>

			<div class="columncontainer ctwo" style="grid-column-gap: 20px">
				<div>
					<ul>
						<li>\(\overline{z + w} = \overline{z} + \overline{w}\)</li>
				<li>\(\overline{zw} = \overline{z}\overline{w}\)</li>
				<li>\(\overline{(\frac{z}{w})} = \frac{\overline{z}}{\overline{w}}\)</li>
				<li>\(\overline{\overline{z}} = z\)</li>
					</ul>
				</div>
				<div>
					<ul>
						<li>\(z \in \mathbb{R} \Longleftrightarrow \overline{z} = z\)</li>
				<li>\(Re_z = \frac{z + \overline{z}}{2}\)</li>
				<li>\(Im_z = \frac{z - \overline{z}}{2i}\)</li>
					</ul>
				</div>
			</div>

			<div class="blue">
			<p>
				If \(x, y \in \mathbb{R}\) and \(x + iy \neq 0\) we can express \(x\) and \(y\) in polar coordinates,
				\begin{align}
				&x = r \cos(\theta) &y = r \sin(\theta)
				\end{align}
				\[\therefore x + iy = r(\cos(\theta) + i\sin(\theta).\]
				\begin{align}
				&r = \sqrt{x^2 + y^2} &\theta \textrm{ satisfies } \tan(\theta) = \frac{y}{x}.
				\end{align}

				\(\theta\) is the <b>argument</b>, with the <b>principal argument</b> being a \(\theta \in (-\pi, \pi]\).
			</p>

			<p>
				\(r\) is the <b>modulus</b>, often denoted \(|x + iy|\).
			</p>
			</div>
			
			<p>
				<b>Properties of modulus</b>, for all \(z, w \in \mathbb{C}\):
			</p>

			<div class="columncontainer ctwo" style="grid-column-gap: 20px">
				<div>
					<ul>
						<li>\(|z| = |\overline{z}|\)</li>
						<li>\(|z| = \sqrt{z\overline{z}}\)</li>
						<li>\(z\overline{z} = |z|^2\)</li>
					</ul>
				</div>
				<div>
					<ul>
						<li>\(|zw| = |z||w|\)</li>
						<li>\(|z + w| \leq |z| + |w|\), <i>(triangle inequality)</i></li>
						<li>\(||z| - |w|| \leq |z - w|\)</li>
					</ul>
				</div>
			</div>

			<p>
				Proof of the triangle inequality is omitted.
			</p>

			<p>
				You can multiply two complex numbers in polar form, \(r_{1} (\cos(\theta) + i\sin(\theta)) \cdot r_{2} (\cos(\phi) + i\sin(\phi)) = r_{1}r_{2}(\cos(\theta + \phi) + i\sin(\theta + \phi))\). 
			</p>

			<div class="blue">
				<p>
					<b><i>De Moivre's Theorem.</i></b> \(\forall n \in \mathbb{Z}\):
					\[(r(\cos{\theta} + i\sin \theta))^n = r^{n}(\cos{n\theta} + i\sin{n\theta}).\]
				</p>
			</div>

			<p class="side">
				<b><i>Q.</i></b> Find all complex numbers \(z : z^3 = 1\).
			</p>

			<p class="side">
				The <b><i>Fundamental Theorem of Algebra</i></b> (Gauss) states that an \(n\) degree polynomial must have \(n\) roots. 
			</p>

			<p class="side">
				<b><i>Other Notation.</i></b> The conjugate \(\overline{z}\) can also be written \(z*\). Sometimes (often in engineering) \(i\) is \(j\).
			</p>
			

		</div>

		<div class="colourband" id="vectors">
			
			<h2>Vectors</h2>
		</div>

		<div class="cbox">
			<h2>Introduction</h2>

			<ol>
				<li><a href="#vec-1">Basics</a></li>
				<li><a href="#vec-2">Linear Combinations and Subspaces</a></li>
				<li><a href="#vec-3">Linear Independence</a></li>
			</ol>

			<h2 id="vec-1">Basics</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part2/note4.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				Vectors in 2 and 3D are members of the sets \(\mathbb{R}^2\) and \(\mathbb{R^3}\) respectively. <i>(Note, thus ordered pairs)</i>
			</p>

			<p>
				Can be treated as coordinate points. 
			</p>

			<p>
				Denoted either with arrow (\(\vec{x}\)), underline (\(\underline{x}\)), or bold (\(\mathbfit{x}\)). I'll be using the arrow.
			</p>

			<p>
				Addition and scalar multplication are done element-wise. For \(\vec{x} = (x_1, x_2, ..., x_n)\) and \(\vec{y} = (y_1, y_2, ..., y_n)\)

				\[\lambda \vec{x} = (\lambda x_1, \lambda x_2, ..., \lambda x_n)\]
				\[\vec{x}\vec{y} = (y_1 + x_1, y_2 + x_2, ...,y_3 + x_n)\]

				\(\vec{x} - \vec{y}\) and \(-\vec{x}\) are also defined accordingly from these.
			</p>

			<p>
				In \(\mathbb{R}^2\) if \(\vec{p} = (p_1, p_2)\) then this is the directed line segment \(\overrightarrow{OP}\) starting at origin \(O\) and ending at point P \((p_1, p_2)\). \(\vec{p}\) is then the <b>position vector</b> of P.
			</p>

			<p>
				Two line segments are equivalent if they have the same length and direction. 
			</p>

			<p>
				For points \(A, B\) with vecs \(\vec{a}, \vec{b}\) then \(\overrightarrow{AB} = \vec{b} - \vec{a}\).
			</p>

			<div class="blue">
				<p>
					For \(\vec{a} = (a_1, a_2) \in \mathbb{R}^2\)
				</p>

				<p>
					The <b>length of \(\vec{a}\)</b> \(|\vec{a}| = \sqrt{a_{1}^{2} + a_{2}^{2}}\); similarly in 3D.
				</p>

				<p>
					A <b>unit vector</b> has length 1. The <b>distance</b> between \(\vec{a}, \vec{b} = |\vec{b} - \vec{a}|\).
				</p>
			</div>

			<p></p>

			<div class="blue">
				<p>
					The <b>scalar (dot) product</b>, \(\vec{a} \cdot \vec{b}\) is the real number \(a_1 b_1 + a_2 b_2 + ... + a_n b_n\).
				</p>
				
				<p>
					The angle between two position vectors, \(\theta\) between vectors \(\vec{a}, \vec{b}\) is given by

					\[\cos \theta = \frac{\vec{a} \cdot \vec{b} }{|\vec{a}||\vec{b}|}.\]

					Two vectors are <b>orthogonal</b> (perpendicular) if dot product is 0.
				</p>
			</div>

			<p>
				All definitions (if not already) can be extended to \(n\) dimensions.
			</p>

			<p class="blue">
				The <b>zero vector</b>, \(\vec{0}\) has all zeros in it.
			</p>

			<h2 id="vec-2">Linear Combinations and Subspaces</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part2/note5.pdf" class="text">Link to the PDF.</a>
			</p>

			<div class="blue">
				<p>
					<b><i>Linear Combination.</i></b> If \(\vec{u}_1, \vec{u}_2, ..., \vec{u}_m \in \mathbb{R}^n\) and \(a_1, a_2, ..., a_m \in \mathbb{R}\), then any vector of the form

					\[a_1 \vec{u}_1 + a_2 \vec{u}_2 + ... + a_m \vec{u}_m\]

					is a <b>linear combination</b> of \(\vec{u}_1, \vec{u}_2, ..., \vec{u}_m \).
				</p>
			</div>

			<p>
				A linear comb. of a single vector is defined as a multiple of that vector.
			</p>

			<p>
				In \(\mathbb{R}^3\) if \(\vec{u}, \vec{v}\) are not parallel, then \(\alpha \vec{u} + \beta \vec{v}\) represents the vertex of a parallelogram having \(\alpha \vec{u}, \beta \vec{v}\) as sides - a vector in the <b>plane</b> containing \(\vec{u}, \vec{v}, \vec{0}\).
			</p>

			<div class="blue">
				<p>
					<b><i>Span.</i></b> If \(U = \{\vec{u}_1, \vec{u}_2, ..., \vec{u}_m\}\) is a finite set of vectors in \(\mathbb{R}^n\), then the <b>span</b> of U is the set of all linear combinations of vectors in U and is denoted \(\textrm{span } U\);

					\[\textrm{span } U = \{a_1 \vec{u}_1 + a_2 \vec{u}_2 + ... + a_m \vec{u}_m : a_1, a_2, ..., a_n \in \mathbb{R}\}.\]
				</p>
			</div>

			<ul>
				<li>
					If \(U = \{\vec{u}\}\) then the span is the set of all multiples of \(\vec{u}\). 
				</li>
				<li>
					Note that for <i>basis</i> spans, 1 vector is a line, 2 vectors is a plane, and onwards to hyperplanes. (Basis is covered in next section)
				</li>
				<li>
					Elementary spans of \(\mathbb{R}^2, \mathbb{R}^3\) are \(\{(1, 0), (0, 1)\}\) and \(\{(1, 0, 0), (0,1,0), (0,0,1)\}\) respectively. 
				</li>
			</ul>

			<div class="blue">
				<p>
					<b><i>Subspaces.</i></b> A <b>subspace</b> of \(\mathbb{R}^n\) is a non-empty subset \(S \subseteq \mathbb{R}^n\) such that:
					\begin{align}
					(1) &\vec{u}, \vec{v} \in S \implies \vec{u} + \vec{v} \in S;\\
					(2) &\vec{u} \in S, \lambda \in \mathbb{R} \implies	\lambda \vec{u} \in S.
					\end{align}
					i.e. closed on addition and multiplication.
				</p>
			</div>

			<p>
				Means if a set of vectors is in a subspace, any linear combinations of those vectors is also in.
			</p>

			<p>
				Two elementary subspaces of \(\mathbb{R}^n\) are \(\{\vec{0}\}\) (just empty) and \(\mathbb{R}^n\) itself.
			</p>

			<button class="collapsible">Problem...</button>
			<div class="ccontent">
				<p>
					<b><i>Problem.</i></b> Determine if \(S\) is a subspace of \(\mathbb{R}^n\):
				</p>

				<ol>
					<li>\(S = \{(x, y, 0) : x, y \in \mathbb{R}\} \in \mathbb{R}^3\)</li>
					<li>\(S = \{(1, 1)\} \in \mathbb{R}^2\)</li>
					<li>\(S = \{(x, y) : x^2 + y^2 \leq 1\} \in \mathbb{R}^2\)</li>
				</ol>
			</div>
			<button class="collapsible">Answer...</button>
			<div class="ccontent">
				<p>
					<b><i>Answer.</i></b>(1) We need to show closure on addition and scaling. Let \(\vec{u}, \vec{v} \in S : \vec{u} = (a, b, 0), \vec{v} = (c, d, 0)\) for some \(a, b, c, d \in \mathbb{R}\).

					\[\vec{u} + \vec{v} = (a, b, 0) + (c, d, 0) = (a+c, b+d, 0) \in S.\]

					For any \(\lambda \in \mathbb{R}\)

					\[\lambda \vec{u} = \lambda (a, b, 0) = (\lambda a, \lambda b, 0) \in S.\] 
				</p>

				<p>
					(2) Nope, since \(2(1,1) \not \in S\), so no scaling closure.
				</p>

				<p>
					(3) Nope. Let \(\vec{u} = (1, 0), \vec{v} = (0, 1)\), both of which \(\in S\), however \(\vec{u} + \vec{v} = (1, 1)\). \(1^2 + 1^2 = 2 \not \leq 1\), so not closed under addition.
				</p>
			</div>

			<p></p>
			<div class="blue">
				<p>
					<b><i>Properties of Subspaces.</i></b>
				</p>

				<ol>
					<li>Every subspace contains \(\vec{0}\).</li>
					<li>If \(U\) is a nonempty finite subset of \(\mathbb{R}^n\) then \(\textrm{span } U\) is a subspace, the subspace <b>spanned or generated</b> by U.</li>
				</ol>
			</div>

			<h2 id="vec-3">Linear Independence</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part2/note5.pdf" class="text">Link to the PDF.</a>
			</p>

			<div class="blue">
				<p>
				A set of vectors \(\{\vec{u}_1, \vec{u}_2, ..., \vec{u}_m\} \in\mathbb{R}^n\) are <b>linearly <i>dependent</i></b> IF there are real numbers \(a_1, a_2, ..., a_n\) which are NOT ALL ZERO such that \(a_1 \vec{u}_1 + a_2 \vec{u}_2 + ... + a_m \vec{u}_m = \vec{0}.\)

				
			</p>
			<p>
				Thus a <b>linearly <i>independent</i></b> set is where IF \(a_1 \vec{u}_1 + a_2 \vec{u}_2 + ... + a_m \vec{u}_m = \vec{0}.\)
				THEN ALL \(a_i\) are <b>0</b>.
			</p>
			</div>
			

			<p>
				i.e. if you can't find a nonzero linear combination that makes zero vector, then the set is linearly independent.
			</p>

			<ul>
				<li>If a set contains one nonzero vector, it is lin. indep.</li>
				<li>If it contains the zero vector, it is lin. dep.</li>
			</ul>

			<p>
				In a set of three vectors, you can fairly easily solve three simultanous equations all with the sum of zero. Then, you either find that your three coefficients \(\alpha, \beta, \gamma\) has to be 0 (indep) or there is some non-zero relationship between at least two of them (dep)
			</p>

			<p class="side">
				<b><i>Theorem.</i></b> A set \(\{\vec{u}_1, \vec{u}_2, ..., \vec{u}_m\}\) of nonzero vectors is linearly <i>depending</i> <b>iff</b> some / any vector \(\vec{u}_r\) is a linear combination of its predecessors \{\vec{u}_1, \vec{u}_2, ..., \vec{u}_m{r-1}\}
			</p>

			<p><i>(proof omitted)</i>
			</p>

			<h2 id="vec-4">Basis and Dimension</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part2/note7.pdf" class="text">Link to the PDF.</a>
			</p>

			<p class="blue">
				<b><i>Basis.</i></b> Let \(S\) be a subspace of \(\mathbb{R}^n\). A set of vectors is a <b>basis</b> of S if it is a <i>linearly independent</i> set which spans S.
			</p>

			<p> 
				e.g. The set \(\{(1,0,0), (0,1,0), (0,0,1)\}\) is a basis for \(\mathbb{R}^3\). In fact, it is the <b>standard basis</b>.
			</p>

			<p class="side">
				<b><i>Theorem.</i></b> Let \(S\) be subspace of \(\mathbb{R}^n\). If a set \(\vec{v}_1, \vec{v}_2, ..., \vec{v}_m\) spans S, then any <i>linearly indep.</i> subset of S has <i>at most</i> \(m\) vectors.
			</p>

			<p><i>(proof omitted)</i></p>

			<p>
				This leads to the fact that any two bases for a subpace S have the <b>same</b> number of elems. 
			</p>

			<p class="blue">
				<b><i>Dimension.</i></b> The <b>dimension</b> of a subspace of \(\mathbb{R}^n\) is the number of vectors in the basis.
			</p>

			<button class="collapsible">Problem...</button>
			<div class="ccontent">
				<p>
					<b><i>Problem.</i></b> Show that the set \(S = \{(x, y, z) : x + 2y - z = 0\}\) is a subspace of \(\mathbb{R}^3\), and find a basis and dimension of \(S\).
				</p>
			</div>
			<p></p>
			<button class="collapsible">Answer...</button>
			<div class="ccontent">
				<p>
					<b><i>Answer.</i></b> We can rewrite S as:
					\begin{align}
					S &= \{(x, y, x+2y = 0) : x, y \in \mathbb{R}\} \\
					&= \{x(1, 0, 1) + y(0, 1, 2) : x, y \in \mathbb{R}\} \\
					&= \textrm{ span } \{(1, 0, 1), (0, 1, 2)\}.
					\end{align}

					Whih shows that S is a subspace, since the span of any nonempty finite set is a subspace (known property). 
				</p>

				<p>
					By inspection we can see that the two vectors in the set are independent, thus it is a basis. Thus the dimension of S is 2. 
				</p>
			</div>

			<p>
				(Supposedly) we can use the theorem from <a href="#vec-3">lineaer independence</a> to construct a basis from as panning set. 
			</p>

			<div class="blue">
				<p>
					Let \(\{\vec{v}_1, \vec{v}_2, ..., \vec{v}_m\}\) be a basis of a subspace S of \(\mathbb{R}^n\). Then removing each \(\vec{v}_i\) which is a linear combination of its "predecessors" will leave a basis for S. 
				</p>
			</div>
			<p></p>
			<button class="collapsible">Problem...</button>
			<div class="ccontent">
				<p>
					<b><i>Problem.</i></b> Find a basis for and dimension of a subspace S (of \(\mathbb{R}^4\)) spanned by
					\[\{(2,1,0,-3), (-1,0,-1,2), (1,2,-3,0), (0,0,0,1), (0,1,-2,0)\}.\]
				</p>
			</div>
			<p></p>
			<button class="collapsible">Answer...</button>
			<div class="ccontent">
				<p>
					<b><i>Answer.</i></b> Let's look at (1, 2, -3, 0) and see if it is a lin. comb. of predecessors. 
					\[(1, 2, -3, 0) = \alpha(2,1,0,-3) + \beta(-1,0,-1,2)\]
					\begin{align}
					&\implies \begin{cases} 2\alpha - \beta &= 1 \\ \alpha &= 2 \\ -\beta &= -3 \\ -3\alpha + 2\beta &= 0 \end{cases}
					&\implies \begin{cases} \alpha &= 2 \\ \beta &= 3. \end{cases}
					\end{align}
					We can see it is a linear combination, so we remove, giving
					\[\{(2,1,0,-3), (-1,0,-1,2), (0,0,0,1), (0,1,-2,0)\}.\]
				</p>

				<p>
					Now we next check \((0,0,0,1)\). 
					\[(0,0,0,1) = \alpha(2,1,0,-3) + \beta(-1,0,-1,2)\]
					\begin{align}
					&\implies \begin{cases} 2\alpha - \beta &= 0 \\ \alpha &= 0 \\ -\beta &= 0 \\ -3\alpha + 2\beta &= 1 \end{cases}
					&\implies \begin{cases} \alpha &= 0 \\ \beta &= 0 \\ -3\alpha + 2\beta &= 1. \end{cases}
					\end{align}

					Which have no solution of \(\alpha, \beta\) and thus (0, 0, 0, 1) is not a linear combination of priors. Thus \(\{(0,0,0,1),(2,1,0,-3),(-1,0,-1,2)\}\) is a lin. indep. set.
				</p>

				<p>
					Check the last one against all others,
					\[(0,1,-2,0) = \alpha(2,1,0,-3) + \beta(-1,0,-1,2) + \gamma(1, 2, -3, 0)\]
					\begin{align}
					&\implies \begin{cases} 2\alpha - \beta &= 0 \\ \alpha &= 1 \\ \beta &= 2 \\ -3\alpha + 2\beta + \gamma &= 0 \end{cases}
					&\implies \begin{cases} \alpha &= 1 \\ \beta &= 2 \\ \gamma &= -1. \end{cases}
					\end{align}
					So we remove that, thus finally the remaining set \(\{(0,0,0,1),(2,1,0,-3),(-1,0,-1,2)\}\) is the final basis of \(S\), which gives \(S\) a dimension of 3.
				</p>
			</div>

			<p>
				There are a few quick checks one can do beforehand. 
			</p>

			<div class="blue">
				<p>
					Let S be an \(m\)-dimensional subspace of \(\mathbb{R}^n\) then
				</p>
				<ol>
					<li>Any subset of S with more than \(m\) vectors is linearly <i>dependent</i>;</li>
					<li>A subset of S is a basis <i>if and only if</i> it is a linearly independent set containing \(m\) vectors.</li>
				</ol>

				<p>
					It then follows that any subset of \(\mathbb{R}^n\) is linearly <i>dependent</i>, and a subset of \(\mathbb{R}^n\) <i>iff</i> it is a linearly independent set containing \(n\) vectors. 
				</p>
			</div>
			<p></p>

			<button class="collapsible">\(\mathbb{R}^2, \mathbb{R}^3\) properties...</button>
			<div class="ccontent">
				<p>
					Subspaces of \(\mathbb{R}^2\):
				</p>
				<ol>
					<li>There is one 0 dim subspace \(\{\vec{0}\}\)</li>
					<li>A 1D subspace is spanned by a single non-zero vector: straight lines through origin.</li>
					<li>The only 2D subspace is \(\mathbb{R}^2\)</li>
				</ol>

				<p>
					Subspaces of \(\mathbb{R}^3\):
				</p>
				<ol>
					<li>There is one 0 dim subspace \(\{\vec{0}\}\)</li>
					<li>A 1D subspace is spanned by a single non-zero vector: straight lines through origin.</li>
					<li>A 2D subspace is spanned by 2 lin. indep. vectors: plains containing the origin</li>
					<li>The only 3D subspace is \(\mathbb{R}^3\)</li>
				</ol>
			</div>

			
		</div>

		<div class="colourband" id="matrices">
			<h2>Matrices</h2>
		</div>

		<div class="cbox">
			<h2>Introduction</h2>

			<ol>
				<li><a href="#mat-1">Matrix Algebra</a></li>
				<li><a href="#mat-2">Matrix Inverse, Linear Equations</a></li>
				<li><a href="#mat-3">Matrix Inverse, Determinants</a></li>
				<li><a href="#mat-4">Linear Transformations</a></li>
				<li><a href="#mat-5">Matrices and Linear Transformations</a></li>
			</ol>

			<h2 id="mat-1">Matrix Algebra</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part2/note8.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				Matrices are rectangular arrays of elements. It's order is its \(\textrm{row } \times \textrm{ column}\). Note that an \(m \times 1\) matrix is called a <b>column matrix/vector</b>, and \(1 \times n\) matrices are similarly named as rows. Elements are referred to with subscript row column: \(a_{ij}\).
			</p>

			<p>
				Sum of two matrices is only defined if they have the same order, and is <i>elementwise</i> addition. Scalar multiplication is also done elementwise.
			</p>

			<p>
				The Zero matrix, denoted \(O_{m \times n}\) is a matrix of all zeros. 
			</p>

			<div class="blue">
				<p>
					<b><i>Properties of addition and scalar multiplication.</i></b> \(\forall m \times n\) matrices \(A, B, C\), \(\forall \lambda, \mu \in \mathbb{R}\):
				</p>

				<ol>
					<li>\(A + (B+C) = (A+B)+C\) (associativity of addition)</li>
					<li>\(A + O = A = O + A\)</li>
					<li>\(A + (-A) = O = (-A) + A\)</li>
					<li>\(A+B=B+A\) (commutativity of addition)</li>
					<li>\((\lambda + \mu)A = \lambda A + \mu A\)</li>
					<li>\(\lambda (A+B) = \lambda A + \lambda B\)</li>
					<li>\(\lambda(\mu A) = (\lambda \mu ) A\)</li>
				</ol>
			</div>

			<p>
				Matrix multiplication can only happen between an \(A_{m \times \mathbfit{n}}\) and a \(B_{\mathbfit{n} \times p}\) (note the highlighted dimensions) and will produce a matrix \(C_{m \times p}\). 
			</p>

			<p>
				Matrix multiplication is hard to explain in text, so <a href="https://www.youtube.com/watch?v=as8C8w-Nz94">see this video</a> if you're not sure (by blackpenredpen).
			</p>

			<p>
				A square matrix \(A_{n \times n}\) is said to be of <i>order \(n\)</i>
			</p>

			<p>
				<b>Diagonal matrices</b> only have elements on the leading diagonal; \(a_{ii}\) for some \(i : [1..n]\).
			</p>

			<p>
				The <b>identity matrix</b> \(I\) (or \(I_n\)) is the \(n \times n\) diagonal matrix whose diagonal elements are all 1. 
			</p>

			<p>
				For a square matrix \(A\), \(A, AA, AAA, ...\) are defined as \(A, A^2, A^3,...\) respectively. \(A^0 = I\). Functions \(\exp(A), \cos(A), \sin(A)\) can also be defined <i>(hint: taylor series)</i>.
			</p>

			<div class="blue">
				<p>
					<b><i>Properties of matrix multiplicaiton.</i></b> whenever the products exist:
				</p>
				<ol>
					<li>\((AB)C = A(BC)\) (associativity)</li>
					<li>\(A(B+C) = AB + AC\), \((A+B)C = AC + BC\)</li>
					<li>\(IA = A = AI\)</li>
					<li>\(OA = O = AO\)</li>
					<li>\(A^p A^q = A^{p+q} = A^q A^p\), \((A^p)^q = A^{pq}\)</li>
				</ol>
				<p>
					Note that matrix multiplication is <b>not commutative</b>: \(AB \neq BA\) (for all but specific circumstances).
				</p>
			</div>

			<p>
				The <b>transpose</b> \(A^T\) of a matrix is obtained by swapping rows and columns (i.e. reflecting on leading diagonal).
			</p>

			<div class="blue">
				<p>
					<b><i>Properties of transposition.</i></b>
				</p>
				<ol>
					<li>\((A^T)^T=A\)</li>
					<li>\((A+B)^T = A^T + B^T\) if \(A+B\) exists</li>
					<li>\((\lambda A)^T = \lambda A^T\) for any \(\lambda \in \mathbb{R}\)</li>
					<li>\((AB)^T = B^T A^T\) if \(AB\) exists.</li>
				</ol>
			</div>

			<p>
				For same order square matrices \(A, B\), \(B\) is the inverse of \(A\) if and only if \(AB = I = BA\). The inverse (should it exist) is <b>unique</b> and denoted \(A^{-1}\).
			</p>

			<p>
				The <b>determinant</b> of a \(2 \times 2\) matrix \(A = \begin{bmatrix} a & b \\ c & d \end{bmatrix}\) is \(ad-bc\) and denoted \(|A|, \det(A)\).
			</p>

			<p>
				If a \(2 \times 2\) matrix is invertible, then \(\det(A)det(A^{-1}) = \det(AA^{-1}) = \det(I) = 1\). Thus \(\det(A) \neq 0\) and in that case,
			</p>

			<p class="blue">
				The inverse of \(A = \begin{bmatrix} a & b \\ c & d \end{bmatrix}\) is

				\[A^{-1} = \frac{1}{\det A} \begin{bmatrix} d & -b \\ -c & a \end{bmatrix}\]
				(a particular case of a general result)
			</p>

			<h2 id="mat-2">Matrix Inverse, Linear Equations</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part2/note9.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				A system of linear equations can be written in matrix form.

				\begin{align}
				ax_1 + bx_2 &= y_1 \\
				cx_1 + dx_2 &= y_2 
				\end{align}

				\[
				\equiv \begin{bmatrix} a & b \\ c & d \end{bmatrix} \begin{bmatrix} x_1 \\ x_2 \end{bmatrix} = \begin{bmatrix} y_1 \\ y_2 \end{bmatrix}.
				\]

				Which can be extrapolated to general form.
			</p>

			<div class="blue">
				<p>
				The following operations can be performed to solve a system (<b>Gaussian Elimination</b>):
			</p>

			<ul>
				<li>Swap two rows (equations)</li>
				<li>Multiply a row (both sides of an eqn) by a nonzero number</li>
				<li>Add a multiple of one row (eqn) to another</li>
			</ul>
			</div>
			

			<p>
				Which can be done over the <i>augmented matrix</i>, which is gotten by combining \(\begin{bmatrix} a & b \\ c & d \end{bmatrix}\) and \(\begin{bmatrix} y_1 \\ y_2 \end{bmatrix}\) (the coefficients and the result).

				\[
				\left[\begin{array}{cc|c} a & b & y_1 \\ c & d & y_2 \end{array}\right]
				\]
			</p>

			<p>
				Two matrices \(A, B\) are <b>row equivalent</b> if we can use row operations to get from A to B. Denoted \(A \sim B\).
			</p>

			<p class="blue">
				A matrix is in <b>row echelon form</b> if the first nonzero entry in each row is further to the right of said entry in the previous row. By reducing to row echelon form we can solve a system of linear equations. 
			</p>

			<p>
				See the pdf for sample problems. <i>Note: there also exists <b>reduced row echelon form</b>, where each leading entry is a 1, and each column with a 1 in has 0s for all other entries.</i>
			</p>

			<p>
				Elementary row ops can be done by multiplying by so-called <i>elementary matrices</i>. These are defined for (\E_{n \times n}\):
			</p>

			<ul>
				<li>\(E_{ij}\) obtained from \(I\) by exchanging rows \(i, j\)</li>
				<li>For \(\lambda \neq 0, \; E_i(\lambda)\) obtained from \(I\) by multiplying row \(i\) by \(\lambda\)</li>
				<li>\(E_{ij}(\mu)\) obtained from \(I\) by adding \(\mu \cdot\) row \(j\) to row \(i\)</li>
			</ul>

			<p>
				Every elementary matrix is invertible.
			</p>

			<p class="blue">
				If a sequence of row operations transforms a square matrix \(A\) into \(I\). then \(A^{-1}\) exists and the same sequence transforms \(I\) into \(A\).
			</p>

			<p>
				This is best done with an augmented matix, like
				\[
				\left[\begin{array}{cc|cc} a & b & 1 & 0 \\ c & d & 0 & 1 \end{array}\right]
				\]
			</p>

			<h2 id="mat-3">Matrix Inverse, Determinants</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part2/note10.pdf" class="text">Link to first PDF.</a> <br>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part2/note11.pdf" class="text">Link to second PDF.</a>
			</p>

			<p>
				The determinant of a \(3 \times 3\) matrix is denoted the same way, and is defined

				\[
				\begin{vmatrix}
				a_{11} & a_{12} & a_{13} \\ a_{21} & a_{22} & a_{23} \\ a_{31} & a_{32} & a_{33}
				\end{vmatrix} =

				a_{11} \begin{vmatrix} a_{22} & a_{23} \\ a_{32} & a_{33}\end{vmatrix}
				- a_{12} \begin{vmatrix}a_{21} & a_{23} \\ a_{31} & a_{33}\end{vmatrix}
				+ a_{32} \begin{vmatrix}a_{21} & a_{22} \\ a_{31} & a_{32}\end{vmatrix}

				\]

				i.e. all elements on the first row multiplied (respecting +/- grid) with the determinant of the minor matrix (the cofactor) - the matrix gotten by deleting the row and column with said element. 
			</p>

			<p>
				\[\begin{bmatrix}+&-&+\\-&+&-\\+&-&+\end{bmatrix}\]
			</p>

			<p>
				This can be done with any row or column.
			</p>

			<div class="blue">
				<p>
					On elementary row operations and determinants (\(B\) obtained from \(A\)):
				</p>
				<ol>
					<li>Multiplying a row in A by a \(\lambda\): \(|B| = \lambda|A|\)</li>
					<li>Swapping 2 rows of A: \(|B| = -|A|\)</li>
					<li>Adding a multiple of one row to another: \(|B| = |A|\)</li>
				</ol>
			</div>

			<p></p>
			<div class="blue">
				<p>
					A square matrix is inversible <i>iff</i> its determinant is not 0. If \(A\) is invertible,
				\[A^{-1} = \frac{1}{|A|} \textrm{adj}(A)\]
					where \(\textrm{adj}(A)\) is the <b>transposed matrix of cofactors</b>.
				</p>
				
			</div>

			<p>
				You can also use matrix inverses to calculate equations:
				\begin{align}
				\textrm{if } &A\vec{x} = \vec{y}\\
				\textrm{then } &A^{-1} A \vec{x} = A^{-1} \vec{y} \implies \vec{x} = A^{-1}\vec{y}
				\end{align}
				Where the column vector x are the variables, and column vector y are the values of the equations. 
			</p>

			<p class="blue">
				<b><i>Linear independence via determinants.</i></b> A set of \(n\) vectors in \(\mathbb{R}^n\) is linearly independent <i>if and only if</i> it is the set of column vectors of a matrix with nonzero determinant.
			</p>

			<p>
				Basically, bang \(n\)  \(\mathbb{R}^n\) vectors into a square matrix, compute the determinant, and if it is 0, then those vectors are linearly dependent.
			</p>

			<h2 class="mat-4">Linear Transformations</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part2/note12.pdf" class="text">Link to the PDF.</a>
			</p>

			<div class="blue">
				<p>
					A function \(T : \textrm{R}^m \longrightarrow \mathbb{R}^n\) is a <b>linear transformation</b> if, \(\forall \vec{u}, \vec{v} \in \mathbb{R}^n, \lambda \in \mathbb{R}\), we have:

					\[ T(\vec{u} + \vec{v}) = T(\vec{u}) + T(\vec{v}), \]
					\[ T(\lambda \vec{u}) = \lambda T(\vec{u}). \]

					Which are preservation of addition and scaling respectively. Also,	
				</p>

				<p>
					\[T(\vec{0}) = \vec{0}.\]
				</p>
			</div>

			<p>
				For simple problems, verifying that the transformation fits the two rules of addition and scaling is sufficient.
			</p>

			<div class="side">
				<p>
					<b><i>Example.</i></b> Let \(\vec{u}\) be a nonzero 2D vector. If \(\vec{x} \in \mathbb{R}^2\) then we define the <b>projection</b> of \(\vec{x}\) onto \(\vec{u}\) to be a vector \(P_{\vec{u}}(\vec{x})\) such that
				</p>
				<ol>
					<li>\(P_{\vec{u}}(\vec{x})\) is a multiple of \(\vec{u}\)</li>
					<li>\(\vec{x} - P_{\vec{u}}(\vec{x})\) is perpendicular to \(\vec{u}\).</li>
				</ol>
				<p>
					We have by (1) that \(P_{\vec{u}}(\vec{x}) = \alpha \vec{u}\) for some \(\alpha \in \mathbb{R}\), so by (2)
					\[0 = (\vec{x} - P_{\vec{u}}(\vec{x})) \cdot \vec{u} = (\vec{x} - \alpha \vec{u}) \cdot \vec{u} = \vec{x} \cdot \vec{u} - \alpha |\vec{u}|^2,\]
					\[\implies \alpha = \frac{\vec{x}\cdot\vec{u}}{|\vec{u}|^2}.\]
				</p>
				<p>
					The projection can then be regarded as a function \(P_\vec{u} : \mathbb{R}^2 \longrightarrow \mathbb{R}^2\) defined \(\forall \vec{x} \in \mathbb{R}^2\):
					\[P_{\vec{u}}(\vec{x}) = (\frac{\vec{x}\cdot\vec{u}}{|\vec{u}|^2})\vec{u}.\]
					This function can be verified to be a linear transformation.
				</p>
			</div>
			<p></p>
			<div class="side">
				<p>
					<b><i>Example.</i></b> For \(\theta \in [0, 2\pi)\) define \(R_\theta : \mathbb{R}^2 \longrightarrow \mathbb{R^2}\) to be a function describing rotation about angle \(\theta\) through origin. After a bit of derivation, we get

					\[R_\theta (x, y) = (x\cos\theta - y\sin\theta, x\sin\theta - y\cos\theta).\]

					Or alternatively in matrix form (let \((x', y')\) be \(R_\theta (x, y)\)) as

					\[
					\begin{bmatrix} x' \\ y' \end{bmatrix} = \begin{bmatrix}\ \cos\theta & -\sin\theta \\ \sin\theta & \cos\theta \end{bmatrix} \begin{bmatrix} x \\y \end{bmatrix}.
					\]
				</p>
			</div>

			<h2 id="mat-5">Linear Transformations and Matrices</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part2/note13.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				Referring back to the last example in the last section, it is further true that <b>every</b> \(M_{m \times n}\) matrix can act as a linear transformation (\(T(\vec{x}) = M\vec{x}\)). Vectors are column vectors.
			</p>

			<p>
				For a basis \(V = \{\vec{v}_1, \vec{v}_2, ... \vec{v}_n\}\) of \(\mathbb{R}^n\), every \(\vec{x} \in \mathbb{R}^n\) has a linear expansion \(\vec{x} = a_1 \vec{v}_1 + a_2 \vec{v}_2 + ... + a_n \vec{v}_n\).
			</p>

			<p>
				These coefficients \(a_1 ... a_n\) are the <b>coordiates of \(x\) with respect to basis \(V\)</b>.
			</p>

			<p>
				Let \(T : \mathbb{R}^m \longrightarrow \mathbb{R}^n\) be a linear transformation, V be a basis in \(\mathbb{R}^m\) and W a basis in \(\mathbb{R}^n\).
			</p>

			<p>
				For each vector \(\vec{v}\) in V \(T(\vec{v})\) has an expansion in W. The <b>Matrix of a linear transformation</b> T with respect to V and W is the \(m \times n\) matrix where each column \(i\) contains the coefficients of the expansion of \(T(\vec{v}_i)\) for each \(\vec{v}_i \in V\).
			</p>

			<p>
				When \(m = n, \; W = V\) then it is referred to as the <b>matrix of T with respect to basis V</b>.
			</p>

			
			<div class="blue">
				<p>
					<b><i>Matrix of a linear transformation.</i></b> For a linear transformation T (as above), M the matrix of T with respect to bases V, W (as above); the columns of M contain the coordinates of the <i>images</i> of the basis vectors in V w/ respect to W. 
				</p>

				<p>
					If \(\vec{x} \in \mathbb{R}^m\) has coordinates \([x_1,...,x_n]\) with respect to V then the coordinates with respect to W, \([y_1, ... , y_n]\) are
					\[\begin{bmatrix} y_1 \\ \vdots \\ y_n \end{bmatrix} = M \begin{bmatrix} x_1 \\ \vdots \\ x_n \end{bmatrix}.\]
				</p>
			</div>

			<p>
				A matrix that changes between two different bases in \(\mathbb{R}^n\) is called a <b>transition matrix</b>.
			</p>

			<p>
				The definition on the notes is uh, <!-- fuck awful --> just do the same thing as above but the matrix will be square.
			</p>

			<h2 id="mat-6">Eigenvalues and Eigenvectors</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part2/note14.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				Relating to matrices multiplying vectors, and especially where the vectors don't change direction. 
			</p>

			<p class="blue">
				For a matrix A and a vector \(\vec{r}\), if \(A\vec{r} = \lambda \vec{r}, \; \lambda \in \mathbb{R}\), then \(\vec{r}\) is the <b>eigenvector</b> and \(\lambda\) is the <b>eigenvalue</b>.
			</p>

			<p class="blue">
				A number \(\lambda\) is an eigenvalue of A if and only if it satisfies the <b>characteristic equation</b>
				\[|A - \lambda I| = 0.\]
			</p>

			<p>
				For an order \(n\) matrix there are \(n\) (not necessarily unique) eigenvalues. Eigenvalues can also be \(\in \mathbb{C}\).
			</p>

			<p>
				Recall that diagonal matrices are written \(\textrm{diag}[a_{11}, a_{22}, ..., a_{nn}]\).
			</p>

			<div class="blue">
				<p>
					<b><i>Diagonalisation of Matrices.</i></b> For an order \(n\) matrix A:
					\[A = UDU^{-1}\]
					Where \(D = \textrm{diag}[\lambda_1, \lambda_2, ..., \lambda_n]\) (the eigen values), and
					\(U = [\vec{v}_1, \vec{v}_2, \dots, \vec{v}_n]\) are the <i>corresponding</i> eignvectors of said eigenvalues.
				</p>

				<p>
					Note that if you have repeated eigenvalues, you have to find multiple <i>distinct</i> (lin. indep.) eigenvectors for that eigenvalue.
				</p>
			</div>
		</div>

		<div class="colourband" id="sequences">
			<h2>Sequences and Series</h2>
		</div>

		<div class="cbox">
			<h2>Introduction</h2>

			<ol>
				<li><a href="#seq-1">Sequences</a></li>
				<li><a href="#seq-3">Series</a></li>
				<li><a href="#seq-2">Recurrences</a></li>
				<li><a href="=seq-4">Decimal Representation of Reals</a></li>
			</ol>

			<p class="small">
				By the way, did I ever mention I hate sequences and series?
			</p>

			<h2 id="seq-1">Sequences</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part3/note15.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				A sequence \((a_n)\) is an infinite list of numbers \((a_0, a_1,...)\). We can define sequences through <i>n<sup>th</sup> term</i> rules or <i>recursively</i>.
			</p>

			<div class="blue">
				<p>
					<b><i>Convergent Sequence.</i></b> A sequence \(a_n\) is said to <b>converge </b>to a <b>limit</b> \(l \in \mathbb{R}\) if for every small \(\epsilon > 0\) there is a related integer \(N\) such that \(|a_n - l| < \epsilon \; \forall n > N\). This is denoted as
					\begin{align}
					&\lim_{n \rightarrow \infty} a_n = l; &a_n \rightarrow l.
					\end{align}
				</p>
				
			</div>

			<p>
				In layman's terms, if a sequence converges, then for every (increasingly small) positive number, the difference between the sequence's terms and the limit will be eventually smaller.
			</p>
			<p>
				\(N\) here is like a <i>threshold indicator</i>, where every term of the sequence after \(N\) will be within the \(\epsilon\) difference.
			</p>
			<p>
				We generally worth with \(n \in \mathbb{N}\).
			</p>			

			<div class="side">
				<p>
					<b><i>Example.</i></b> The sequence \(a_n = \frac{1}{n}\) converges to 0. We can prove this by going to the definition - let us have a small \(\epsilon > 0\). 
				</p>
				<p>
					Then \(\exists N : a_N - 0 < \epsilon\), or \(\frac{1}{N} < \epsilon\). We can choose any integer \(N > \frac{1}{e}\), to demonstrate that this is possible for any \(\epsilon\). For any \(n > N\):

					\[|\frac{1}{n} - 0| = \frac{1}{n} < \frac{1}{N} < \epsilon,\]

					to write it out as an equation.
				</p>
			</div>

			<p>
				If possible, try break a large sequence down into simpler components. They can be combined using the following:
			</p>

			<div class="blue">
				<p>
					<b><i>Combination Rules for Convergent Sequences.</i></b> For convergent sequences \(a_n \rightarrow \alpha, b+n \rightarrow \beta, c_n \rightarrow \gamma\):
				</p>

				<ol>
					<li><b>Sum</b> rule: \(a_n + b_n \rightarrow \alpha + \beta\)</li>
					<li><b>Scalar multiple</b> rule: \(\lambda a_n \rightarrow \lambda\alpha, \; \lambda \in \mathbb{R}\)</li> 
					<li><b>Product</b> rule: \(a_n b_n \rightarrow \alpha\beta\)</li>
					<li><b>Reciprocal</b> rule: \(\frac{1}{a_n} \rightarrow \frac{1}{\alpha}\)</li>
					<li><b>Quotient</b> rule: \(\frac{b_n}{a_n} \rightarrow \frac{\beta}{\alpha}\)</li>
					<li><b><i>Hybrid</i></b> rule: \(\frac{b_n c_n}{a_n} \rightarrow \frac{\beta\gamma}{\alpha}\)</li>
				</ol>

			</div>
			<p></p>
			<button class="collapsible">Problem...</button>
			<div class="ccontent">
				<p>
					<b><i>Problem.</i></b> Show that the following sequence converges, find its limit:
					\[ a_n = \frac{(n+2)(2n-1)}{3n^2 + 1} \]
				</p>
			</div>
			<p></p>
			<button class="collapsible">Answer...</button>
			<div class="ccontent">
				<p>
					The components do not converge themselves, a technique here is <i>dividing by the fastest increasing term</i>. Dividing by \(n^2\),

					\[ a_n = \frac{\frac{(n+2)}{n}\frac{(2n-1)}{n}}{\frac{3n^2 +1}{n^2}} = \frac{(1 + \frac{2}{n})(2 - \frac{1}{n})}{3 + \frac{1}{n^2}}. \]
				</p>
				<p>
					Now the components \(\frac{1}{n}\) and \(\frac{1}{n^2}\) converge to 0, so applying combination rules we can get

					\[a_n \rightarrow \frac{(1+0)(2-0)}{3+0} = \frac{2}{3}. \]
				</p>
			</div>

			<p>
				A sequence \(a_n\) is <b>bounded above</b> if there is a number \(U : a_n \leq U \forall n\). \(a_n\) is <b>bounded below</b> if there is a number \(L : L \leq a_n \forall n\). A sequence is <b>bounded</b> if it is bounded both above and below.
			</p>

			<p>
				A <b>subsequence</b> of a sequence is obtained from the original sequence by deleting some terms. We can say \(a_{2n}, a_{2n+1}\) are the even and odd subsequences respectively of \(a_n\).
			</p>

			<p>
				A sequence \(a_n\) is an <b>increasing</b> sequence if \(a_{n+1} \geq a_n \;\forall n\). It is  a <b>decreasing</b> sequence if \(a_{n+1} \leq a_n \;\forall n\). 
			</p>

			<div class="blue">
				<p><b><i>Basic Properties of Convergent Sequences.</i></b></p>

				<ol>
					<li>A convergent sequence has a <i>unique</i> limit.</li>
					<li>If \(a_n \rightarrow l\) then <i>every subsequence</i> of \(a_n\) also converges to \(l\).</li>
					<li>If \(a_n \rightarrow l\) then \(|a_n| \rightarrow |l|\).</li>
					<li><b>The squeeze rule.</b> If \(a_n \rightarrow l, b_n \rightarrow l; a_n < c_n < b_n \; \forall n\) then \(c_n \rightarrow l\).<sup>1</sup></li>
					<li>A convergent sequence is always bounded.<sup>2</sup></li>
					<li>An increasing sequence which is bounded above converges. A decreasing sequence which is bounded below converges.</li>
				</ol>

				<p class="small">
					<sup>1</sup>The sequence \(c_n\) is "squeezed" between two sequences which both converge to the same limit, so naturally it will too.<br>
					<sup>2</sup>\(\exists B > 0 : - B \leq a_n \leq B, \; \forall n\).
				</p>
			</div>

			<p>
				You can demonstrate an alternating sequence (e.g. \((-1)^n\)) doesn't converge by looking at <i>subsequences</i>.
			</p>

			<p>
				Reminder: the binomial theorem is
				\[(1 + x)^n = 1 + nx + \frac{n(n-1)}{2!}x^2 + ... + \frac{n!}{k!(n-k)!}x^k\]
			</p>

			<button class="collapsible">Problem...</button>
			<div class="ccontent">
				<p>
					<b><i>Problem.</i></b> Show that for \(x \geq 0, n > 0\), this: \((1+x)^{\frac{1}{n}} \leq 1 + \frac{x}{n}\).
				</p>

				<p>
					Hence deduce/show that if \(c > 0\) then \(c^\frac{1}{n} \rightarrow 1\).
				</p>
			</div>
			<p></p>
			<button class="collapsible">Answer...</button>
			<div class="ccontent">
				<p>
					<b><i>Answer.</i></b> Firstly, we can rearrange and use the binomial theorem.
					\begin{align}
					1 + x &\leq (1 + \frac{x}{n})^n. \\
					(1 + \frac{x}{n})^n &= 1 + n\frac{x}{n} + \textrm{ (other positive terms) via binomial exp, so} \\
					1 + x &\leq 1 + x + \textrm{ (other positive terms)} \\
					\end{align}
					Thus if we take \(n^\textrm{th}\) roots of each side we will demonstrate that
					\[(1+x)^\frac{1}{n} \leq 1 + \frac{x}{n}.\]
				</p>
				<p>
					For the second part, we need to consider separately the cases \(c \geq 1\) and \(c < 1\).
				</p>
				<p>
					If \(c \geq 1\) then \(c^\frac{1}{n} \geq 1\). If we use the inequality we demonstrated in the first part, letting \(x = c-1 \geq 0\) we get
					\[1 \leq c^\frac{1}{n} \leq 1 + \frac{c-1}{n}.\]
				</p>
				<p>
					By the squeeze rule, we can (in an ideal world) see that \(c^\frac{1}{n} \rightarrow 1\). 
				</p>
				<p>
					Finally if \(c < 1\) then \(\frac{1}{c} > 1\) and by the reciprocal rule \(\frac{1}{c^\frac{1}{n}} \rightarrow 1\).
				</p>
				<p class="small">
					Did you get that? Me neither.
				</p>
			</div>

			<p>
				<b><i>Divergent Sequence.</i></b> A squence \(a_n\) is said to <b>diverge to infinity</b> if \(\forall K \in \mathbb{R}\; \exists N : n > N \implies a_n > K\). 
			</p>

			<p>
				In plain english, there is a point in \(a_n\) where the terms are greater than any real number one picks.
			</p>

			<p>
				We denote this as \(a_n \rightarrow \infty\). \(a_n\) diverges to \(-\infty\) if \(-a_n \rightarrow \infty\). 
			</p>

			<p>
				A divergent sequence that doesn't go off to infinity is said to <b>oscillate</b>.
			</p>

			<div class="blue">
				<p>
					<b><i>Basic convergent sequences.</i></b>
					\begin{align}
					& \lim_{n \rightarrow \infty} \frac{1}{n^p} = 0 & \forall p > 0 \\
					& \lim_{n \rightarrow \infty} c^n = 0 & \forall c : |c| < 1 \\
					& \lim_{n \rightarrow \infty} c^\frac{1}{n} = 1 & \forall c > 0 \\
					& \lim_{n \rightarrow \infty} n^p c^n = 0 & \forall p > 0 \land |c| < 1 \\
					& \lim_{n \rightarrow \infty} \frac{c^n}{n!} = 0 & \forall c \in \mathbb{R} \\
					& \lim_{n \rightarrow \infty} (1 + \frac{c}{n})^n = e^c & \forall c \in \mathbb{R}
					\end{align}
				</p>
				
			</div>

			

			<h2 id="seq-3">Series</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part3/note17.pdf" class="text">Link to the PDF.</a>
			</p>

			<button class="collapsible">Addendum: Partial Fractions</button>
			<div class="ccontent">
				<p>
					Partial fractions can be important in series.
				</p>
				<p>
					Where a rational function is decomposed into a sum of simpler fractions, such as
					\[\frac{cx+d}{(x-a)(x-b)} = \frac{A}{x-a} + \frac{B}{x-b}.\]
				</p>
				<p>
					When there is no repeated factor, simply substituting \(x = a, x=b\) can eliminate a term and make it easy to find the unknowns \(A, B\). When there is however, we need to just pick values of \(x\) and solve from there.
				</p>
				<p>
					If there is a repeated factor \((x-a)^n\), the partial sum will have all the fractions with denominations \((x-a), (x-a)^2,...\) up to \((x-a)^n\)
				</p>
				<p>
					If the degree of the numerator is higher than the denominator, then we have to divide out the numerator (polynomial long division) to get a valid separable fraction,
					\[\frac{x^3 + 3x}{(x+1)(x-3)} = x+2 + \frac{10x+6}{(x+1)(x-3)}.\]
				</p>
			</div>

			<p>
				A series \(\sum a_n\) is a pair of sequences:
			</p>
			<ol>
				<li>A sequence \(a_n\) called the <b>sequence of terms</b></li>
				<li>A sequence \(s_n\) called the <b>sequence of partial sums</b> defined as
				\[s_n = \sum_{k=0}^{n} a_k.\]</li>
			</ol>

			<p>
				If the sequence of partial sums converges to \(s\), then the series converges to the sum \(s\);
				\[\sum_{n=0}^{\infty} a_n = s.\]
				Divergent if not. 
			</p>

			<p>
				A standard one is the geometric series, \(\sum r^n\) which will always converge to \(\frac{1}{1-r}\) when \(|r| < 1\). You can prove this by working out \(rs_n - s_n\).

				\begin{align}
				s_n - rs_n = 1 - r^{n+1} &\Longleftrightarrow s_n(1-r) = 1 - r^{n+1}\\
				&\Longleftrightarrow s_n = \frac{1 - r^{n+1}}{1-r}.
				\end{align}
				And \(|r| < 1\) means that \(r\)-power will converge to 0.
			</p>

			<p>
				A standard divergent series is the harmonic series, \(\sum \frac{1}{n}\). You can prove this by estimating partial sums \(s_2, s_4, s_8, s_{16}, ...\) and see that it will forever build to \(1 + 0.5 + 0.5 + 0.5 + ...\).
				\[s_{2^n} > 1 + \frac{n}{2}.\]
				Though any series \(\sum \frac{1}{n^k}\) where \(k > 1\) will always converge.
			</p>

			<div class="blue">
				<p><b><i>Basic Properties of Convergent Series.</i></b></p>
				<ol>
					<li><b>Sum rule</b>, \(\sum a_n\) converges to \(s,\; \sum b_n\) converges to \(t \implies \sum (a_n + b_n)\) converges to \(s + t\).</li>
					<li><b>Multiple rule</b>, \(\sum a_n\) converges to \(s, \; \lambda \in \mathbb{R} \implies \sum \lambda a_n\) converges to \(\lambda s\).</li>
					<li>\(\sum a_n\) converges \(\implies a_n \rightarrow 0\).</li>
					<li>\(\sum |a_n|\) converges \(\implies \sum a_n\) also converges.</li>
				</ol>
			</div>

			<p>
				No. 4 is only useful really when you have an "oscillating" series, like \(\sum \frac{(-1)^n}{2^n}\).
			</p>

			<div class="blue">
				<p>
					<b><i>The Comparison Test.</i></b> Suppose that \(0 \leq a_n \leq b_n\) for all \(n\),
				</p>
				<ol>
					<li>If \(\sum b_n\) converges then so does \(\sum a_n\)</li>
					<li>If \(\sum a_n\) diverges then so does \(\sum b_n\).</li>
				</ol>
			</div>

			<p>
				Usually with comparison test questions you just pull out equations from thin air, but (especially with rational functions) there's usually a technique for doing so based on the largest power of \(n\), and slowly chipping away a piece at a time until we get a very simple expression.
			</p>

			<button class="collapsible">Problem...</button>
			<div class="ccontent">
				<p>
					<b><i>Problem.</i></b> Determine whether the following series converges or diverges:
					\begin{align}
					& (1)\; \sum \frac{n+2}{n^3 - n^2 + 1} & (2) \;\sum \frac{n^2 + 4}{2n^3 - n + 1}
					\end{align}
				</p>
			</div>
			<p></p>
			<button class="collapsible">Answer...</button>
			<div class="ccontent">
				<p>
					<b><i>Answer 1.</i></b> Take a look at the fraction \(\frac{n+2}{n^3 - n^2 + 1}\). If we want to find a smaller fraction, we want a smaller numerator and a larger denominator than our current fraction.
					\begin{align}
					& n+2 \geq n & n^3 - n^2 + 1 \geq n^3
					\end{align}
					So we get the fraction \(\frac{n}{n^3}\) or \(\frac{1}{n^2}\) which we know will converge as a series. No help there.
				</p>
				<p>
					For a larger fraction, we want a bigger numerator and a smaller denominator;

					\begin{align}
					n+2 &\leq n + 2n \textrm{ or } 3n \\n^3 - n^2 + 1 \geq n^3 - n^2 \textrm{ or } n^2 (n -1) &\geq \frac{n^3}{2}.
					\end{align}

					Admittedly, at the end we were pulling expressions out of thin air a bit but hopefully you can see that it's all valid. Thus
					\[\frac{n+2}{n^3 - n^2 + 1} \leq \frac{6}{n^2}\]
					and since we know \(\sum \frac{6}{n^2}\) converges (\(6 \sum \frac{1}{n^2}\)) the original one must too.
				</p>

				<p>
					<b><i>Answer 2.</i></b> We're gonna be cheaty and say that this sequence does diverge. To show this, let's find a smaller fraction which diverges.

					\begin{align}
					n^2 + 4 &\geq n^2 \\
					2n^3 -n + 1 &\leq 2n^3
					\end{align}

					(the \(-n\) more than cancels out the \(+1\)) and we can see that this gives us 

					\[\frac{1}{2n} \leq \frac{n^2 + 4}{2n^3 -n+1}\]

					And oh no, \(\sum \frac{1}{2n}\) diverges (multiple rule) so the original one must too.
				</p>
			</div>
			<p></p>

			<div class="blue">
				<p>
					<b><i>The Ratio Test.</i></b> If \(|\frac{a_{n+1}}{a_n}| \rightarrow L\) then
				</p>
				<ol>
					<li>\(0 \leq L < 1 \implies \sum a_n\) converges.</li>
					<li>\(L > 1\) or \(L \textrm{ is } \infty \implies \sum a_n\) diverges.</li>
					<li>\(L = 1 \implies\) the test is inconclusive.</li>
				</ol>
			</div>

			<p>
				Useful in dealing with factorials.
			</p>

			<div class="blue">
				<p><b><i>Basic Convergent Series.</i></b></p>
				<ul>
					<li>\(\sum_{n=0}^{\infty} r^n = \frac{1}{1-r}\) for all \(r : |r| < 1\)</li>
					<li>\(\sum \frac{1}{n^k}\) converges for all \(k > 1\)</li>
					<li>\(\sum n^k r^n\) converges for \(k > 0 \land |r| < 1\)</li>
					<li>\(\sum_{n=0}^{\infty} \frac{c^n}{n!} = e^c\) for all \(c \in \mathbb{R}\)</li>
				</ul>
				<p><b><i>Basic Divergent Series.</i></b></p>
				<ul>
				<li>\(\sum \frac{1}{n^k}\) diverges for all \(k < 1\).</li></ul>
			</div>

			<p>
				A <b>power series</b> is one of the form \(\sum a_n x^n\). Usually we start at \(n = 0\), such that the sequence goes \(a_0, a_1x, a_2x^2, ...\)
			</p>

			<p class="side">
				<b><i>Lemma.</i></b> If \(\sum a_n R^n\) converges for some \(R \geq 0\), then \(\sum a_n x^n\) converges \(\forall x : |x| < R\). <i>(proof in notes)</i>
			</p>

			<p>
				\(R \geq 0\) is the <b>radius of convergence</b> of a power series \(\sum a_n x^n\) if it converges according to the above, and diverges if \(|x| > R\). If a series converges \(\forall x\) then the radius is infinity. 
			</p>

			<p>
				If the series \(\sum a_n x^n\) has a conv. rad \(R\) then it defines a function
				\begin{align}
				&f(x) = \sum_{n=0}^{\infty} a_nx^n &\forall x \in (-R, R)
				\end{align}
			</p>

			<p>
				You can find the <a href="https://www.youtube.com/watch?v=4L9dSZN5Nvg" class="text">radius of convergence using ratio test</a>, essentially evaluate
				\[\lim_{n \rightarrow \infty} |\frac{a_{n+1}}{a_n}| < 1.\]
				and you will get an \(|x| < ...\) where that something is your radius.
			</p>

			<div class="blue">
				<p>
					<b><i>Basic Properties of Power Series.</i></b> Let
					\begin{align}
					f(x) &= \sum_{n=0}^{\infty} a_nx^n & x \in (-R_1, R_1) \\
					g(x) &= \sum_{n=0}^{\infty} b_nx^n & x \in (-R_2, R_2)
					\end{align}
					For positive \(R_1, R_2\), and let \(R = \min(R_1, R_2)\). Then for all \(x \in (-R , R)\),
				</p>
				<ol>
					<li>If \(f(x) = g(x)\) then \(a_n = b_n\) for all \(n\)</li>
					<li><b>Sum rule,</b> \(f(x) + g(x) = \sum_{n=0}^{\infty} (a_n + b_n) x^n\)</li>
					<li><b>Multiple rule,</b> \(\lambda f(x) = \sum_{n=0}^{\infty} \lambda a_nx^n \; \forall \lambda \in \mathbb{R}\)</li>
					<li><b>Product rule,</b> \(f(x)g(x) = \sum_{n=0}^{\infty} (a_0b_n + a_1b_{n-1} + ... + a_{n-1}b_1 + a_nb_0)x^n \).</li>
				</ol>
			</div>

			<p>
				This also gives the general binomial theorem, which for any \(q \in \mathbb{Q}, x \in (-1, 1)\)

				\begin{align}
				(1+x)^q &= \sum_{n=0}^{\infty} {q \choose n} x^n \\
				{q \choose n} &= \frac{q!}{n!(q-n)!}
				\end{align}
			</p>


			<h2 id="seq-2">Recurrences</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part3/note16.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				<i>Like the differential equations of sequences.</i>
			</p>

			<p>
				A recurrence is a sequence defined, funnily enough, recursively.
			</p>
			<p>
				For example, the fibonacci sequence \(F_n\) is defined as
				\[F_n = F_{n-1} + F_{n-2}\]
				\[F_0 = 0, F_1 = 1.\]
			</p>
			<p>
				The <i>Towers of Hanoi</i> game's number of steps taken was computed to be the recurrence
				\[T_n = 2T_{n-1} + 1.\]
				For \(T_0 = 0\) this gives \(0, 1, 3, 7, 15, ...\) which we can see is \(T_n = 2^n - 1\). This latter form is the <b>closed form</b> of \(T_n\) and allows for immediate computation.
			</p>

			<p>
				We are looking at solving linear recurrences with constant coefficients, of the form
				\[x_n + a_1x_{n-1} + ... a_kx_{n-k} = f(n)\]
				where \(f\) is a given function. (If the terms from 1 to k are given, then this describes a unique sequence.)
			</p>
			<p>
				More importantly, we will look at <b>homogenous</b> (\(f(n) = 0\)) recurrences with \(k = 2\). Thus, we want the general solution of
				\[x_n + ax_{n-1} + bx_{n-2} =0.\]

			</p>
			<p>
				In the general case, we want to look for solutions of the form \(A\lambda^n\) where \(\lambda, A\) are constants. A bit of deriving later, we can get the auxillary equation in lambda.
			</p>
			<p class="blue">
				The <b>auxillary equation</b> of the recurrence \(x_n + ax_{n-1} + bx_{n-2} = 0\) is
				\[\lambda^2 + a\lambda + b = 0.\]
			</p>

			<div class="blue">
				<p>
					<b><i>General Solution.</i></b> of the recurrence \(x_n + ax_{n-1} + bx_{n-2} = 0\),
				</p>
				<p>
					Let \(\lambda_1, \lambda_2\) be the roots of the auxillary equation.
				</p>
				<ul>
					<li>\(\lambda_1 \neq \lambda 2 \implies x_n = A\lambda_1^n + B\lambda_2^n\)</li>
					<li>\(\lambda_1 = \lambda_2 \implies x_n = A\lambda_1^n + Bn\lambda_2^n\)</li>
				</ul>
				<p>
					For constants \(A, B\), which can be found if the first two terms of the sequence are known.
				</p>
			</div>
			<p></p>
			<button class="collapsible">Problem...</button>
			<div class="ccontent">
				<p>
					<b><i>Problem.</i></b> Find a closed form for the fibonacci sequence.
				</p>
			</div>
			<p></p>
			<button class="collapsible">Answer...</button>
			<div class="ccontent">
				<p>
					<b><i>Answer.</i></b> We have \(F_n = F_{n-1} + F_{n-2}\) so \(F_n - F_{n-1} - F_{n-2} = 0\). The auxillary equation is
					\[\lambda^2 - \lambda - 1 = 0\]
					Which has roots
					\[\lambda = \frac{1 \pm \sqrt{5}}{2}\]
					Or \(\phi\) and \(-(\frac{1}{\phi})\) (the golden ratio phi). Hence
					\[F_n = A(\frac{1 + \sqrt{5}}{2}) + B(\frac{1 - \sqrt{5}}{2}).\]
					We know \(F_0 = 0, F_1 = 1\) so if we substitue these values in, we get that \(A = \frac{1}{\sqrt{5}}, B = -\frac{1}{\sqrt{5}}\).

					\begin{align}
					F_n &= \frac{1}{\sqrt{5}}(\frac{1 + \sqrt{5}}{2}) -\frac{1}{\sqrt{5}}(\frac{1 - \sqrt{5}}{2}). \\
					&= \frac{1}{\sqrt{5}}(\phi^n + \phi^{-n}).
					\end{align}
				</p>
				<p>
					Actually by some magic we can further simplify down to
					\[F_n = \left \lfloor{\frac{\phi^n}{\sqrt{5}}}\right \rfloor\]
				</p>
			</div>

			<p>
				Non-homogenous recurrences have the \(f(n)\) bit not 0. 
			</p>

			<div class="blue">
				<p><b><i>Finding solutions to non-homogenous recurrences.</i></b> of form \(x_n + ax_{n-1} + bx_{n-2} = f(n)\)</p>
				<ol>
					<li>
						Find the general solution \(x_n = h_n\) of the homogenous recurrence:
						\[x_n + ax_{n-1} + bx_{n-2} = 0.\]
						(will have 2 arbitrary constants)
					</li>
					<li>
						Find <i>any</i> particular solution \(x_n = p_n\) of the original recurrence. 
					</li>
					<li>
						The general solution will be \(x_n = h_n + p_n\).
					</li>
				</ol>
			</div>

			<p>
				Finding the particular solution \(p_n\) is not straight forward, but the technique is to try solutions that are <i>similar in form</i> to \(f(n)\). Substitue these into the original recurrence (as they are solutions!) and try solve. 
			</p>

			<p>
				If \(f(n)\) is a constant, try find a constant \(k\).
			</p>
			<p>
				If \(f(n)\) is a polynomial, try find a <i>same degree</i> polynomial. (substitute in a general polynomial)
			</p>
			<p>
				Etc. just like diff. eqns. 
			</p>

			<h2 id="seq-4">Decimal Representation of Reals</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part3/note16.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				Rational numbers can be represented by expansions, so can repeating decimals. 
			</p>

			<p>
				Repeating decimals can be expressed as a fraction by summing an appropriate geometric series. 
			</p>

			<p>
				For example, \(0.4\overline{9}\) can be expanded as follows;
				\begin{align}
				0.4\overline{9} &= \frac{4}{10} + \frac{0}{10^2} + \frac{9}{10^3} + ... \\
				&= \frac{4}{10} + \frac{9}{10}(1 + \frac{1}{10} + \frac{1}{10^2} + ...) \\
				&= \frac{4}{10} + \frac{9}{100}(\frac{1}{1-0.1}) = \frac{4}{10} + \frac{9}{90} = \frac{4}{10} + \frac{1}{10} = \frac{1}{2}.
				\end{align}
			</p>

			<p>
				The decimal expansion of any arbitarary real can be computed by squeezing between two converging sequences.
			</p>

			<button class="collapsible nul">Expand if you really want to see...</button>
			<div class="ccontent cnul">
			<p>
				 If that real \(x\) is not an integer, it is between one integer and the next consecutive one. Now divide the integer gap into 10 fractions - if \(x\) is not on a fraction then it is between two consecutive division points,

				\[a_0 + \frac{a_1}{10} < x < a_0 + \frac{a_1 + 1}{10}\]

				Where \(a_1 \in \{0..9\}\). We can then repeat to get

				\[a_0 + \frac{a_1}{10} + \frac{a_2}{10^2} < x < a_0 + \frac{a_1}{10} + \frac{a_2 + 1}{10^2} \]

				etc etc.
			</p>
			</div>
			

			<p>
				Every rational has a terminating or repeating decimal, there's some formal <i>rigorous</i> waffle and then you compute it via long division really.
			</p>

			<p>
				Not sure why this is here save the fact that yes decimals are related to series.
			</p>
		</div>

		<div class="colourband" id="calculus">
			<h2>Calculus</h2>
		</div>

		<div class="cbox">
			<h2>Introduction</h2>

			<ol>
				<li><a href="#calc-1">Limits and Continuity</a></li>
				<li><a href="#calc-2">Differentiation</a></li>
				<li><a href="#calc-3">Properties of Differentiable Functions</a></li>
			</ol>

			<h2 id="calc-1">Limits and Continuity</h2>

			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part4/note19.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				<i>(Definitions)</i> let a function \(f: I \longrightarrow \mathbb{R}\) be defined on an interval \(I\). We're interested in a point \(a\) in that interval, where \(f\) may or may not be defined.
			</p>

			<p>
				When \(f(x)\) tends to a value \(l\) as \(x\) tends towards \(a\) from the left (negative side), we write the limit
				\[\lim_{x \rightarrow a-} f(x) = l\]

				Conversely, if \(f(x)\) tends to \(l\) as \(x\) to \(a\) from the other side we write
				\[\lim_{x \rightarrow a+} f(x) = l\]

				If \(\lim_{x \rightarrow a-} f(x) = l\) and \(\lim_{x \rightarrow a+} f(x) = l\) then
				\[\lim_{x \rightarrow a} f(x) = l.\]

				What this says that if every sequence \(x_n\) in \(I\) which converges to \(a\), \(x_n \neq a\), then \(\forall n\) the sequence \(f(x_n)\) converges to \(l\).
			</p>

			<button class="collapsible nul">Floor and Ceil...</button>
			<div class="ccontent cnul">
			<p>
				The \(\left \lfloor{\textrm{floor}}\right \rfloor \) and \(\left \lceil{\textrm{ceiling}}\right \rceil \) functions always round down and up respectively to the nearest integer.
			</p>

			<p>
				\(\forall k \in \mathbb{Z}\):
				\begin{align}
				& \lim_{x \rightarrow k-} \left \lfloor{x}\right \rfloor = k-1, & \lim_{x \rightarrow k+} \left \lfloor{x}\right \rfloor = k;
				\end{align}
				\begin{align}
				& \lim_{x \rightarrow k-} \left \lceil{x}\right \rceil = k, & \lim_{x \rightarrow k+} \left \lceil{x}\right \rceil = k+1.
				\end{align}
			</p>
			</div>

			

			<p class="side">
				<b><i>Example.</i></b> Prove that \(\lim_x \rightarrow 0 \frac{1}{x}\) does not exist. 
			</p>

			<button class="collapsible">Proof...</button>
			
			<div class="ccontent">
			<p>
				<b><i>Proof.</i></b> We need to find a sequence \(x_n \rightarrow 0\) where \(f(x_n)\) does not converge. We can magic the sequence \(x_n = \frac{1}{n}\) which does converge to 0, but \(f(x_n) = n\) is an unbounded sequence which does not converge. Hence, the limit does not exist.
				$$\tag*{$\Box$}$$
			</p>
			</div>

			<p></p>

			<div class="blue">
				<p>
					<b><i>Combination rules for limits.</i></b>  If \(\lim_{x \rightarrow a} f(x) = l\) and \(\lim_{x \rightarrow a} g(x) = m\) then
				</p>
				<ul>
					<li><b>Sum</b> rule: \(\lim_{x \rightarrow a} (f(x) + g(x)) = l + m\)</li>
					<li><b>Multiple</b> rule: \(\lim_{x \rightarrow a} \lambda f(x) = \lambda l\), \(\lambda \in \mathbb{R}\)</li>
					<li><b>Product</b> rule: \(\lim_{x \rightarrow a} f(x)g(x) = lm\)</li>
					<li><b>Quotient</b> rule: \(\lim_{x \rightarrow a} \frac{f(x)}{g(x)} = \frac{l}{m}\) provided \(m \neq 0\)</li>
				</ul>

				<p>
					<b><i>Squeeze rule for limits.</i></b> If \(f(x) \leq g(x) \leq h(x)\) for all \(x \neq a\),
					<div style="border-spacing: 0px 0px;">\[\lim_{x \rightarrow a} f(x) = l \land \lim_{x \rightarrow a} h(x) = l \implies \lim_{x \rightarrow a} g(x) = l.\]</div>
				</p>
			</div>

			<p>
				A continuous function is one with no "jumps" -
			</p>

			<p>
				A function \(f : D \longrightarrow \mathbb{R}\) (\(D \subseteq \mathbb{R}\)) is <b>continuous at a point \(a\)</b> if \(\lim{x \rightarrow a} f(x)\) exists and equals \(f(a)\). \(f\) is continous if it is continous at every point in the interval.
			</p>

			<div class="blue">
				<p>
					<b><i>Combination rules for continuous functions.</i></b> If \(f, g\) are continuous at \(a\), then so are
				</p>
				<ul>
					<li>The sum \(f+g\)</li>
					<li>The scalar multiple \(\lambda f\) (\(\lambda \in \mathbb{R}\))</li>
					<li>The product \(fg\)</li>
					<li>The quotient \(\frac{f}{g}\) provided \(g(a) \neq 0\)</li>
				</ul>
				<p>
					If \(f\) is continuous at \(a\) and \(g\) is continuous at \(f(a)\), then the composite \(g \circ f\) is also continous at \(a\).
				</p>
				
			</div>

			<p>
				<i>\(g \circ f \equiv g(f(x))\).</i>
			</p>

			<div class="blue">
				<p>
					<b><i>Basic continuous functions.</i></b>
				</p>
				<ul>
					<li>polynomials and rational functions*</li>
					<li>The modulus/absolute function</li>
					<li>The square root function, and n<sup>th</sup> root function where \(n \in \mathbb{Z}^+\)</li>
					<li>Trig functions</li>
					<li>Exponential functions</li>
					<li>Functions defined by power series</li>
				</ul>
				<p class="small">
					*The domain of rational functions exclude the divide by zero bit and so is continuous.
				</p>
			</div>


			<p class="side">
				<b><i>Intermediate Value Theorem.</i></b> If \(f : [a, b] \longrightarrow \mathbb{R}\) is continuous, \(f(a), f(b)\) have opposite signs, then there is a point \(c\) between  \(: f(c) = 0\).
			</p>

			<button class="collapsible">Problem...</button>
			<div class="ccontent">
				<p>
					<b><i>Problem.</i></b> Show that there is a number \(x : x^{179} + \frac{163}{1 + x^2} = 119\).
				</p>
			</div>
			<p></p>
			<button class="collapsible">Answer...</button>
			<div class="ccontent">
				<p>
					<b><i>Answer.</i></b> Rearrange, let \(f(x) = x^{179} + \frac{163}{1 + x^2} - 119\). 
				</p>

				<p>
					\(f(0) > 0,\; f(1) < 0\) thus by intermediate value theorem \(\exists x \in [1, 0] : f(x) = 0\). 
				</p>
				<p class="small">
					<i>(You do have to conjure numbers to do this question)</i>
				</p>$$\tag*{$\Box$}$$
				
			</div>

			<p class="side">
				<b><i>Extreme Value Theorem.</i></b> If \(f : [a, b] \longrightarrow \mathbb{R}\) is continuous, then \(\exists m, M \in [a, b]:\)
				\begin{align}
				&f(m) \leq f(x) \leq f(M) &\forall x \in [a, b]
				\end{align}
			</p>

			<p>
				Basically, there's a maximum and minimum value of a function in a bound. 
			</p>

			<h2 id="calc-2">Differentiation</h2>
			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part4/note20.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				If the limit of a real function \(f(x)\) at point \(a\)
				\[lim_{h \rightarrow 0} \frac{f(a + h) - f(a)}{h} \]
				exists, then \(f(x)\) is differentiable at \(a\), we get \(f'(a)\).
			</p>

			<p>
				The \(\frac{d}{dx}\) thing is called Leibniz notation.
			</p>

			<p class="side">
				<b><i>Theorem.</i></b> If \(f\) is differentiable at \(a\), \(f\) is also continuous at \(a\). However, \(f\) may be continuous but <i>not</i> diff'able.
			</p>

			<p>
				For example, the function \(f(x) = |x|\) is continuous at 0 but not differnetiable, because at 0 the relevant limit does not exist (there's a crinkle).
			</p>

			<p>
				Also though the notes is very from principles <i>""RIGOUR""</i> \(\frac{d(x^n)}{dx} = nx^{n-1}\) - in case you didn't know.
			</p>

			<div class="blue">
				<p>
					<b><i>Combination Rules for Derivatives.</i></b> If \(f, g\) are diff'able, the following are also diff'able and follow these rules:
				</p>
				<ul>
					<li><b>Sum</b> rule (\(f + g\)): \((f +g)' = f' + g'\)</li>
					<li><b>Multiple</b> rule (\(lambda f:\lambda \in \mathbb{R}\)): \((\lambda f)' = \lambda f'\)</li>
					<li><b>Product</b> rule (\(fg\)): \((fg)' = fg' + gf'\)</li>
					<li><b>Quotient</b> rule (\(f/g\)):  
						<div style="border-spacing: 0px 0px;">\((\frac{f}{g})' = \frac{gf' - fg'}{g^2}\)</div>
					</li>
				</ul>
			</div>

			<p></p>
			<div class="blue">
				<p><b><i>Trig derivatives.</i></b></p>
				<div style="border-spacing: 0px 0px;">
				\begin{array}{ccc}
				& \frac{d(\sin x)}{dx} = \cos x & \frac{d(\cos x)}{dx} = -\sin x &\frac{d(\tan x)}{dx} = \frac{1}{\cos ^2 x} = \sec ^2 x.
				\end{array}
				</div>
				
			</div>
			<p></p>
			<div class="blue">
				<p>
					<b><i>The Chain Rule.</i></b> (providing the functions \(y = f(z), \; z = g(x)\) are diff'able)

					<div style="border-spacing: 0px 0px;">
					\begin{align}
					\frac{dy}{dx} &= \frac{dy}{dz} \times \frac{dz}{dx} \\
					\textrm{or } (f \circ g)'(x) &= g'(x) f'(g(x))
					\end{align}
					</div>
				</p>
			</div>

			<p></p>
			<div class="blue">
				<p>
					<b><i>Diff'n of functions def' by power series.</i></b> If \(\sum(a_nx^n\) is a power series with radius of convergence R, and \(f\) is defined
					\[f(x) = \sum_{n=0}^\infty a_nx^n : x \in (-R, R)\]
					then it is diff'able and
					\[f'(x) = \sum_{n=1}^\infty na_nx^{n-1}\]
				</p>

				<p>
					<i>Pay attention: \(n=0\) changes to \(n=1\)</i>
				</p>
			</div>

			<p>
				The exponential function \(\exp(x)\) or \(e^x\) can be defined as a power series (its maclaurin series) and thus differentiable to get... \(e^x\). 
			</p>

			<button class="collapsible">Problem...</button>
			<div class="ccontent">
				<p>
					<b><i>Problem.</i></b> Find \(\sum_{n=1}^\infty \frac{n}{2^n}\).
				</p>
			</div>
			<p></p>
			<button class="collapsible">Answer...</button>
			<div class="ccontent">
				<p>
					<b><i>Answer.</i></b> You've got to bear with me on this one, because the given solution is clearly written by someone who knew the answer already and have left out a lot of the logic leaps.
				</p>

				<p>
					We start with a standard definition, for \(|x| = 1\)
					\[\sum_{n=0}^\infty x^n = \frac{1}{1-x}\]
					We differentiate the left to get
					\[\sum_{n=1}^\infty nx^{n-1} = \frac{d}{dx} (\frac{1}{1-x}).\]
					And the right resolves into \((1-x)^{-2}\).
				</p>

				<p>
					This derivative form of the power set is very similar to the sum we want to find, so much so that if we take \(x = \frac{1}{2}\),

					\[\sum_{n=1}^\infty n(\frac{1}{2})^{n-1} = \sum_{n=1}^\infty \frac{n}{2^{n-1}} \]

					Which resolves down into \(4\) since we can just sub in \(x\) to the other side. Note that if we want to get to \(\frac{n}{2^n}\) from \(\frac{n}{2^n-1}\) we have to multiply by \(\frac{1}{2}\), so we multiply both sides by a half to get

					\[\sum_{n=1}^\infty \frac{n}{2^n} = 2.\]
				</p>
			</div>

			<h2 id="calc-3">Properties of Differentiable Functions</h2>
			<p>
				<a href="https://warwick.ac.uk/fac/sci/dcs/teaching/material/cs131/part4/note21.pdf" class="text">Link to the PDF.</a>
			</p>

			<p>
				<i>(Things to be aware of)</i> Turning points, of which are local <i>maxima</i> and <i>minima</i>. 
			</p>

			<p class="side">
				<b><i>Turning Point Theorem.</i></b> If a diff'able function \(f\) has a turning point at \(a\), \(f'(a) = 0\).
			</p>

			<p>
				All points \(a\) where \(f(a) = 0\) are called <b>stationary points</b>, which aren't necessarily turning points. A stationary point which is neither a local maximum nor minimum is a <b>point of inflection</b>
			</p>

			<p>
				To locate maxima and minima of a cont. function in a range \([a, b]\), we need only consider values at
			</p>
			<ul>
				<li>The stationary points of \(f\) in \([a, b]\)</li>
				<li>The end points \(a, b\)</li>
			</ul>

			<p class="side">
				<b><i>Rolle's Theorem.</i></b> If \(f : [a, b] \longrightarrow \mathbb{R}\) is continuous, is diff'able on \(a, b\) and \(f(a) = f(b)\) then there is a point \(c \in a, b : f'(c) = 0\)
			</p>

			<p>
				You have two end points with the same \(y\) value, so in the middle there must be <i>some</i> value which is a stationary point. (on horizontal lines, all the points work.)
			</p>

			<p class="side">
				<b><i>Mean Value Theorem.</i></b> If \(f\) is continuous and diff'able over \([a, b]\) then \(\exists c \in [a,b] : \)
				\[f'(c) = \frac{f(b) - f(a)}{b-a}. \]
			</p>

			<p>
				Which is just Rolle's theorem but on a angled graph. 
			</p>

			<div class="blue">
				<p>
					<b><i>Consequences of the MVT.</i></b> Suppose \(f\) is continuous on \([a,b]\) and diff'able on \((a,b)\),
				</p>
				<ol>
					<li>
						<ul>
							<li>\(f'(x) = 0 \forall x \in (a, b) \implies f\) is constant on \([a, b]\)</li>
							<li>\(f'(x) > 0 \forall x \in (a, b) \implies f\) is <i>strictly</i> increasing</li>
							<li>\(f'(x) < 0 \forall x \in (a, b) \implies f\) is <i>strictly</i> decreasing</i></li>
						</ul>
					</li>
					<li>
						<b>Second Derivative Test.</b> Suppose \(f'(c) = 0\). \(f''(c) > 0 \implies f\) has local <i>mini</i>mum; \(f''(c) < 0 \implies f\) has local <i>maxi</i>mum.
					</li>
				</ol>
			</div>

			<p>
				For curve sketching:
			</p>
			<ul>
				<li>Find stationary points, their co-ordinates, and their nature (max/min/infl)</li>
				<li>Find where \(f(x) = 0\), i.e. intersects \(x\) axis</li>
				<li>Find \(f\) where \(x = 0\), i.e. y-intercept</li>
				<li>Determine what happens to \(f(x)\) as \(x \rightarrow \pm\infty\) (asymptotes?)</li>
				<li>Investigate near where (if) \(f(x) \rightarrow \infty\), where a divide by zero is found or some other asymptote.</li>
			</ul>
		</div>
		

		<footer>
			<div class="cbox">
				<div class="columncontainer ctwo">
					<div>
						<p class="small">
							 2020-2021 Yijun Hu, all rights reserved.
						</p>
					</div>
					<div>
						<p class="small rj">
							Designed by Yijun Hu
						</p>
					</div>
				</div>
			</div>
		</footer>

	</div>

	<script type="text/javascript" src="../../js/collapsible.js"></script>  <!--This stays at the end-->
	<script type="text/javascript" src="../../js/toggle-darklight.js"></script>
	<!--<script type="text/javascript" src="../../js/prism.js"></script>-->
</body>
</html>